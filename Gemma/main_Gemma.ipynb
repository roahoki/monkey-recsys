{"cells":[{"cell_type":"markdown","source":["### G-Drive Setup"],"metadata":{"id":"Isbtmy0bipQr"},"id":"Isbtmy0bipQr"},{"cell_type":"markdown","source":["Este notebook asume que se está ejecutando en Google Colab, y que el dataset `LLM-Redial` disponible en https://drive.google.com/drive/folders/1TIP4PFm9z0C4R4--KnHoWuiB1uK-dv5m se encuentra descargado en el drive del usuario."],"metadata":{"id":"G91y3WGR8JVS"},"id":"G91y3WGR8JVS"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zpy6FRKqFfjT","executionInfo":{"status":"ok","timestamp":1751073396191,"user_tz":240,"elapsed":114482,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"7ace460a-6eaf-4878-aa11-0298a8a08be4","collapsed":true},"id":"Zpy6FRKqFfjT","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### Instalaciones necesarias"],"metadata":{"id":"dOxz1jT1ZsaU"},"id":"dOxz1jT1ZsaU"},{"cell_type":"code","source":["%pip install unsloth[colab-new] xformers trl peft accelerate bitsandbytes rapidfuzz wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Y5xa5v8nZviG","executionInfo":{"status":"ok","timestamp":1751073573988,"user_tz":240,"elapsed":177787,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"797e74fb-7504-4ef3-f1a5-9ca57f6809ec"},"id":"Y5xa5v8nZviG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xformers\n","  Downloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting trl\n","  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Collecting rapidfuzz\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.20.1)\n","Collecting unsloth[colab-new]\n","  Downloading unsloth-2025.6.8-py3-none-any.whl.metadata (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting unsloth_zoo>=2025.6.4 (from unsloth[colab-new])\n","  Downloading unsloth_zoo-2025.6.6-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: torch<=2.7.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (2.6.0+cu124)\n","Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (3.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (24.2)\n","Collecting tyro (from unsloth[colab-new])\n","  Downloading tyro-0.9.24-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.52.4)\n","Collecting datasets>=3.4.1 (from unsloth[colab-new])\n","  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (2.0.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (5.29.5)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.33.0)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.1.9)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.34.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth[colab-new]) (0.21.0+cu124)\n","INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n","Collecting xformers\n","  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Collecting torch<=2.7.0,>=2.4.0 (from unsloth[colab-new])\n","  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (4.14.0)\n","Collecting sympy>=1.13.3 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.6.4.1 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.7.77 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Collecting nvidia-nccl-cu12==2.26.2 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvtx-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting triton>=3.0.0 (from unsloth[colab-new])\n","  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth[colab-new]) (75.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.7)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth[colab-new]) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth[colab-new]) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth[colab-new]) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth[colab-new]) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth[colab-new]) (0.70.15)\n","Collecting fsspec (from torch<=2.7.0,>=2.4.0->unsloth[colab-new])\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth[colab-new]) (1.1.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.6.15)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth[colab-new]) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth[colab-new]) (0.21.2)\n","Collecting protobuf (from unsloth[colab-new])\n","  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2025.6.4->unsloth[colab-new])\n","  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.6.4->unsloth[colab-new]) (11.2.1)\n","Collecting msgspec (from unsloth_zoo>=2025.6.4->unsloth[colab-new])\n","  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth[colab-new]) (8.7.0)\n","INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n","Collecting torchvision (from unsloth[colab-new])\n","  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (13.9.4)\n","Collecting shtab>=1.5.6 (from tyro->unsloth[colab-new])\n","  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth[colab-new]) (4.4.4)\n","\u001b[33mWARNING: unsloth 2025.6.8 does not provide the extra 'triton'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (3.11.15)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]) (2.19.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (1.3.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth[colab-new]) (3.23.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.7.0,>=2.4.0->unsloth[colab-new]) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth[colab-new]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth[colab-new]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth[colab-new]) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth[colab-new]) (1.20.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth[colab-new]) (1.17.0)\n","Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.19.0-py3-none-any.whl (375 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth_zoo-2025.6.6-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.9.24-py3-none-any.whl (128 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unsloth-2025.6.8-py3-none-any.whl (280 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n","Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m133.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n","Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, rapidfuzz, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n","  Attempting uninstall: nvidia-cusparselt-cu12\n","    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n","    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n","      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.1\n","    Uninstalling sympy-1.13.1:\n","      Successfully uninstalled sympy-1.13.1\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.5\n","    Uninstalling protobuf-5.29.5:\n","      Successfully uninstalled protobuf-5.29.5\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2025.3.2\n","    Uninstalling fsspec-2025.3.2:\n","      Successfully uninstalled fsspec-2025.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.14.4\n","    Uninstalling datasets-2.14.4:\n","      Successfully uninstalled datasets-2.14.4\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n","tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.46.0 cut_cross_entropy-25.1.1 datasets-3.6.0 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 protobuf-3.20.3 rapidfuzz-3.13.0 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.19.0 tyro-0.9.24 unsloth-2025.6.8 unsloth_zoo-2025.6.6 xformers-0.0.30\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"5afea0ce328d4f6799aad4be7907010c"}},"metadata":{}}]},{"cell_type":"code","source":["import shutil\n","import os\n","\n","source_path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/Tools.py'\n","destination_path = '/content/Tools.py'\n","\n","shutil.copy(source_path, destination_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"uop1TotjGGPP","executionInfo":{"status":"ok","timestamp":1751073575511,"user_tz":240,"elapsed":1519,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"a972c26d-f012-4569-ef10-ee26e27132cb","collapsed":true},"id":"uop1TotjGGPP","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/Tools.py'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import zipfile\n","\n","zip_path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/LLM_Redial.zip'\n","extract_path = '/content/LLM_Redial'\n","\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(extract_path)"],"metadata":{"id":"Xs5gDWtwGbge"},"id":"Xs5gDWtwGbge","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"495d7471","metadata":{"id":"495d7471","collapsed":true,"executionInfo":{"status":"ok","timestamp":1751073591006,"user_tz":240,"elapsed":9310,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"colab":{"base_uri":"https://localhost:8080/","height":327,"referenced_widgets":["c402648e16b44646ab73f966d242a899","a6d4e7a6b1bc45fe947022b49c6d3073","dadd9c3ebd4c4e55b30adc1872261374","506d34cf4aea485a945944f3d5753ae6","082288bf33ea4ce18746940713ba90b3","8f817238370b4396a2fbaf87970cac25","509f5584c7be4be8aed24cdde8628618","ec37a4af38574c99a40ad03bb85e082d","bc56144883154c1eb16935e60a86c842","834c500ce32c4708a566dd2481bb8ba8","f37ef37d5c0e42c7ac3afd9b020576c2","301c2fc756764175bdc16edae351ea7b","a47fb8871bf84ec9b09ed7533dcc2c2e","eb715b42d0d44afdb842cc3dc2a22c5c","63617185efd3443b9c662630b16b67d4","e7d621ddf66c49a9afc78f7b158c5d00","d321150264fb4dd0998fb6d927542c61","e64111300f624baa97cee66b17e7192a","05e2a4e34ded48b59fe108c642838a2a","9cb438a4f10b4a94afff67f338b0d464","dadaf261cab14cd8b11be2d253942d22","83827f121e544bb38f803113868a3f7d","11342ed6df504494956b74e674d066e2","168d5b1e026240128a060c94c79e0943","6601eac68e474b82875a6d6e9498064c","e05fa1a04d39437ebc5355e590f9799b","c0dd7879eede45e899af2da522d6a1e9","c7c0fb663bbb49d7b596e104268cdb56","bd288243957e428e9f69c3c8a6e36f5c","ee238f65d6f747cda1f51aacf48c4824","279c05c856dd4873ac1d2de506b46435","6b316269295e41c799745684a9111c33","4e1e4e9108c14fb09cd5aab92d577d00","10d1b72880d24e51881f832fe1b3f1ce","ac9e58ebce8c4fe084aa1b17517e54e8","1884c30c7d334886b3ffbd2fdd3ae653","40bc7160567c47a79b00d2b87b133704","a4af6b2a03c14bd7a5963dfcd8743914","4bcac0097179429faa1045e7ea8ad2c9","06e01de0166247a29f28026eaa625826","66abfa5c113a4f21b30104fa73a24560","08861ca926094f94acc62fd30eebdc04","efc8c0f8c4294aeba92e635898f7b52f","7bc697469107439a9f523502a92f6b0f"]},"outputId":"13a98078-6a2f-46c0-f352-416ec7f9a7f2"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c402648e16b44646ab73f966d242a899"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"301c2fc756764175bdc16edae351ea7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11342ed6df504494956b74e674d066e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10d1b72880d24e51881f832fe1b3f1ce"}},"metadata":{}}],"source":["# Gemma requiere un proceso adicional de autenticación a diferencia de\n","# los demás modelos por lo que proveeremos un token creado por nosotros\n","\n","from transformers import AutoTokenizer\n","from huggingface_hub import login\n","\n","model_name = \"google/gemma-2b-it\"\n","hf_token = \"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\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n","\n","login(token=\"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\")"]},{"cell_type":"code","execution_count":null,"id":"c9f178ea","metadata":{"id":"c9f178ea"},"outputs":[],"source":["# Cargar datos del Dataset\n","\n","import Tools as t\n","\n","path = \"./LLM_Redial/Movie\"\n","\n","final_data_path = '{}/final_data.jsonl'.format(path)\n","Conversation_path = '{}/Conversation.txt'.format(path)\n","user_map_path = '{}/user_ids.json'.format(path)\n","item_map_path = '{}/item_map.json'.format(path)\n","\n","final_data = t.read_jsonl(final_data_path)\n","user_map = t.read_json(user_map_path)\n","item_map = t.read_json(item_map_path)\n","Conversation = t.read_dialogue(Conversation_path)"]},{"cell_type":"markdown","source":["### Para limpiar el entorno y guardar las variables relevantes"],"metadata":{"id":"2V-9NouMbhXi"},"id":"2V-9NouMbhXi"},{"cell_type":"code","source":["import gc\n","import torch\n","import dill\n","\n","def cleanup_for_dill_serialization():\n","    \"\"\"\n","    Limpia todas las variables pesadas que pueden causar problemas con dill\n","    Mantiene solo los outputs y variables esenciales\n","    \"\"\"\n","    # Variables que debes eliminar ANTES de dill.dump_session()\n","    variables_to_delete = [\n","        'model', 'base_model', 'config', 'pipe',\n","\n","        # Tensores y objetos de PyTorch\n","        'inputs', 'output_ids', 'outputs',\n","\n","        # Variables temporales del loop\n","        'decoded', 'prompt', 'messages', 'ctx', 'msg',\n","\n","        # Indices y variables de control\n","        'i', 'n', 'k',\n","    ]\n","\n","    # Lista de variables que SÍ quieres mantener\n","    variables_to_keep = [\n","        'item_map',\n","        'Conversation',\n","        'model_name',\n","        'output_r'\n","        'outputs_mp'\n","        'outputs_z_s',\n","        'outputs_f_s',\n","        'outputs_ft_s',\n","        'outputs_z_n',\n","        'outputs_f_n',\n","        'outputs_ft_n',\n","        'rand_conversations',\n","        'num_test_items',\n","        'train_conv',\n","        'test_conv',\n","        'few_shot_users',\n","        'num_test_items',\n","        'few_shot_data'\n","    ]\n","\n","    # Obtener todas las variables globales\n","    global_vars = list(globals().keys())\n","\n","    # Eliminar variables específicamente problemáticas\n","    for var_name in variables_to_delete:\n","        if var_name in globals():\n","            print(f\"   ├── Eliminando: {var_name}\")\n","            try:\n","                del globals()[var_name]\n","            except:\n","                print(f\"No se pudo eliminar {var_name}\")\n","\n","    vars_to_remove = []\n","    for var_name in global_vars:\n","        if var_name.startswith('_'):  # Variables privadas\n","            continue\n","\n","        if var_name in variables_to_keep:  # No eliminar variables importantes\n","            continue\n","\n","        try:\n","            var_obj = globals().get(var_name)\n","            var_type = str(type(var_obj))\n","\n","            # Detectar objetos problemáticos\n","            problematic_types = [\n","                'transformers',\n","                'peft',\n","                'torch.nn',\n","                'pipeline',\n","                'PreTrainedModel',\n","                'PreTrainedTokenizer',\n","                'PeftModel',\n","                'Tensor'\n","            ]\n","\n","            if any(prob_type in var_type for prob_type in problematic_types):\n","                vars_to_remove.append(var_name)\n","\n","        except Exception as e:\n","            vars_to_remove.append(var_name)\n","\n","    # Eliminar variables problemáticas detectadas\n","    for var_name in vars_to_remove:\n","        print(f\"   ├── Eliminando: {var_name}\")\n","        try:\n","            del globals()[var_name]\n","        except:\n","            print(f\"No se pudo eliminar: {var_name}\")\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","    gc.collect()\n","\n","    # Verificar tamaño de variables mantenidas\n","    print(\"\\n📊 Variables mantenidas:\")\n","    for var_name in variables_to_keep:\n","        if var_name in globals():\n","            var_obj = globals()[var_name]\n","            try:\n","                if hasattr(var_obj, '__len__'):\n","                    print(f\"   ├── {var_name}: {len(var_obj)} elementos\")\n","                else:\n","                    print(f\"   ├── {var_name}: {type(var_obj)}\")\n","            except:\n","                print(f\"   ├── {var_name}: (no se puede medir)\")\n","\n","    return True\n","\n","# FUNCIÓN PRINCIPAL PARA TU CASO\n","def cleanup_after_lora_generation():\n","    \"\"\"\n","    Limpieza específica después de generar con modelo LoRA\n","    \"\"\"\n","    print(\"🎯 Limpieza específica para modelo LoRA...\")\n","\n","    # Variables específicas de tu código LoRA\n","    lora_specific_vars = [\n","        'peft_model_path',\n","        'config',           # PeftConfig\n","        'base_model',       # Modelo base\n","        'model',           # PeftModel final\n","        'tokenizer',       # Tokenizer\n","        'pipe',           # Pipeline\n","        'inputs',          # Tensors de input\n","        'output_ids',      # Tensors de output IDs\n","        'prompt',          # Prompt generado\n","        'messages',        # Mensajes del chat template\n","        'ctx',            # Context string\n","        'msg',            # Message string\n","        'decoded',        # String decodificado\n","        'outputs',        # Lista temporal (no outputs_ft_s)\n","    ]\n","\n","    for var_name in lora_specific_vars:\n","        if var_name in globals():\n","            print(f\"   ├── Eliminando: {var_name}\")\n","            try:\n","                del globals()[var_name]\n","            except Exception as e:\n","                print(f\"   │   └── Error: {e}\")\n","\n","    # Limpieza general\n","    cleanup_for_dill_serialization()\n","\n","def limpiar_y_guardar():\n","  cleanup_after_lora_generation()\n","  path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/sessions/TinyLlama/TinyLlama_notebook_env.db'\n","  with open(path, 'wb') as f:\n","      dill.dump_session(f)"],"metadata":{"id":"j30Tahk7iIZQ"},"id":"j30Tahk7iIZQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Para retornar la respuesta del modelo como una lista de nombres"],"metadata":{"id":"v1C7hJKuibgu"},"id":"v1C7hJKuibgu"},{"cell_type":"code","source":["def format_ans(ans, n):\n","    import re\n","\n","    answer_list = []\n","    try:\n","        lines = ans.strip().splitlines()\n","\n","        for line in lines:\n","            line = line.strip()\n","            # Detecta líneas como \"1. Movie Name\" o \"- Movie Name\"\n","            match = re.match(r\"^\\s*(?:\\d+\\.\\s+|\\-\\s+)(.+)\", line)\n","            if match:\n","                movie = match.group(1).strip()\n","                movie = re.sub(r\"\\(\\d{4}\\)\", \"\", movie)  # Elimina años como (2023)\n","                movie = movie.replace('\"', '')\n","                answer_list.append(movie)\n","                if len(answer_list) >= n:\n","                    break\n","\n","        return answer_list\n","\n","    except Exception as e:\n","        print(f\"Error en format_ans: {e}\")\n","        return []\n","\n","def extraer_listas_recomendadas(outputs_generados, n=10):\n","    \"\"\"\n","    Extrae listas de películas desde outputs generados por el modelo.\n","\n","    Args:\n","        outputs_generados: Lista de listas de strings generadas por el modelo.\n","        n: Cantidad máxima de películas por lista.\n","\n","    Returns:\n","        Lista de listas con películas extraídas y formateadas.\n","    \"\"\"\n","    listas_recomendadas = []\n","    for outputs in outputs_generados:\n","        rec_lists = []\n","        for out in outputs:\n","            try:\n","                inicio = out.index(\"(JUST NAMES, ONE PER LINE)\")\n","                fragmento = out[inicio:]\n","                peliculas = format_ans(fragmento, n)\n","                rec_lists.append(peliculas)\n","            except ValueError:\n","                # En caso de que no se encuentre la marca, agrega una lista vacía o un mensaje\n","                rec_lists.append([])\n","        listas_recomendadas.append(rec_lists)\n","    return listas_recomendadas\n"],"metadata":{"id":"G7m99E7Zie-6"},"id":"G7m99E7Zie-6","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Para guardar y cargar las respuestas del modelo"],"metadata":{"id":"0vgxlIwajA7b"},"id":"0vgxlIwajA7b"},{"cell_type":"code","source":["import json\n","\n","def guardar_datos_json(lista_de_listas, nombre_archivo):\n","  \"\"\"\n","  Guarda una lista de listas en un archivo de texto en formato JSON.\n","\n","  Args:\n","    lista_de_listas: La lista de listas a guardar.\n","    nombre_archivo: El nombre del archivo donde se guardará.\n","  \"\"\"\n","  try:\n","    os.makedirs(os.path.dirname(nombre_archivo), exist_ok=True)\n","\n","    with open(nombre_archivo, 'w', encoding='utf-8') as f:\n","      json.dump(lista_de_listas, f, ensure_ascii=False, indent=4)\n","    print(f\"Outputs guardados exitosamente en '{nombre_archivo}'\")\n","  except Exception as e:\n","    print(f\"Error al guardar outputs: {e}\")\n","\n","def cargar_datos_json(nombre_archivo):\n","  \"\"\"\n","  Carga una lista de listas desde un archivo de texto en formato JSON.\n","\n","  Args:\n","    nombre_archivo: El nombre del archivo desde donde se cargará.\n","\n","  Returns:\n","    La lista de listas cargada, o None si hay un error.\n","  \"\"\"\n","  try:\n","    with open(nombre_archivo, 'r', encoding='utf-8') as f:\n","      lista_de_listas = json.load(f)\n","    print(f\"Outputs cargados exitosamente desde '{nombre_archivo}'\")\n","    return lista_de_listas\n","  except FileNotFoundError:\n","    print(f\"Error: El archivo '{nombre_archivo}' no fue encontrado.\")\n","    return None\n","  except json.JSONDecodeError:\n","    print(f\"Error: El archivo '{nombre_archivo}' no es un JSON válido.\")\n","    return None\n","  except Exception as e:\n","    print(f\"Error al cargar outputs: {e}\")\n","    return None"],"metadata":{"id":"YpJK1UHUjFON"},"id":"YpJK1UHUjFON","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Cargar las conversaciones a utilizar para el entrenamiento, validación y testeo"],"metadata":{"id":"X5bMKc0ylLKN"},"id":"X5bMKc0ylLKN"},{"cell_type":"code","source":["def load_conversations(conv_path):\n","\n","    all_conversations = {}\n","    current_conv_id = None\n","    current_conv_lines = []\n","\n","    with open(conv_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            line_stripped = line.strip()\n","\n","            # Si es un número (ID de conversación)\n","            if line_stripped.isdigit():\n","                # Guardar conversación anterior si existe\n","                if current_conv_id is not None:\n","                    all_conversations[current_conv_id] = \"\".join(current_conv_lines[2:])\n","\n","                # Iniciar nueva conversación\n","                current_conv_id = int(line_stripped)\n","                current_conv_lines = [line]\n","            else:\n","                # Agregar línea a la conversación actual\n","                if current_conv_id is not None:\n","                    current_conv_lines.append(line)\n","\n","    if current_conv_id is not None:\n","        all_conversations[current_conv_id] = current_conv_lines\n","\n","\n","    all_conversations[len(all_conversations)-1] = \"\".join(all_conversations[len(all_conversations)-1][2:])\n","\n","    return all_conversations\n","\n","all_conversations = load_conversations(Conversation_path)\n","n_conversations = len(all_conversations)\n","print(n_conversations)"],"metadata":{"id":"srtBco5ylL93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751073591214,"user_tz":240,"elapsed":11,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"723b6bf6-76e1-4651-9e97-7b03f714a655"},"id":"srtBco5ylL93","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10089\n"]}]},{"cell_type":"markdown","id":"14e7c87a","metadata":{"id":"14e7c87a"},"source":["### Separación de diálogos en train, test y val, cuidando que todas las conversaciones de un usuario en particular se encuentren en sólo train o sólo en test\n"]},{"cell_type":"code","execution_count":null,"id":"93ada744","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93ada744","executionInfo":{"status":"ok","timestamp":1751073591667,"user_tz":240,"elapsed":451,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"cf202a1c-ddf3-440e-ebcb-2b3c876cc4ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Numero total de conversaciones procesadas: 10089\n","Usuarios en conjunto TEST: 299\n","Usuarios en conjunto VALIDACIÓN: 250\n","Usuarios en conjunto ENTRENAMIENTO: 2582\n","Total conjuntos generados: 3131\n"]}],"source":["import random\n","import json\n","\n","path = './LLM_Redial/Movie/final_data.jsonl'\n","\n","# Cada entrada de final_data.jsonl se ve así\n","#{\n","#  \"A30Q8X8B1S3GGT\": {\n","#    \"history_interaction\": [...],\n","#    \"user_might_like\": [...],\n","#    \"Conversation\": [...]\n","#  }\n","#}\n","\n","with open(path, 'r', encoding='utf-8') as file:\n","    data = [json.loads(line) for line in file]\n","\n","# Construimos el mapa de usuario\n","user_data_map = {user_id: user_info for item in data for user_id, user_info in item.items()}\n","user_ids = list(user_data_map.keys())\n","n_conversations = sum(len(info[\"Conversation\"]) for info in user_data_map.values())\n","\n","train_len = n_conversations * 0.8\n","test_val_len = n_conversations * 0.1\n","\n","train_conv = []\n","test_conv = []\n","val_conv = []\n","used_users = []\n","\n","aux = []\n","\n","# Seleccionamos las conversaciones para el Testeo\n","while len(aux) < test_val_len:\n","    try:\n","        convs = []\n","        random.seed(42)\n","        available_users = list(set(user_ids) - set(used_users))\n","        user_id = random.choice(available_users)\n","\n","        used_users.append(user_id)\n","        user_data = user_data_map.get(user_id)\n","        user_conversations = user_data.get(\"Conversation\", [])\n","\n","        for conv in user_conversations:\n","            conversation_details = list(conv.values())[0]\n","            conversation_id = conversation_details[\"conversation_id\"]\n","            conversation = all_conversations[conversation_id]\n","            convs.append(conversation)\n","            aux.append(conversation)\n","\n","        test_conv.append([user_id, convs])\n","\n","    except ValueError:\n","        print(f\"[ERROR - TEST] ValueError al seleccionar usuario: {user_id}, conversación: {conversation_id}\")\n","\n","aux = []\n","\n","# Seleccionamos las conversaciones para la Validación\n","while len(aux) < test_val_len:\n","    try:\n","        convs = []\n","        random.seed(42)\n","        available_users = list(set(user_ids) - set(used_users))\n","        user_id = random.choice(available_users)\n","\n","        used_users.append(user_id)\n","        user_data = user_data_map.get(user_id)\n","        user_conversations = user_data.get(\"Conversation\", [])\n","\n","        for conv in user_conversations:\n","            conversation_details = list(conv.values())[0]\n","            conversation_id = conversation_details[\"conversation_id\"]\n","            conversation = all_conversations[conversation_id]\n","            convs.append(conversation)\n","            aux.append(conversation)\n","\n","        val_conv.append([user_id, convs])\n","\n","    except ValueError:\n","        print(f\"[ERROR - VALIDACIÓN] ValueError al seleccionar usuario: {user_id}, conversación: {conversation_id}\")\n","\n","# Asignamos el resto de usuarios a Training\n","for user_id in list(set(user_ids) - set(used_users)):\n","    try:\n","        convs = []\n","        user_data = user_data_map.get(user_id)\n","        user_conversations = user_data.get(\"Conversation\", [])\n","\n","        for conv in user_conversations:\n","            conversation_details = list(conv.values())[0]\n","            conversation_id = conversation_details[\"conversation_id\"]\n","            conversation = all_conversations[conversation_id]\n","            convs.append(conversation)\n","\n","        train_conv.append([user_id, convs])\n","\n","    except ValueError:\n","        print(f\"[ERROR - ENTRENAMIENTO] ValueError al procesar usuario: {user_id}, conversación: {conversation_id}\")\n","\n","total = len(test_conv) + len(val_conv) + len(train_conv)\n","\n","print(f\"Numero total de conversaciones procesadas: {n_conversations}\")\n","print(f\"Usuarios en conjunto TEST: {len(test_conv)}\")\n","print(f\"Usuarios en conjunto VALIDACIÓN: {len(val_conv)}\")\n","print(f\"Usuarios en conjunto ENTRENAMIENTO: {len(train_conv)}\")\n","print(f\"Total conjuntos generados: {total}\")"]},{"cell_type":"markdown","id":"0426f46b","metadata":{"id":"0426f46b"},"source":["### Selección aleatoria de diálogos para testear"]},{"cell_type":"code","source":["import random\n","\n","num_test_items = 100\n","\n","def extraer_dialogos(conversations, num_conversations):\n","  rand_conversations = []\n","  all = []\n","  used_convs = []\n","\n","  for conv in conversations:\n","    all.extend([f\"{conv[0]}:::{c}\" for c in conv[1]])\n","\n","  while len(rand_conversations) < num_conversations:\n","    rand_user = random.choice(list(set(all)^set(used_convs)))\n","    used_convs.append(rand_user)\n","    rand_user = rand_user.split(\":::\")\n","    user_id = rand_user[0]\n","    user_conversation  = rand_user[1]\n","    user_data = user_data_map[user_id]\n","    convs = user_data.get(\"Conversation\", [])\n","\n","    for i in range(len(convs)):\n","      conv_details = list(convs[i].values())[0]\n","      conversation = all_conversations[conv_details[\"conversation_id\"]]\n","\n","      if user_conversation == conversation:\n","        rand_user_conv_id = i\n","\n","    dialog = \"\\n\\n\".join(user_conversation.split(\"\\n\\n\")[:3])\n","    dialog_id = list(convs[rand_user_conv_id].values())[0][\"conversation_id\"]\n","    dialog_ground_truth = list(convs[rand_user_conv_id].values())[0][\"rec_item\"]\n","    rand_user_interactions = [item_map[m] for m in user_data.get(\"history_interaction\", [])]\n","\n","    rand_conversations.append([\n","        rand_user_conv_id, # 0: Índice de conversación\n","        dialog, # 1: Texto del diálogo parcial\n","        user_data, # 2: Info estructurada del usuario\n","        dialog_id, # 3: ID de conversación\n","        dialog_ground_truth, # 4: Item recomendado como verdad\n","        rand_user_interactions,  # 5: Interaccion aleatoria de usuario\n","    ])\n","\n","  return rand_conversations"],"metadata":{"id":"sX4418osmqBA"},"id":"sX4418osmqBA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import os\n","\n","# Elegimos si generamos respuestas nuevas o si cargamos datos ya generados\n","\n","eleccion = \"\"\n","\n","while eleccion not in [\"1\", \"2\"]:\n","  eleccion = input(\"Generar respuestas nuevas (1) o cargar respuestas anteriores (2)? \")\n","  if eleccion not in [\"1\", \"2\"]:\n","    print(\"Opción inválida. Por favor, elige 1 o 2.\\n\")\n","\n","print(\"Generando respuestas nuevas...\" if eleccion == \"1\" else \"Cargando datos anteriores...\")\n","\n","# Con seed nos referimos al archivo en el drive que buscamos crear para guardar los datos\n","# O el que ya existe para cargarlos (CUIDADO CON SOBREESCRIBIR SEEDS, REVISAR DE ANTEMANO)\n","\n","seed_num = input(\"Ingresa el número de seed a cargar / guardar / sobreescribir: \")\n","\n","output_dir = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}\"\n","os.makedirs(output_dir, exist_ok=True)\n","output_path = f\"{output_dir}/rand_conversations.json\"\n","\n","if eleccion == \"1\":\n","    rand_conversations = extraer_dialogos(test_conv, num_test_items)\n","    guardar_datos_json(rand_conversations, output_path)\n","    print(f\"Datos guardados en: {output_path}\")\n","else:\n","    rand_conversations = cargar_datos_json(output_path)\n","    print(f\"Datos cargados desde: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bayqqYKIkZPp","executionInfo":{"status":"ok","timestamp":1751073604806,"user_tz":240,"elapsed":13118,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"3f90f006-dd93-4f0b-a1d2-96b4571d254e"},"id":"bayqqYKIkZPp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Generar respuestas nuevas (1) o cargar respuestas anteriores (2)? 1\n","Generando respuestas nuevas...\n","Ingresa el número de seed a cargar / guardar / sobreescribir: 2\n","Outputs guardados exitosamente en '/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed2/rand_conversations.json'\n","Datos guardados en: /content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed2/rand_conversations.json\n"]}]},{"cell_type":"markdown","source":["#Generación de 20 listas de recomendación de 10 películas"],"metadata":{"id":"3q78vcYZtwhb"},"id":"3q78vcYZtwhb"},{"cell_type":"markdown","id":"24214eec","metadata":{"id":"24214eec"},"source":["### Zero-Shot con interacciones históricas:"]},{"cell_type":"code","source":["import torch\n","from transformers import pipeline\n","import random\n","import time\n","\n","path = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}/Gemma/zero_shot.json\"\n","\n","if eleccion == \"1\":\n","\n","  k = 20 # 20\n","  outputs_z_s = []\n","\n","  pipe = pipeline(\n","      \"text-generation\",\n","      model=model_name,\n","      device_map=\"auto\",\n","      torch_dtype=torch.float16,\n","      use_auth_token=hf_token,\n","  )\n","\n","  base_ctx = (\n","      \"Me das una lista de 10 peliculas que recomiendes? Solamente dame la lista\"\n","      \"de las 10 peliculas enumeradas del 1 al 10, con sus nombres en ingles, y \"\n","      \"sin repetir la misma pelicula en la lista. No digas nada mas.\"\n","  )\n","\n","  gen_kwargs = {\n","      \"max_new_tokens\": 200,\n","      \"do_sample\": True,\n","      \"temperature\": 0.7,\n","      \"top_k\": 50,\n","      \"top_p\": 0.95,\n","      \"pad_token_id\": pipe.tokenizer.eos_token_id  # Prevents warnings\n","  }\n","\n","  total_start_time = time.time()\n","\n","  for n in range(2): #num_test_items\n","      if torch.cuda.is_available():\n","          torch.cuda.empty_cache()\n","\n","      if n%5 == 0:\n","        start_time = time.time()\n","\n","      print(f\"Generating for test item {n+1}...\")\n","      outputs = []\n","\n","      # Build message once per test item\n","      msg = (\n","          \"\\nBased on the following conversation: \\n\"\n","          f\"{rand_conversations[n][1]} \\n\\n\"\n","          \"And the movies the user has previously interacted with: \\n\"\n","          f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n","          \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n","      )\n","\n","      messages = [{\"role\": \"user\", \"content\": base_ctx + msg}]\n","      prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","\n","      # Tokenize once per test item, not per generation\n","      inputs = pipe.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","      # Batch generation option (much faster if memory allows)\n","      with torch.no_grad():\n","          iter_start_time = time.time()\n","          output_ids = pipe.model.generate(\n","              **inputs,\n","              num_return_sequences=k,\n","              **gen_kwargs\n","          )\n","          for output_id in output_ids:\n","              decoded = pipe.tokenizer.decode(output_id, skip_special_tokens=True)\n","              outputs.append(decoded)\n","          # print(f\"Iteration {i} of test item {n+1} generated in {time.time() - iter_start_time} seconds.\")\n","\n","      outputs_z_s.append(outputs)\n","\n","      if (n+1)%5 == 0:\n","        print(f\"Test items {n-3}-{n+1} generated in {(time.time() - start_time):.3f} seconds.\\n\")\n","\n","  total = time.time() - total_start_time\n","  print(f\"Total generation time: {int(total//60)} minutes and {int(total - total//60*60)} seconds.\\n\")\n","\n","  z_s_rec_lists = extraer_listas_recomendadas(outputs_z_s)\n","  print(z_s_rec_lists)\n","\n","  print()\n","\n","  guardar_datos_json(z_s_rec_lists, path)\n","elif eleccion == \"2\":\n","  outputs_z_s = cargar_datos_json(path)\n","  z_s_rec_lists = outputs_z_s\n","  print(z_s_rec_lists)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397,"referenced_widgets":["409b9df2f0d9469ab2e3156142392a0b","883cc0ca9f9e4820a960de95df934246","f543e8c169fc4475ab7179911bb30b4d","ca4ffb739f144e75ac4fe17addd8d820","86432e7e019d4f3a9115598993685b3b","9c3d94d9849844ab89f9a3b120fb040e","44952e48db984a619993335c8ebac1f4","cc3ad252487141cb9a52761090c987de","ac9e6488ec544cf78cdb50bc0fb1e7d9","abb49fd97d7342288c610dd9a155094e","2e05a02b311d478b8b6094c153d665b5","c2b10fbfb00742bbb07484621d1ba027","5923079496ac479c9d095ba9fc5672b5","f1d7eefdc7014003a4fde4e347f03d4a","4b3b690a063c4126b381752e914f37c4","3821f50f18da465aa75fed635533ff79","06e7811c81ce4ae1840c6fd3cf55eabf","d88d359706a1451db821331d19dcfcb2","ce903cb7482a419b9f5a1324da1b5447","98fb8bd6757a4192abeb7d7602f645ec","0f3476b88d0d41e094a41e2b4b644b0e","4b41515b5ca84a549936b5d0130224a4","17b6aecbbf114416abd925fe29db8346","93c76780f5924145a5930ba281af8014","bb6120f2b1fc4159be5fea24dbdcf4e6","2332389cdec940d2aa2e6c6427787f78","3be6ffcfd68a479bbdbf47576d2a3734","d9beda91e4214b63822a481a611b4fae","d203f33f03304356b184d779e54fb800","6fdce1ba22864a10bac0eee425022359","fd1412d8d10043a397d897fa62e0d1fa","096785efab7b4ad6bff54ebd1e46e25e","b382c9fadeeb430c8330b97e6fe90ec0","f761276e25f24a4ca66893edb00c87a1","6efb2bf82a934de9a759c17db15e7cee","1d81a15fe04740e8abee2cb2af6899a3","8e5e7e989739494c93322890ecc1b812","a24a1c12d7634267b2e2e9091d2a7f2f","5ad7d2d258e644458db89aa0583585bf","89da0831e9b04b57a751e25616bf4b19","12fb549995494496b0bdf46bebae034a","1eb1fa22d81d41c58d7b7c2cf3f04cf0","2cb78937f34e410f94c4bfcd000d76b3","e2e2e1f7789b472cb220e62e88b6ceb2","233e17b1dae140cf80b53c77e1c7f270","5e331e96a70f4d53a160ac6d136d4791","149e1540ad6149e38550efbca20500c9","cbce53a9e29f47e68683dfc3dc3988fb","efe68a4785354f33ae8200fd15d9a34c","d453c2a92eb447739baa14f8d83c974c","1da49a1040ff463f99ccd140724968eb","a65d22a67b0e42368e2789b7aadb57e2","55b7763789ce477aa90710546cc0cc2b","1efcfbbdb5fb473abba403b4538660e4","dd6ebf534d4f4cb187e890d37aada266","0f2e19f60b6144bc8b20c2c04f996b7c","01242a08cfe84b798b43a28ffd6e3b52","0f88954373c44a678173290c8f99ec66","98b63e9ba6904bf6829ef0738befc3ef","cc9bd11270c94530831fad19750e1b60","c11a887d33c846f888130b17a083f58c","ccbbb59fff704b57b16bbfef3f1afb56","20d3806e83e743668350d7992db51bdc","0741d8e9df7e43109e54dc9aeec9e983","fe6298db36f4428a95af9a94da58d50e","ef9f3bcf7aa44caaa2d588b854a9277e","8ea7fc309d0c493bafec1a03914264cc","076278c7e45a4ac4b0f597a71462d568","c207c37ddc7149ffaf8e0bdfb2437e45","d631743977174e95a365b348ead3e74b","1b6c27d329f340bbbcb8249132345a42","d5876370392949a7aaa9df035cfc1e64","84303f05754841529f9ae802b68316fa","e7fbf55a131247349e2be7d4197a6161","383d62cf278342e6825dab7f989c4929","d6f4b87a05f7431b8e4a5b8104d6202a","4ddef1f7f8b64482ae42746819976c0c"]},"id":"wR5kticljoN5","executionInfo":{"status":"ok","timestamp":1751073640689,"user_tz":240,"elapsed":35879,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"925ea6fb-be71-4d05-9bc7-6825ea1408e3"},"id":"wR5kticljoN5","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"409b9df2f0d9469ab2e3156142392a0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2b10fbfb00742bbb07484621d1ba027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17b6aecbbf114416abd925fe29db8346"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f761276e25f24a4ca66893edb00c87a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"233e17b1dae140cf80b53c77e1c7f270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2e19f60b6144bc8b20c2c04f996b7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ea7fc309d0c493bafec1a03914264cc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Generating for test item 1...\n","Generating for test item 2...\n","Total generation time: 0 minutes and 6 seconds.\n","\n","[[['Cheaper By the Dozen VHS', 'Meet the Fockers', 'Star Trek Fan Collective - BORG', 'Star Trek Fan Collective - Q', 'The Animatrix VHS', 'Smallville: Season 5', 'After the Sunset', 'An American Werewolf in London', 'Ultimate Avengers: The Movie', 'Jersey Girl VHS'], ['Cheaper By the Dozen VHS', 'The Animatrix VHS', 'After the Sunset', 'Meet the Fockers', 'Mallrats - LaserDisc', 'Star Trek: Fan Collective - Q', 'The Animatrix VHS', 'Star Trek Fan Collective - BORG', 'Smallville: Season 5', 'Jersey Girl VHS']], [['The Kingdom', 'John Adams', 'Taken', 'Murder By Death VHS', 'The Spy Who Came in From the Cold VHS', 'Daybreakers Blu-ray w/ Digital Copy [Blu-ray]', 'The Missing', 'In the Shadow of the Moon', 'Buried', 'Dream House'], ['The Kingdom', 'Murder By Death VHS', 'In the Shadow of the Moon', 'Buried', 'John Adams', 'Taken', \"Jennifer's Body [Blu-ray]\", 'Daybreakers Blu-ray w/ Digital Copy [Blu-ray] ', 'The Spy Who Came in From the Cold VHS', 'Dream House']]]\n","\n","Outputs guardados exitosamente en '/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed2/Gemma/zero_shot.json'\n"]}]},{"cell_type":"markdown","source":["### Few-Shot con interacción histórica"],"metadata":{"id":"bpYn7Iyp3vJ4"},"id":"bpYn7Iyp3vJ4"},{"cell_type":"code","source":["# Seleccionamos aleatoriamente los datos de Few-Shot desde Training\n","\n","few_shot_data = []\n","random.seed(42)\n","train_users = random.sample(train_conv, 5)\n","\n","for u in train_users:\n","    user_id = u[0]\n","    user_data = next((item[user_id] for item in data if user_id in item), None)\n","\n","    user_interactions = [item_map[m] for m in user_data.get(\"history_interaction\", [])]\n","    conversation_list = user_data.get(\"Conversation\", [])\n","    conversation_str = min(u[1], key=len) if u[1] else \"\"\n","\n","    for c in conversation_list:\n","        values = list(c.values())[0]\n","        user_likes = [item_map[m] for m in values.get(\"user_likes\", [])]\n","        user_dislikes = [item_map[m] for m in values.get(\"user_dislikes\", [])]\n","        recs = [item_map[m] for m in values.get(\"rec_item\", [])]\n","\n","    few_shot_data.append({\n","        \"conversation\": conversation_str,\n","        \"interactions\": user_interactions,\n","        \"likes\": user_likes,\n","        \"dislikes\": user_dislikes,\n","        \"recs\": recs\n","    })"],"metadata":{"id":"vmdHgK2ao2DO"},"id":"vmdHgK2ao2DO","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import pipeline\n","import random\n","import time\n","\n","path = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}/Gemma/few_shot.json\"\n","\n","if eleccion == \"1\":\n","\n","  k = 2 # 20\n","  outputs_f_s = []\n","\n","  pipe = pipeline(\n","      \"text-generation\",\n","      model=model_name,\n","      device_map=\"auto\",\n","      torch_dtype=torch.float16,\n","      use_auth_token=hf_token,\n","  )\n","\n","  base_ctx = (\n","      \"Me das una lista de 10 peliculas que recomiendes? Solamente dame la lista\"\n","      \"de las 10 peliculas enumeradas del 1 al 10, con sus nombres en ingles, y \"\n","      \"sin repetir la misma pelicula en la lista. No digas nada mas.\"\n","  )\n","\n","  gen_kwargs = {\n","      \"max_new_tokens\": 200,\n","      \"do_sample\": True,\n","      \"temperature\": 0.7,\n","      \"top_k\": 50,\n","      \"top_p\": 0.95,\n","      \"pad_token_id\": pipe.tokenizer.eos_token_id  # Prevents warnings\n","  }\n","\n","  total_start_time = time.time()\n","\n","  for n in range(2): #num_test_items\n","      if torch.cuda.is_available():\n","          torch.cuda.empty_cache()\n","\n","      if n%5 == 0:\n","        start_time = time.time()\n","\n","      print(f\"Generating for test item {n+1}...\")\n","      outputs = []\n","\n","      # Build message once per test item\n","      msg = (\n","          \"Based on these 4 examples: \\n\"\n","          f\"{few_shot_data[0]}\\n\"\n","          f\"{few_shot_data[1]}\\n\"\n","          f\"{few_shot_data[2]}\\n\"\n","          f\"{few_shot_data[3]}\\n\\n\"\n","          \"And based on the following conversation: \\n\"\n","          f\"{rand_conversations[n][1]} \\n\\n\"\n","          \"And the movies the user has previously interaced with: \\n\"\n","          f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n","          \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n","      )\n","\n","      messages = [{\"role\": \"user\", \"content\": base_ctx + msg}]\n","      prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","\n","      # Tokenize once per test item, not per generation\n","      inputs = pipe.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","      # Batch generation option (much faster if memory allows)\n","      with torch.no_grad():\n","          iter_start_time = time.time()\n","          output_ids = pipe.model.generate(\n","              **inputs,\n","              num_return_sequences=k,\n","              **gen_kwargs\n","          )\n","          for output_id in output_ids:\n","              decoded = pipe.tokenizer.decode(output_id, skip_special_tokens=True)\n","              outputs.append(decoded)\n","          # print(f\"Iteration {i} of test item {n+1} generated in {time.time() - iter_start_time} seconds.\")\n","\n","      outputs_f_s.append(outputs)\n","\n","      if (n+1)%5 == 0:\n","        print(f\"Test items {n-3}-{n+1} generated in {(time.time() - start_time):.3f} seconds.\\n\")\n","\n","  total = time.time() - total_start_time\n","  print(f\"Total generation time: {int(total//60)} minutes and {int(total - total//60*60)} seconds.\\n\")\n","\n","  f_s_rec_lists = extraer_listas_recomendadas(outputs_f_s)\n","  print(f_s_rec_lists)\n","\n","  print()\n","\n","  guardar_datos_json(f_s_rec_lists, path)\n","\n","elif eleccion == \"2\":\n","  outputs_f_s = cargar_datos_json(path)\n","  f_s_rec_lists = outputs_f_s\n","  print(f_s_rec_lists)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["2c35d898e1bd44939c4293cdaf49c0de","f21a633265674c46843cefb55dda3689","0af66e17253642958959b1d7974cd5d2","637d9b9097f04237871a9fd6d3119512","b3faecd3c2984ceca759895d5a8b07f3","e85aba775a51485da7786fa6a7963642","42a201eb911c4ca8b64dc0cb6eb9ff16","05c92b79a49e4a768b00fbf252a25c0b","7f9bb0cac65f4f879a062cedb69f6550","bf3434e522ba4e13a27f217a31ef6e3a","08340fd705384a6ba78bebf7c45ba8ff"]},"id":"oJWzkxM73ynC","executionInfo":{"status":"ok","timestamp":1751073651791,"user_tz":240,"elapsed":11079,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"e9da82e1-21ee-434c-8402-9abe67e731c2"},"id":"oJWzkxM73ynC","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c35d898e1bd44939c4293cdaf49c0de"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Device set to use cuda:0\n"]},{"output_type":"stream","name":"stdout","text":["Generating for test item 1...\n","Generating for test item 2...\n","Total generation time: 0 minutes and 6 seconds.\n","\n","[[['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'The Hunt 2012 Jagten', 'The Magnificent Seven VHS', 'The Hunted', 'The Fighter', 'Captain Phillips Steelbook', 'The Hunger Games: Mockingjay Part 1 2015', 'The Revenant'], ['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'Galactica 1980: Mankind Battles for Survival in Space', 'The Boy Who Could Fly', 'The Hunted', 'The Hunger Games: Mockingjay Part 1 2015', 'The Huntsman', 'The Fisher King', 'Desperado: A Legend to Remember']], [['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'The Kingdom', 'The Last Kiss', 'Vanishing Point VHS', 'Valkyrie', 'John Adams', 'Buried', 'Looper (Dvd,2012)'], ['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'The Kingdom', 'The Last Kiss', 'Vanishing Point VHS', 'Valkyrie', 'John Adams', 'Buried', 'Looper (Dvd,2012)']]]\n","\n","Outputs guardados exitosamente en '/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed2/Gemma/few_shot.json'\n"]}]},{"cell_type":"markdown","source":["### Fine-Tuning"],"metadata":{"id":"5wjZtVkYlEWT"},"id":"5wjZtVkYlEWT"},{"cell_type":"markdown","source":["#### Entrenamiento"],"metadata":{"id":"ehJDPTVeGOp2"},"id":"ehJDPTVeGOp2"},{"cell_type":"code","source":["from huggingface_hub import login\n","import wandb\n","\n","wandb.login(key=\"171b9e8bef7fa2c87c99e61e1f41f864a00b3be8\")\n","login(token=\"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\")"],"metadata":{"id":"juGqpt2SlGjQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751073655838,"user_tz":240,"elapsed":4043,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"a9587c69-cb15-4a35-f7cb-8880ec701922"},"id":"juGqpt2SlGjQ","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmonkey-recsys\u001b[0m (\u001b[33mmonkey-recsys-pontificia-universidad-cat-lica-del-per-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}]},{"cell_type":"code","source":["# Calculamos las 20 películas más gustadas por los usuarios del conjunto de entrenamiento.\n","\n","movie_likes = {}\n","for u in train_conv:\n","  user = u[0]\n","  user_data = user_data_map[user]\n","  convs = user_data.get(\"Conversation\", [])\n","  for c in convs:\n","    user_likes = list(c.values())[0][\"user_likes\"]\n","    for m in user_likes:\n","      try:\n","        movie_likes[m] += 1\n","      except:\n","        movie_likes[m] = 1\n","\n","sorted_movie_likes = dict(sorted(movie_likes.items(), key=lambda item: item[1], reverse=True))\n","top_20_movies = dict(list(sorted_movie_likes.items())[:20])\n","top_20_movie_names = [item_map[m] for m in list(top_20_movies.keys())]"],"metadata":{"id":"HuxaKk68lH7m"},"id":"HuxaKk68lH7m","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def preparar_datos_fine_tuning(rand_conversations):\n","\n","    fine_tune_data = []\n","\n","    base_ctx = (\n","      \"Me das una lista de 10 peliculas que recomiendes? Solamente dame la lista\"\n","      \"de las 10 peliculas enumeradas del 1 al 10, con sus nombres en ingles, y \"\n","      \"sin repetir la misma pelicula en la lista. No digas nada mas.\"\n","  )\n","\n","    for conversation_data in rand_conversations:\n","      msg = (\n","          \"\\nBased on the following conversation: \\n\"\n","          f\"{conversation_data[1]} \\n\\n\"\n","          \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n","      )\n","\n","      input_text = base_ctx + msg\n","\n","      top_10_recommendations = []\n","\n","      top_10_recommendations.append(item_map[conversation_data[4][0]]) # ground truth numero 1\n","\n","      user_convs = list(conversation_data[2].get(\"Conversation\", []))\n","      user_conv_id = conversation_data[0]\n","      user_likes = list(user_convs[user_conv_id].values())[0][\"user_likes\"]\n","      user_likes = [item_map[m] for m in user_likes]\n","\n","      # Agregamos 3 películas que le gustan al usuario que no se mencionan en el extracto\n","      for m in user_likes:\n","        if m not in conversation_data[1] and len(top_10_recommendations) < 4:\n","          top_10_recommendations.append(m)\n","\n","      # Agregamos 4 películas de sus interacciones\n","      interactions = random.sample(conversation_data[5], min(10, len(conversation_data[5])))\n","      top_10_recommendations.extend(interactions[:4])\n","\n","      # Rellenamos con películas al azar de las 20 más populares\n","      while len(top_10_recommendations) < 10:\n","        random_movie = random.choice(top_20_movie_names)\n","        if random_movie not in top_10_recommendations:\n","          top_10_recommendations.append(random_movie)\n","\n","      output_text = \"\\n\".join([f\"{i+1}. {movie}\" for i, movie in enumerate(top_10_recommendations)])\n","      fine_tune_data.append({\"text\": f\"\"\"{input_text}{output_text}<|endoftext|>\"\"\"})\n","\n","    return fine_tune_data\n"],"metadata":{"id":"R_bBAkhaldEJ"},"id":"R_bBAkhaldEJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["entrenar = \"\"\n","\n","while entrenar not in [\"1\", \"2\"]:\n","  entrenar = input(\"Entrenar desde cero (1) o cargar modelo pre-entrenado (2)? \")\n","\n","  if entrenar not in [\"1\", \"2\"]:\n","    print(\"Opción inválida. Por favor, elige 1 o 2.\\n\")"],"metadata":{"id":"7T0iL6tjlmAC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751073692585,"user_tz":240,"elapsed":36703,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"628724fb-1ba6-47e5-834b-8bdde9f7e8e3"},"id":"7T0iL6tjlmAC","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Entrenar desde cero (1) o cargar modelo pre-entrenado (2)? 2\n"]}]},{"cell_type":"code","source":["from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM\n","from peft import PeftModel, PeftConfig\n","from unsloth import FastLanguageModel\n","from trl import SFTTrainer\n","from datasets import Dataset\n","import torch\n","\n","path = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}/Gemma/fine-tuning/R2\"\n","\n","if entrenar == \"1\":\n","\n","  fine_tune_convs = extraer_dialogos(train_conv, len(train_conv))\n","  fine_tune_convs_val = extraer_dialogos(val_conv, min(1000, len(val_conv)))\n","  fine_tune_data = preparar_datos_fine_tuning(fine_tune_convs)\n","  fine_tune_data_val = preparar_datos_fine_tuning(fine_tune_convs_val)\n","\n","  model, tokenizer = FastLanguageModel.from_pretrained(\n","      model_name = model_name,\n","      max_seq_length = 2048,\n","      dtype = None,\n","      load_in_4bit = True,\n","      trust_remote_code = True,\n","  )\n","\n","  model = FastLanguageModel.get_peft_model(\n","      model,\n","      r = 16,\n","      target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                        \"gate_proj\", \"up_proj\", \"down_proj\"],\n","      lora_alpha = 16,\n","      lora_dropout = 0.1,\n","      bias = \"none\",\n","      use_gradient_checkpointing = True,\n","      random_state = 1234,\n","  )\n","\n","  train_dataset = Dataset.from_list(fine_tune_data)\n","  val_dataset = Dataset.from_list(fine_tune_data_val)\n","\n","  data_collator = DataCollatorForLanguageModeling(\n","      tokenizer=tokenizer,\n","      mlm=False,  # False para modelos como TinyLlama, Gemma (causal LM)\n","      pad_to_multiple_of=8,  # Optimización para tensor cores\n","      return_tensors=\"pt\"\n","  )\n","\n","  training_args = TrainingArguments(\n","      output_dir=path,\n","      per_device_train_batch_size=4,        # batch por GPU\n","      gradient_accumulation_steps=8,        # acumular gradientes para simular un batch mayor\n","      warmup_steps = 50,\n","      max_steps = 500,                    # ~2-3 epochs para 4000 ejemplos\n","      learning_rate = 2e-4,               # Relativamente alto para LoRA\n","      bf16 = True,                        # Crucial para eficiencia\n","      logging_steps = 25,\n","      optim = \"adamw_8bit\",               # Optimizador eficiente\n","      weight_decay = 0.01,\n","      lr_scheduler_type = \"cosine\",\n","      seed = 1234,\n","      save_steps = 100,\n","      eval_steps = 100,\n","      eval_strategy = \"steps\",\n","      load_best_model_at_end = True,\n","      metric_for_best_model = \"eval_loss\",\n","      greater_is_better = False,\n","  )\n","\n","  trainer = SFTTrainer(\n","      model = model,\n","      tokenizer = tokenizer,\n","      train_dataset = train_dataset,\n","      eval_dataset = val_dataset,\n","      data_collator=data_collator,\n","      dataset_text_field = \"text\",\n","      max_seq_length = 2048,\n","      dataset_num_proc = 2,\n","      args = training_args,\n","  )\n","\n","  trainer.train()\n","\n","  model.save_pretrained(path)\n","  tokenizer.save_pretrained(path)\n","\n","elif entrenar == \"2\":\n","  ft_model, ft_tokenizer = FastLanguageModel.from_pretrained(\n","      model_name = path,\n","      max_seq_length = 2048,\n","      dtype = None,\n","      load_in_4bit = True,\n","  )\n","\n","  FastLanguageModel.for_inference(ft_model)\n","  print(\"Modelo cargado exitosamente.\")"],"metadata":{"id":"rlZdL-OylodT","colab":{"base_uri":"https://localhost:8080/","height":339,"referenced_widgets":["8d3e75825ced4e1e811a7fb96f24ddcf","602382f40c6d4407b9cf02f6b7373325","18e0f9afd5344da2be1bf9ce5ce689f8","ba06836a71e94b709bea2e564b73de8b","465246d8ef3e45d6b6649773e87559a0","bf1d84f1fa594868ba9e29d95884ca51","a5c1588cd3f34ba5a532b12f912a85f0","787311b2ada44fe4b954ae5707cdf32d","3850a3ad05234498a002af62defdfb8a","d6d6c9f899f44e7380a1985319c92b90","6578c955a3e94e28ace5caea3c77c77e","5857b8f550724772bb23359fd231b17f","03b8e31dd84c4d34895ecadb6a381490","61e4f681189c401e855bb6a602232ce5","57e32f87c53047b39acc9c711da11608","b9bd7d2f2f3e4137815542ac5e5d9d7e","84bf8adcb7404de6ac9e1aa09dd8270d","22d26f1db41b414b942e5e3aad38092a","891a3f6056bf4b0a93a4321fcee78ee5","e8333504dda54bf18a5d690454bc6c18","bf4425c8a69a41c9af896bf28e10afeb","2bd3412456ef42d68af35bc3a39613dd"]},"executionInfo":{"status":"ok","timestamp":1751073736530,"user_tz":240,"elapsed":43943,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"1d7138fe-3b87-4a04-c1ab-0c947fa1b139"},"id":"rlZdL-OylodT","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-21-1987798422.py:3: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth import FastLanguageModel\n"]},{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.6.8: Fast Gemma patching. Transformers: 4.52.4.\n","   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.07G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d3e75825ced4e1e811a7fb96f24ddcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5857b8f550724772bb23359fd231b17f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unsloth 2025.6.8 patched 18 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"]},{"output_type":"stream","name":"stdout","text":["Modelo cargado exitosamente.\n"]}]},{"cell_type":"markdown","source":["#### Obtención de listas"],"metadata":{"id":"1fSAK06GGSZR"},"id":"1fSAK06GGSZR"},{"cell_type":"code","source":["from transformers import pipeline\n","from unsloth import FastLanguageModel\n","\n","path = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}/Gemma/fine_tuned_R2.json\"\n","\n","if eleccion == \"1\":\n","\n","  k = 20 # 20\n","  outputs_ft_s = []\n","\n","  ft_model_path = f\"/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed{seed_num}/Gemma/fine-tuning/R2\"\n","\n","  ft_model, ft_tokenizer = FastLanguageModel.from_pretrained(\n","      model_name = ft_model_path,\n","      max_seq_length = 2048,\n","      dtype = None,\n","      load_in_4bit = True,\n","      trust_remote_code = True,\n","  )\n","\n","  FastLanguageModel.for_inference(ft_model)\n","\n","  base_ctx = (\n","      \"Me das una lista de 10 peliculas que recomiendes? Solamente dame la lista\"\n","      \"de las 10 peliculas enumeradas del 1 al 10, con sus nombres en ingles, y \"\n","      \"sin repetir la misma pelicula en la lista. No digas nada mas.\"\n","  )\n","\n","  gen_kwargs = {\n","      \"max_new_tokens\": 200,\n","      \"do_sample\": True,\n","      \"temperature\": 0.7,\n","      \"top_k\": 50,\n","      \"top_p\": 0.95,\n","      \"pad_token_id\": ft_tokenizer.eos_token_id,\n","      \"eos_token_id\": ft_tokenizer.eos_token_id\n","    }\n","\n","  total_start_time = time.time()\n","\n","  for n in range(2): #num_test_items\n","      if torch.cuda.is_available():\n","          torch.cuda.empty_cache()\n","\n","      if n%5 == 0:\n","        start_time = time.time()\n","\n","      print(f\"Generating for test item {n+1}...\")\n","      outputs = []\n","\n","      # Build message once per test item\n","      msg = (\n","          \"\\nBased on the following conversation: \\n\"\n","          f\"{rand_conversations[n][1]} \\n\\n\"\n","          # \"And the movies the user has previously interacted with: \\n\"\n","          # f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n","          \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n","      )\n","\n","      prompt = base_ctx + msg\n","\n","      # Tokenize once per test item, not per generation\n","      inputs = ft_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","      # Batch generation option (much faster if memory allows)\n","      with torch.no_grad():\n","          iter_start_time = time.time()\n","          output_ids = ft_model.generate(\n","              **inputs,\n","              num_return_sequences=k,\n","              **gen_kwargs\n","          )\n","          for output_id in output_ids:\n","              decoded = ft_tokenizer.decode(output_id, skip_special_tokens=True)\n","              outputs.append(decoded)\n","          # print(f\"Iteration {i} of test item {n+1} generated in {time.time() - iter_start_time} seconds.\")\n","\n","      outputs_ft_s.append(outputs)\n","\n","      if (n+1)%5 == 0:\n","        print(f\"Test items {n-3}-{n+1} generated in {(time.time() - start_time):.3f} seconds.\\n\")\n","\n","  total = time.time() - total_start_time\n","  print(f\"Total generation time: {int(total//60)} minutes and {int(total - total//60*60)} seconds.\\n\")\n","\n","\n","  ft_s_rec_lists = extraer_listas_recomendadas(outputs_ft_s)\n","  print(ft_s_rec_lists)\n","\n","  print()\n","\n","  guardar_datos_json(ft_s_rec_lists, path)\n","\n","elif eleccion == \"2\":\n","  outputs_ft_s = cargar_datos_json(path)\n","  ft_s_rec_lists = outputs_ft_s\n","  print(ft_s_rec_lists)"],"metadata":{"id":"g6RvszRgpV7J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751073771771,"user_tz":240,"elapsed":35226,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"5ba99d90-e15a-4b5a-ab54-fd85789d6f53"},"id":"g6RvszRgpV7J","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unsloth: WARNING `trust_remote_code` is True.\n","Are you certain you want to do remote code execution?\n","==((====))==  Unsloth 2025.6.8: Fast Gemma patching. Transformers: 4.52.4.\n","   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Generating for test item 1...\n","Generating for test item 2...\n","Total generation time: 0 minutes and 22 seconds.\n","\n","[[['Cheaper By the Dozen VHS', 'The Lord of the Rings: The Return of the King', 'The Lord of the Rings: The Return of the King', 'The Water Horse: Legend of the Deep', 'Terminator, The', 'The Sixth Sense VHS', 'Gravity 2013  Region Free', 'Requiem for a Dream Unrated Edition  VHS', 'The Silence of the Lambs VHS<|endoftext|>', 'Cheaper By the Dozen VHS'], ['The Best of The Simpsons 1 1997  VHS', \"Mr. Magorium's Wonder Emporium\", 'The Lord of the Rings: The Return of the King', 'The Chronicles of Narnia: Prince Caspian', 'The Lord of the Rings: The Fellowship of the Ring', 'Gladiator VHS', 'Gravity 2013  Region Free', 'Terminator 3: Rise of the Machines', 'The Others<|endoftext|>', 'The Chronicles of Narnia: Prince Caspian']], [['The Silence of the Lambs VHS', \"The King's Speech\", 'The Silence of the Lambs', 'The 13th Warrior', 'The Silence of the Lambs VHS', 'The Others', 'Terminator 3: Rise of the Machines', 'Gravity 2013  Region Free', 'The Lord of the Rings: The Fellowship of the Ring<|endoftext|>', 'The Silence of the Lambs'], ['The Last Samurai', 'The Last Samurai', 'We Were Soldiers VHS', 'The Good Shepherd', 'The Others', 'Gravity 2013  Region Free', 'The Lord of the Rings: The Return of the King', 'The Lord of the Rings: The Fellowship of the Ring', 'The Silence of the Lambs VHS<|endoftext|>', 'The Lord of the Rings: The Return of the King']]]\n","\n","Outputs guardados exitosamente en '/content/gdrive/MyDrive/Proyecto LLMonkeys/outputs/seed2/Gemma/fine_tuned_R2.json'\n"]}]},{"cell_type":"markdown","source":["## Evaluación"],"metadata":{"id":"kEEEo2aUjYsJ"},"id":"kEEEo2aUjYsJ"},{"cell_type":"markdown","source":["### Funciones a utilizar para evaluar y sacar métricas"],"metadata":{"id":"mwxDQiz0x907"},"id":"mwxDQiz0x907"},{"cell_type":"code","source":["from sklearn.metrics import ndcg_score\n","from rapidfuzz import fuzz\n","import numpy as np\n","import re\n","import html\n","\n","def normalizar_titulo(titulo):\n","    # Decode entidades HTML como &amp;\n","    titulo = html.unescape(titulo)\n","    # Minúsculas\n","    titulo = titulo.lower()\n","    # Eliminar puntuación excepto letras, números y &\n","    titulo = re.sub(r\"[^a-z0-9& ]+\", \"\", titulo)\n","    # Eliminar múltiples espacios\n","    titulo = re.sub(r\"\\s+\", \" \", titulo).strip()\n","    return titulo\n","\n","def comparar_titulos(t1, t2):\n","    t1 = normalizar_titulo(t1)\n","    t2 = normalizar_titulo(t2)\n","    return fuzz.token_set_ratio(t1, t2)\n","\n","# Funciones generadas por DeepSeek\n","def recall_at_k(generated_recommendations, ground_truth, k=10):\n","    hits = 0\n","    # Tomar las primeras K recomendaciones generadas\n","    top_k = generated_recommendations[:k]\n","    for e in top_k:\n","      if comparar_titulos(e, ground_truth[0]) > 80:\n","        hits = 1\n","\n","    # Evitar división por cero\n","    return hits\n","\n","def ndcg_at_k(generated_recommendations, ground_truth, k=10):\n","    # Crear una lista binaria de relevancia (1 si está en ground truth, 0 si no)\n","    relevance = [1 if item in ground_truth else 0 for item in generated_recommendations[:k]]\n","\n","    # Crear el \"ideal ranking\" (todas las relevantes primero)\n","    ideal_relevance = sorted(relevance, reverse=True)\n","\n","    # Calcular NDCG\n","    return ndcg_score([relevance], [ideal_relevance])\n","\n","def clean_lists(x_s_rec_lists):\n","    import re\n","\n","    clean_all = []\n","\n","    for block in x_s_rec_lists:\n","        # CASO: block = [['Blade Runner', ...]] -> lista con una sola lista adentro\n","        if (\n","            isinstance(block, list)\n","            and len(block) == 1\n","            and isinstance(block[0], list)\n","            and all(isinstance(m, str) for m in block[0])\n","        ):\n","            cleaned = list(dict.fromkeys([m.strip() for m in block[0] if m.strip()]))[:10]\n","            if cleaned:\n","                clean_all.append(cleaned)\n","            continue\n","\n","        # CASO: block = ['Blade Runner', ...] -> ya es una lista de strings\n","        if isinstance(block, list) and all(isinstance(m, str) for m in block):\n","            cleaned = list(dict.fromkeys([m.strip() for m in block if m.strip()]))[:10]\n","            if cleaned:\n","                clean_all.append(cleaned)\n","            continue\n","\n","        # CASO: block es texto crudo (str) con enumeraciones\n","        if isinstance(block, str):\n","            lines = block.splitlines()\n","            cleaned = []\n","            for line in lines:\n","                match = re.search(r\"(?:^\\s*\\d+[\\)\\.\\:\\-]?\\s*)?(.*)\", line)\n","                if match:\n","                    movie = match.group(1).strip()\n","                    if movie:\n","                        cleaned.append(movie)\n","            cleaned = list(dict.fromkeys(cleaned))[:10]\n","            if cleaned:\n","                clean_all.append(cleaned)\n","            continue\n","\n","        # CASO raro: intentar extraer strings si es una lista anidada\n","        if isinstance(block, list):\n","            flattened = []\n","            for sub in block:\n","                if isinstance(sub, str):\n","                    flattened.append(sub)\n","                elif isinstance(sub, list):\n","                    flattened.extend([s for s in sub if isinstance(s, str)])\n","            cleaned = list(dict.fromkeys([m.strip() for m in flattened if m.strip()]))[:10]\n","            if cleaned:\n","                clean_all.append(cleaned)\n","\n","    return clean_all\n","\n","\n","def evaluate_recommendations(cleaned_lists, conversations, item_map, k=10):\n","    total_recall = 0.0\n","    total_ndcg = 0.0\n","    best_total_recall = 0.0\n","    best_total_ndcg = 0.0\n","    num_samples = len(cleaned_lists)\n","\n","    for i in range(num_samples):\n","        ground_truth = [item_map[m] for m in conversations[i][4]]\n","\n","        # Primera lista (sin sampling)\n","        total_recall += recall_at_k(cleaned_lists[i][0], ground_truth, k=k)\n","        total_ndcg += ndcg_at_k(cleaned_lists[i][0], ground_truth, k=k)\n","\n","        # Sampling: seleccionar la mejor entre varias muestras\n","        best_r = 0.0\n","        best_n = 0.0\n","        for rec_list in cleaned_lists[i]:\n","            recall = recall_at_k(rec_list, ground_truth, k=k)\n","            ndcg = ndcg_at_k(rec_list, ground_truth, k=k)\n","            best_r = max(best_r, recall)\n","            best_n = max(best_n, ndcg)\n","        best_total_recall += best_r\n","        best_total_ndcg += best_n\n","\n","    avg_recall = total_recall / num_samples\n","    avg_ndcg = total_ndcg / num_samples\n","    best_avg_recall = best_total_recall / num_samples\n","    best_avg_ndcg = best_total_ndcg / num_samples\n","\n","    return avg_recall, avg_ndcg, best_avg_recall, best_avg_ndcg\n","\n","def evaluate_zero_shot(rec_lists, rand_conversations, item_map, k=10):\n","  total_recall = 0.0\n","  total_ndcg = 0.0\n","  num_items = len(rec_lists)\n","\n","  for i in range(num_items):\n","      rec = rec_lists[i]\n","      ground_truth = [item_map[m] for m in rand_conversations[i][4]]\n","\n","      total_recall += recall_at_k(rec, ground_truth, k=k)\n","      total_ndcg += ndcg_at_k(rec, ground_truth, k=k)\n","\n","  return total_recall / num_items, total_ndcg / num_items\n","\n","\n","pattern = r\"\\d+\\.\\s(.*?)\\s\\(\\d{4}\\)\"\n","\n","def evaluate_model(rec_lists_clean, rand_conversations, item_map, k=5, model_name=\"\"):\n","    recall_1_k = 0\n","    ndcg_1_k = 0\n","    best_recall_k = 0.0\n","    best_ndcg_k = 0.0\n","    num_test_items = min(len(rand_conversations), len(rec_lists_clean))\n","\n","\n","    for i in range(num_test_items):\n","        gold = [item_map[m] for m in rand_conversations[i][4]]\n","\n","        # Sin sampling\n","        if len(rec_lists_clean[i]) > 0:\n","            recall_1_k += recall_at_k(rec_lists_clean[i], gold, k=k)\n","            ndcg_1_k += ndcg_at_k(rec_lists_clean[i], gold, k=k)\n","\n","        # Con sampling (mejor lista entre múltiples si existiera)\n","        best_r = 0.0\n","        best_n = 0.0\n","        rec_lists = rec_lists_clean[i] if isinstance(rec_lists_clean[i][0], list) else [rec_lists_clean[i]]\n","        for l in rec_lists:\n","            if len(l) > 0:\n","                recall = recall_at_k(l, gold, k=k)\n","                ndcg = ndcg_at_k(l, gold, k=k)\n","                if recall > best_r:\n","                    best_r = recall\n","                if ndcg > best_n:\n","                    best_n = ndcg\n","        best_recall_k += best_r\n","        best_ndcg_k += best_n\n","\n","    print(f\"\\n📊 Resultados para {model_name} (k={k}):\")\n","    print(f\"  Recall@{k} (sin sampling): {recall_1_k / num_test_items:.4f}\")\n","    print(f\"  NDCG@{k} (sin sampling):   {ndcg_1_k / num_test_items:.4f}\")\n","    print(f\"  Recall@{k} (mejor de sampling): {best_recall_k / num_test_items:.4f}\")\n","    print(f\"  NDCG@{k} (mejor de sampling):   {best_ndcg_k / num_test_items:.4f}\")"],"metadata":{"id":"xMu3vJSFSRXv"},"id":"xMu3vJSFSRXv","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Recall@5-10 y NDCG@5-10:"],"metadata":{"id":"W9dFcT15rGqg"},"id":"W9dFcT15rGqg"},{"cell_type":"code","source":["z_s_clean_lists = clean_lists(z_s_rec_lists)\n","f_s_clean_lists = clean_lists(f_s_rec_lists)\n","ft_s_clean_lists = clean_lists(ft_s_rec_lists)\n","\n","print(f\"Numero de listas de películas: {len(z_s_clean_lists)}, {z_s_clean_lists}\")\n","print(f\"Numero de listas de películas: {len(f_s_clean_lists)}, {f_s_clean_lists}\")\n","print(f\"Numero de listas de películas: {len(ft_s_clean_lists)}, {ft_s_clean_lists}\")"],"metadata":{"id":"NGrX5nnJvqfK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751074933329,"user_tz":240,"elapsed":11,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"2763e62a-bc5e-435a-8fe9-6eb7cba3612a"},"id":"NGrX5nnJvqfK","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Numero de listas de películas: 2, [['Cheaper By the Dozen VHS', 'Meet the Fockers', 'Star Trek Fan Collective - BORG', 'Star Trek Fan Collective - Q', 'The Animatrix VHS', 'Smallville: Season 5', 'After the Sunset', 'An American Werewolf in London', 'Ultimate Avengers: The Movie', 'Jersey Girl VHS'], ['The Kingdom', 'John Adams', 'Taken', 'Murder By Death VHS', 'The Spy Who Came in From the Cold VHS', 'Daybreakers Blu-ray w/ Digital Copy [Blu-ray]', 'The Missing', 'In the Shadow of the Moon', 'Buried', 'Dream House']]\n","Numero de listas de películas: 2, [['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'The Hunt 2012 Jagten', 'The Magnificent Seven VHS', 'The Hunted', 'The Fighter', 'Captain Phillips Steelbook', 'The Hunger Games: Mockingjay Part 1 2015', 'The Revenant'], ['The Equalizer', 'Taken 2', 'Lost: The Complete Sixth and Final Season', 'The Kingdom', 'The Last Kiss', 'Vanishing Point VHS', 'Valkyrie', 'John Adams', 'Buried', 'Looper (Dvd,2012)']]\n","Numero de listas de películas: 2, [['Cheaper By the Dozen VHS', 'The Lord of the Rings: The Return of the King', 'The Water Horse: Legend of the Deep', 'Terminator, The', 'The Sixth Sense VHS', 'Gravity 2013  Region Free', 'Requiem for a Dream Unrated Edition  VHS', 'The Silence of the Lambs VHS<|endoftext|>', 'The Best of The Simpsons 1 1997  VHS', \"Mr. Magorium's Wonder Emporium\"], ['The Silence of the Lambs VHS', \"The King's Speech\", 'The Silence of the Lambs', 'The 13th Warrior', 'The Others', 'Terminator 3: Rise of the Machines', 'Gravity 2013  Region Free', 'The Lord of the Rings: The Fellowship of the Ring<|endoftext|>', 'The Last Samurai', 'We Were Soldiers VHS']]\n"]}]},{"cell_type":"code","source":["evaluate_model(z_s_clean_lists, rand_conversations, item_map, k=5, model_name=\"Zero-Shot\")\n","evaluate_model(f_s_clean_lists, rand_conversations, item_map, k=5, model_name=\"Few-Shot\")\n","evaluate_model(ft_s_clean_lists, rand_conversations, item_map, k=5, model_name=\"Fine-Tuned\")\n","\n","# Si también quieres evaluar para k=10:\n","evaluate_model(z_s_clean_lists, rand_conversations, item_map, k=10, model_name=\"Zero-Shot\")\n","evaluate_model(f_s_clean_lists, rand_conversations, item_map, k=10, model_name=\"Few-Shot\")\n","evaluate_model(ft_s_clean_lists, rand_conversations, item_map, k=10, model_name=\"Fine-Tuned\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YipfRhqBNZIv","executionInfo":{"status":"ok","timestamp":1751075165999,"user_tz":240,"elapsed":20,"user":{"displayName":"Monkey RecSys","userId":"15812993793125887963"}},"outputId":"b94cd0f0-4340-41d9-9624-fa7811f7f5fa"},"id":"YipfRhqBNZIv","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Zero-Shot (k=5):\n","  Recall@5 (sin sampling): 0.0000\n","  NDCG@5 (sin sampling):   0.0000\n","  Recall@5 (mejor de sampling): 0.0000\n","  NDCG@5 (mejor de sampling):   0.0000\n","Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Few-Shot (k=5):\n","  Recall@5 (sin sampling): 0.0000\n","  NDCG@5 (sin sampling):   0.0000\n","  Recall@5 (mejor de sampling): 0.0000\n","  NDCG@5 (mejor de sampling):   0.0000\n","Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Fine-Tuned (k=5):\n","  Recall@5 (sin sampling): 0.0000\n","  NDCG@5 (sin sampling):   0.0000\n","  Recall@5 (mejor de sampling): 0.0000\n","  NDCG@5 (mejor de sampling):   0.0000\n","Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Zero-Shot (k=10):\n","  Recall@10 (sin sampling): 0.0000\n","  NDCG@10 (sin sampling):   0.0000\n","  Recall@10 (mejor de sampling): 0.0000\n","  NDCG@10 (mejor de sampling):   0.0000\n","Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Few-Shot (k=10):\n","  Recall@10 (sin sampling): 0.0000\n","  NDCG@10 (sin sampling):   0.0000\n","  Recall@10 (mejor de sampling): 0.0000\n","  NDCG@10 (mejor de sampling):   0.0000\n","Advertencia: se encontraron 2 recomendaciones, pero 100 conversaciones.\n","Usando los primeros 2 ejemplos para evaluar.\n","\n","📊 Resultados para Fine-Tuned (k=10):\n","  Recall@10 (sin sampling): 0.0000\n","  NDCG@10 (sin sampling):   0.0000\n","  Recall@10 (mejor de sampling): 0.0000\n","  NDCG@10 (mejor de sampling):   0.0000\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from collections import Counter\n","import re\n","import gc\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","from scipy.stats import entropy\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","\n","def extract_answer(text, question_text):\n","    \"\"\"Extrae la respuesta del texto generado\"\"\"\n","    # Buscar después de \"Answer:\" o similar\n","    patterns = [r\"Answer:\\s*(.+?)(?:\\n|$)\", r\"answer:\\s*(.+?)(?:\\n|$)\", r\"Answer is\\s*(.+?)(?:\\n|$)\"]\n","\n","    for pattern in patterns:\n","        match = re.search(pattern, text, re.IGNORECASE)\n","        if match:\n","            return match.group(1).strip()\n","\n","    # Si no encuentra patrón, tomar lo que viene después del prompt\n","    try:\n","        # Dividir por el texto de la pregunta y tomar la parte después\n","        parts = text.split(\"Answer:\")\n","        if len(parts) > 1:\n","            return parts[-1].strip().split('\\n')[0].strip()\n","    except:\n","        pass\n","\n","    return text.strip()\n","\n","def calculate_uncertainty_metrics_lightweight(outputs_per_paraphrase, paraphrases):\n","    \"\"\"\n","    Calcula métricas de incertidumbre usando Input Clarification Ensembling\n","\n","    Args:\n","        outputs_per_paraphrase: Lista de listas, cada sublista contiene outputs para una paráfrasis\n","        paraphrases: Lista de paráfrasis usadas\n","\n","    Returns:\n","        dict con métricas de incertidumbre\n","    \"\"\"\n","\n","    # 1. Extraer respuestas limpias\n","    all_answers = []\n","    answers_by_paraphrase = []\n","\n","    for i, outputs in enumerate(outputs_per_paraphrase):\n","        paraphrase_answers = []\n","        for output in outputs:\n","            answer = extract_answer(output, paraphrases[i])\n","            paraphrase_answers.append(answer)\n","            all_answers.append(answer)\n","        answers_by_paraphrase.append(paraphrase_answers)\n","\n","    # 2. Calcular frecuencias de respuestas\n","    answer_counts = Counter(all_answers)\n","    total_responses = len(all_answers)\n","\n","    # 3. INCERTIDUMBRE TOTAL (Shannon Entropy de todas las respuestas)\n","    probs = np.array(list(answer_counts.values())) / total_responses\n","    total_uncertainty = entropy(probs, base=2)  # bits\n","\n","    # 4. INCERTIDUMBRE ALEATORIA (promedio de entropías por paráfrasis)\n","    aleatoric_uncertainties = []\n","    for answers in answers_by_paraphrase:\n","        local_counts = Counter(answers)\n","        local_probs = np.array(list(local_counts.values())) / len(answers)\n","        if len(local_probs) > 1:\n","            aleatoric_uncertainties.append(entropy(local_probs, base=2))\n","        else:\n","            aleatoric_uncertainties.append(0.0)\n","\n","    aleatoric_uncertainty = np.mean(aleatoric_uncertainties)\n","\n","    # 5. INCERTIDUMBRE EPISTÉMICA (diferencia)\n","    epistemic_uncertainty = total_uncertainty - aleatoric_uncertainty\n","\n","    # 6. Métricas adicionales\n","    unique_answers = len(set(all_answers))\n","    most_common_answer, most_common_count = answer_counts.most_common(1)[0]\n","    confidence = most_common_count / total_responses\n","\n","    # 7. Consistencia entre paráfrasis\n","    consistency_scores = []\n","    for i in range(len(paraphrases)):\n","        for j in range(i+1, len(paraphrases)):\n","            # Comparar respuestas más frecuentes de cada paráfrasis\n","            answers_i = Counter(answers_by_paraphrase[i])\n","            answers_j = Counter(answers_by_paraphrase[j])\n","\n","            most_common_i = answers_i.most_common(1)[0][0] if answers_i else \"\"\n","            most_common_j = answers_j.most_common(1)[0][0] if answers_j else \"\"\n","\n","            # Similaridad simple (exacta o parcial)\n","            if most_common_i.lower().strip() == most_common_j.lower().strip():\n","                consistency_scores.append(1.0)\n","            else:\n","                # Similaridad parcial usando tokens comunes\n","                tokens_i = set(most_common_i.lower().split())\n","                tokens_j = set(most_common_j.lower().split())\n","                if tokens_i and tokens_j:\n","                    jaccard = len(tokens_i.intersection(tokens_j)) / len(tokens_i.union(tokens_j))\n","                    consistency_scores.append(jaccard)\n","                else:\n","                    consistency_scores.append(0.0)\n","\n","    consistency = np.mean(consistency_scores) if consistency_scores else 0.0\n","\n","    return {\n","        'total_uncertainty': float(total_uncertainty),\n","        'aleatoric_uncertainty': float(aleatoric_uncertainty),\n","        'epistemic_uncertainty': float(epistemic_uncertainty),\n","        'confidence': float(confidence),\n","        'unique_answers': int(unique_answers),\n","        'most_common_answer': str(most_common_answer),\n","        'consistency_across_paraphrases': float(consistency),\n","        'answer_distribution': {str(k): int(v) for k, v in answer_counts.items()},\n","        'num_paraphrases': len(paraphrases),\n","        'samples_per_paraphrase': len(outputs_per_paraphrase[0]) if outputs_per_paraphrase else 0\n","    }\n","\n","def calculate_logit_uncertainty_lightweight(model, tokenizer, paraphrases, device=\"cuda\", cleanup=True):\n","    \"\"\"\n","    Versión optimizada que limpia memoria agresivamente\n","    \"\"\"\n","    print(\"Calculando incertidumbre por logits (versión ligera)...\")\n","\n","    uncertainties_per_paraphrase = []\n","    logits_stats = []\n","\n","    for i, paraphrase in enumerate(paraphrases):\n","        print(f\"Procesando logits para paráfrasis {i+1}/{len(paraphrases)}\")\n","\n","        ctx = \"You are an oracle who only responds with short and concise answers.\"\n","        msg = f\"Answer the following question: {paraphrase}\\nAnswer:\"\n","        messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n","\n","        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","            next_token_logits = outputs.logits[0, -1, :].cpu()  # Mover a CPU inmediatamente\n","\n","            # Calcular probabilidades y entropía\n","            probs = torch.softmax(next_token_logits, dim=-1)\n","            uncertainty = entropy(probs.numpy(), base=2)\n","            uncertainties_per_paraphrase.append(float(uncertainty))\n","\n","            # Guardar solo estadísticas básicas, no los logits completos\n","            logits_stats.append({\n","                'mean': float(next_token_logits.mean()),\n","                'std': float(next_token_logits.std()),\n","                'max': float(next_token_logits.max()),\n","                'min': float(next_token_logits.min())\n","            })\n","\n","            # Limpiar memoria inmediatamente\n","            del outputs, next_token_logits, probs, inputs\n","            if cleanup:\n","                torch.cuda.empty_cache()\n","                gc.collect()\n","\n","    # Calcular métricas finales sin guardar arrays grandes\n","    mean_uncertainty = np.mean(uncertainties_per_paraphrase)\n","    std_uncertainty = np.std(uncertainties_per_paraphrase)\n","\n","    return {\n","        'logit_uncertainties_per_paraphrase': uncertainties_per_paraphrase,\n","        'mean_logit_uncertainty': float(mean_uncertainty),\n","        'std_logit_uncertainty': float(std_uncertainty),\n","        'logits_stats_summary': {\n","            'mean_of_means': float(np.mean([s['mean'] for s in logits_stats])),\n","            'mean_of_stds': float(np.mean([s['std'] for s in logits_stats])),\n","        }\n","    }\n"],"metadata":{"id":"FZy5oaTqS8fX"},"id":"FZy5oaTqS8fX","execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Configuración\n","model_name = \"google/gemma-2b-it\"  # o el modelo que uses\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Cargar modelo y tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n","\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","# Paráfrasis de la pregunta\n","paraphrases = [\n","    \"What year did the Berlin Wall fall?\",\n","    \"When did the Berlin Wall come down?\",\n","    \"In which year was the Berlin Wall demolished?\",\n","    \"What year did the fall of the Berlin Wall occur?\",\n","    \"When was the Berlin Wall brought down?\",\n","    \"In what year did the Berlin Wall collapse?\",\n","    \"What year did they tear down the Berlin Wall?\",\n","    \"When did the destruction of the Berlin Wall happen?\",\n","    \"In which year did the Berlin Wall get demolished?\",\n","    \"What year marked the fall of the Berlin Wall?\"\n","]\n","\n","# Generar respuestas con sampling\n","outputs_per_paraphrase = []\n","k = 5  # Número de samples por paráfrasis\n","\n","print(\"Generando respuestas...\")\n","for i, paraphrase in enumerate(paraphrases):\n","    print(f\"Procesando paráfrasis {i+1}/{len(paraphrases)}: {paraphrase}\")\n","\n","    outputs = []\n","    ctx = \"You are an oracle who only responds with short and concise answers.\"\n","    msg = f\"Answer the following question: {paraphrase}\\nAnswer:\"\n","    messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n","\n","    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    for j in range(k):\n","        with torch.no_grad():\n","            output_ids = model.generate(\n","                **inputs,\n","                max_new_tokens=50,\n","                do_sample=True,\n","                temperature=0.7,\n","                top_k=50,\n","                top_p=0.95,\n","                pad_token_id=tokenizer.eos_token_id\n","            )\n","\n","            # Decodificar solo la parte nueva (sin el prompt)\n","            new_tokens = output_ids[0][inputs['input_ids'].shape[1]:]\n","            decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n","            outputs.append(decoded)\n","\n","    outputs_per_paraphrase.append(outputs)\n","\n"],"metadata":{"id":"A4pHePUeTDI0"},"id":"A4pHePUeTDI0","execution_count":null,"outputs":[]},{"cell_type":"code","source":["include_logits = True\n","cleanup_model = True"],"metadata":{"id":"vIe8LOKGTgri"},"id":"vIe8LOKGTgri","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"=\"*50)\n","print(\"CALCULANDO INCERTIDUMBRE (VERSIÓN OPTIMIZADA)...\")\n","print(\"=\"*50)\n","\n","# 1. Calcular métricas básicas de incertidumbre\n","uncertainty_metrics = calculate_uncertainty_metrics_lightweight(outputs_per_paraphrase, paraphrases)\n","\n","# 2. Calcular métricas de logits si se solicita\n","logit_metrics = None\n","if include_logits and model is not None and tokenizer is not None:\n","    logit_metrics = calculate_logit_uncertainty_lightweight(\n","        model, tokenizer, paraphrases, device, cleanup=True\n","    )\n","\n","# 3. LIMPIAR MODELO DE MEMORIA SI SE SOLICITA\n","if cleanup_model and model is not None:\n","    print(\"Limpiando modelo de memoria...\")\n","    del model\n","    if tokenizer is not None:\n","        del tokenizer\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(\"✓ Modelo removido de memoria\")\n","\n","# 4. Mostrar resultados\n","print(f\"\\n📊 MÉTRICAS DE INCERTIDUMBRE:\")\n","print(f\"├── Incertidumbre Total: {uncertainty_metrics['total_uncertainty']:.3f} bits\")\n","print(f\"├── Incertidumbre Aleatoria: {uncertainty_metrics['aleatoric_uncertainty']:.3f} bits\")\n","print(f\"├── Incertidumbre Epistémica: {uncertainty_metrics['epistemic_uncertainty']:.3f} bits\")\n","print(f\"├── Confianza: {uncertainty_metrics['confidence']:.3f}\")\n","print(f\"├── Respuestas únicas: {uncertainty_metrics['unique_answers']}\")\n","print(f\"├── Consistencia entre paráfrasis: {uncertainty_metrics['consistency_across_paraphrases']:.3f}\")\n","print(f\"└── Respuesta más común: '{uncertainty_metrics['most_common_answer']}'\")\n","\n","if logit_metrics:\n","    print(f\"\\n🔢 MÉTRICAS DE LOGITS:\")\n","    print(f\"├── Incertidumbre promedio: {logit_metrics['mean_logit_uncertainty']:.3f} bits\")\n","    print(f\"├── Desviación estándar: {logit_metrics['std_logit_uncertainty']:.3f} bits\")\n","    print(f\"└── Media de logits: {logit_metrics['logits_stats_summary']['mean_of_means']:.3f}\")\n","\n","# 5. Interpretación\n","print(f\"\\n🧠 INTERPRETACIÓN:\")\n","if uncertainty_metrics['epistemic_uncertainty'] > uncertainty_metrics['aleatoric_uncertainty']:\n","    print(\"├── El modelo tiene más incertidumbre sobre QUÉ responder\")\n","    print(\"└── → Sugiere falta de conocimiento específico\")\n","else:\n","    print(\"├── El modelo tiene más incertidumbre sobre CÓMO responder\")\n","    print(\"└── → Sugiere ambigüedad inherente en la pregunta\")\n","\n","if uncertainty_metrics['consistency_across_paraphrases'] > 0.8:\n","    print(\"├── Alta consistencia entre paráfrasis\")\n","elif uncertainty_metrics['consistency_across_paraphrases'] > 0.5:\n","    print(\"├── Consistencia moderada entre paráfrasis\")\n","else:\n","    print(\"├── Baja consistencia - posible confusión del modelo\")\n","\n","# DEVOLVER SOLO RESULTADOS LIGEROS\n","results = {\n","    'uncertainty_metrics': uncertainty_metrics,\n","    'logit_metrics': logit_metrics,\n","    'analysis_params': {\n","        'num_paraphrases': len(paraphrases),\n","        'samples_per_paraphrase': len(outputs_per_paraphrase[0]) if outputs_per_paraphrase else 0,\n","        'included_logits': include_logits\n","    }\n","}\n","\n","print(results)"],"metadata":{"id":"88wuKy1rTiVl"},"id":"88wuKy1rTiVl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import dill\n","\n","path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/sessions/Gemma/Gemma_notebook_env.db'\n","with open(path, 'wb') as f:\n","    dill.dump_session(f)"],"metadata":{"id":"-d9y0CmPI4mP"},"id":"-d9y0CmPI4mP","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"colab":{"provenance":[],"gpuType":"L4","collapsed_sections":["dOxz1jT1ZsaU","2V-9NouMbhXi","v1C7hJKuibgu","0vgxlIwajA7b","X5bMKc0ylLKN","14e7c87a","kEEEo2aUjYsJ"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c402648e16b44646ab73f966d242a899":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6d4e7a6b1bc45fe947022b49c6d3073","IPY_MODEL_dadd9c3ebd4c4e55b30adc1872261374","IPY_MODEL_506d34cf4aea485a945944f3d5753ae6"],"layout":"IPY_MODEL_082288bf33ea4ce18746940713ba90b3"}},"a6d4e7a6b1bc45fe947022b49c6d3073":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f817238370b4396a2fbaf87970cac25","placeholder":"​","style":"IPY_MODEL_509f5584c7be4be8aed24cdde8628618","value":"tokenizer_config.json: 100%"}},"dadd9c3ebd4c4e55b30adc1872261374":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec37a4af38574c99a40ad03bb85e082d","max":34173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc56144883154c1eb16935e60a86c842","value":34173}},"506d34cf4aea485a945944f3d5753ae6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_834c500ce32c4708a566dd2481bb8ba8","placeholder":"​","style":"IPY_MODEL_f37ef37d5c0e42c7ac3afd9b020576c2","value":" 34.2k/34.2k [00:00&lt;00:00, 3.80MB/s]"}},"082288bf33ea4ce18746940713ba90b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f817238370b4396a2fbaf87970cac25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509f5584c7be4be8aed24cdde8628618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec37a4af38574c99a40ad03bb85e082d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc56144883154c1eb16935e60a86c842":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834c500ce32c4708a566dd2481bb8ba8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37ef37d5c0e42c7ac3afd9b020576c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"301c2fc756764175bdc16edae351ea7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a47fb8871bf84ec9b09ed7533dcc2c2e","IPY_MODEL_eb715b42d0d44afdb842cc3dc2a22c5c","IPY_MODEL_63617185efd3443b9c662630b16b67d4"],"layout":"IPY_MODEL_e7d621ddf66c49a9afc78f7b158c5d00"}},"a47fb8871bf84ec9b09ed7533dcc2c2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d321150264fb4dd0998fb6d927542c61","placeholder":"​","style":"IPY_MODEL_e64111300f624baa97cee66b17e7192a","value":"tokenizer.model: 100%"}},"eb715b42d0d44afdb842cc3dc2a22c5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05e2a4e34ded48b59fe108c642838a2a","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cb438a4f10b4a94afff67f338b0d464","value":4241003}},"63617185efd3443b9c662630b16b67d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dadaf261cab14cd8b11be2d253942d22","placeholder":"​","style":"IPY_MODEL_83827f121e544bb38f803113868a3f7d","value":" 4.24M/4.24M [00:00&lt;00:00, 66.5MB/s]"}},"e7d621ddf66c49a9afc78f7b158c5d00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d321150264fb4dd0998fb6d927542c61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e64111300f624baa97cee66b17e7192a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05e2a4e34ded48b59fe108c642838a2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cb438a4f10b4a94afff67f338b0d464":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dadaf261cab14cd8b11be2d253942d22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83827f121e544bb38f803113868a3f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11342ed6df504494956b74e674d066e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_168d5b1e026240128a060c94c79e0943","IPY_MODEL_6601eac68e474b82875a6d6e9498064c","IPY_MODEL_e05fa1a04d39437ebc5355e590f9799b"],"layout":"IPY_MODEL_c0dd7879eede45e899af2da522d6a1e9"}},"168d5b1e026240128a060c94c79e0943":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7c0fb663bbb49d7b596e104268cdb56","placeholder":"​","style":"IPY_MODEL_bd288243957e428e9f69c3c8a6e36f5c","value":"tokenizer.json: 100%"}},"6601eac68e474b82875a6d6e9498064c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee238f65d6f747cda1f51aacf48c4824","max":17518497,"min":0,"orientation":"horizontal","style":"IPY_MODEL_279c05c856dd4873ac1d2de506b46435","value":17518497}},"e05fa1a04d39437ebc5355e590f9799b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b316269295e41c799745684a9111c33","placeholder":"​","style":"IPY_MODEL_4e1e4e9108c14fb09cd5aab92d577d00","value":" 17.5M/17.5M [00:00&lt;00:00, 211MB/s]"}},"c0dd7879eede45e899af2da522d6a1e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7c0fb663bbb49d7b596e104268cdb56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd288243957e428e9f69c3c8a6e36f5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee238f65d6f747cda1f51aacf48c4824":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"279c05c856dd4873ac1d2de506b46435":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b316269295e41c799745684a9111c33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1e4e9108c14fb09cd5aab92d577d00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10d1b72880d24e51881f832fe1b3f1ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ac9e58ebce8c4fe084aa1b17517e54e8","IPY_MODEL_1884c30c7d334886b3ffbd2fdd3ae653","IPY_MODEL_40bc7160567c47a79b00d2b87b133704"],"layout":"IPY_MODEL_a4af6b2a03c14bd7a5963dfcd8743914"}},"ac9e58ebce8c4fe084aa1b17517e54e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bcac0097179429faa1045e7ea8ad2c9","placeholder":"​","style":"IPY_MODEL_06e01de0166247a29f28026eaa625826","value":"special_tokens_map.json: 100%"}},"1884c30c7d334886b3ffbd2fdd3ae653":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66abfa5c113a4f21b30104fa73a24560","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08861ca926094f94acc62fd30eebdc04","value":636}},"40bc7160567c47a79b00d2b87b133704":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efc8c0f8c4294aeba92e635898f7b52f","placeholder":"​","style":"IPY_MODEL_7bc697469107439a9f523502a92f6b0f","value":" 636/636 [00:00&lt;00:00, 78.7kB/s]"}},"a4af6b2a03c14bd7a5963dfcd8743914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bcac0097179429faa1045e7ea8ad2c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06e01de0166247a29f28026eaa625826":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66abfa5c113a4f21b30104fa73a24560":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08861ca926094f94acc62fd30eebdc04":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efc8c0f8c4294aeba92e635898f7b52f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bc697469107439a9f523502a92f6b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"409b9df2f0d9469ab2e3156142392a0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_883cc0ca9f9e4820a960de95df934246","IPY_MODEL_f543e8c169fc4475ab7179911bb30b4d","IPY_MODEL_ca4ffb739f144e75ac4fe17addd8d820"],"layout":"IPY_MODEL_86432e7e019d4f3a9115598993685b3b"}},"883cc0ca9f9e4820a960de95df934246":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3d94d9849844ab89f9a3b120fb040e","placeholder":"​","style":"IPY_MODEL_44952e48db984a619993335c8ebac1f4","value":"config.json: 100%"}},"f543e8c169fc4475ab7179911bb30b4d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc3ad252487141cb9a52761090c987de","max":627,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac9e6488ec544cf78cdb50bc0fb1e7d9","value":627}},"ca4ffb739f144e75ac4fe17addd8d820":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abb49fd97d7342288c610dd9a155094e","placeholder":"​","style":"IPY_MODEL_2e05a02b311d478b8b6094c153d665b5","value":" 627/627 [00:00&lt;00:00, 69.3kB/s]"}},"86432e7e019d4f3a9115598993685b3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3d94d9849844ab89f9a3b120fb040e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44952e48db984a619993335c8ebac1f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc3ad252487141cb9a52761090c987de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac9e6488ec544cf78cdb50bc0fb1e7d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abb49fd97d7342288c610dd9a155094e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e05a02b311d478b8b6094c153d665b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2b10fbfb00742bbb07484621d1ba027":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5923079496ac479c9d095ba9fc5672b5","IPY_MODEL_f1d7eefdc7014003a4fde4e347f03d4a","IPY_MODEL_4b3b690a063c4126b381752e914f37c4"],"layout":"IPY_MODEL_3821f50f18da465aa75fed635533ff79"}},"5923079496ac479c9d095ba9fc5672b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e7811c81ce4ae1840c6fd3cf55eabf","placeholder":"​","style":"IPY_MODEL_d88d359706a1451db821331d19dcfcb2","value":"model.safetensors.index.json: 100%"}},"f1d7eefdc7014003a4fde4e347f03d4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce903cb7482a419b9f5a1324da1b5447","max":13489,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98fb8bd6757a4192abeb7d7602f645ec","value":13489}},"4b3b690a063c4126b381752e914f37c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f3476b88d0d41e094a41e2b4b644b0e","placeholder":"​","style":"IPY_MODEL_4b41515b5ca84a549936b5d0130224a4","value":" 13.5k/13.5k [00:00&lt;00:00, 1.59MB/s]"}},"3821f50f18da465aa75fed635533ff79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06e7811c81ce4ae1840c6fd3cf55eabf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d88d359706a1451db821331d19dcfcb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce903cb7482a419b9f5a1324da1b5447":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98fb8bd6757a4192abeb7d7602f645ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f3476b88d0d41e094a41e2b4b644b0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b41515b5ca84a549936b5d0130224a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17b6aecbbf114416abd925fe29db8346":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93c76780f5924145a5930ba281af8014","IPY_MODEL_bb6120f2b1fc4159be5fea24dbdcf4e6","IPY_MODEL_2332389cdec940d2aa2e6c6427787f78"],"layout":"IPY_MODEL_3be6ffcfd68a479bbdbf47576d2a3734"}},"93c76780f5924145a5930ba281af8014":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9beda91e4214b63822a481a611b4fae","placeholder":"​","style":"IPY_MODEL_d203f33f03304356b184d779e54fb800","value":"Fetching 2 files: 100%"}},"bb6120f2b1fc4159be5fea24dbdcf4e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fdce1ba22864a10bac0eee425022359","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd1412d8d10043a397d897fa62e0d1fa","value":2}},"2332389cdec940d2aa2e6c6427787f78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_096785efab7b4ad6bff54ebd1e46e25e","placeholder":"​","style":"IPY_MODEL_b382c9fadeeb430c8330b97e6fe90ec0","value":" 2/2 [00:15&lt;00:00, 15.62s/it]"}},"3be6ffcfd68a479bbdbf47576d2a3734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9beda91e4214b63822a481a611b4fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d203f33f03304356b184d779e54fb800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6fdce1ba22864a10bac0eee425022359":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd1412d8d10043a397d897fa62e0d1fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"096785efab7b4ad6bff54ebd1e46e25e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b382c9fadeeb430c8330b97e6fe90ec0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f761276e25f24a4ca66893edb00c87a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6efb2bf82a934de9a759c17db15e7cee","IPY_MODEL_1d81a15fe04740e8abee2cb2af6899a3","IPY_MODEL_8e5e7e989739494c93322890ecc1b812"],"layout":"IPY_MODEL_a24a1c12d7634267b2e2e9091d2a7f2f"}},"6efb2bf82a934de9a759c17db15e7cee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ad7d2d258e644458db89aa0583585bf","placeholder":"​","style":"IPY_MODEL_89da0831e9b04b57a751e25616bf4b19","value":"model-00001-of-00002.safetensors: 100%"}},"1d81a15fe04740e8abee2cb2af6899a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12fb549995494496b0bdf46bebae034a","max":4945242264,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1eb1fa22d81d41c58d7b7c2cf3f04cf0","value":4945242264}},"8e5e7e989739494c93322890ecc1b812":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb78937f34e410f94c4bfcd000d76b3","placeholder":"​","style":"IPY_MODEL_e2e2e1f7789b472cb220e62e88b6ceb2","value":" 4.95G/4.95G [00:15&lt;00:00, 477MB/s]"}},"a24a1c12d7634267b2e2e9091d2a7f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ad7d2d258e644458db89aa0583585bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89da0831e9b04b57a751e25616bf4b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12fb549995494496b0bdf46bebae034a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eb1fa22d81d41c58d7b7c2cf3f04cf0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cb78937f34e410f94c4bfcd000d76b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e2e1f7789b472cb220e62e88b6ceb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"233e17b1dae140cf80b53c77e1c7f270":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e331e96a70f4d53a160ac6d136d4791","IPY_MODEL_149e1540ad6149e38550efbca20500c9","IPY_MODEL_cbce53a9e29f47e68683dfc3dc3988fb"],"layout":"IPY_MODEL_efe68a4785354f33ae8200fd15d9a34c"}},"5e331e96a70f4d53a160ac6d136d4791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d453c2a92eb447739baa14f8d83c974c","placeholder":"​","style":"IPY_MODEL_1da49a1040ff463f99ccd140724968eb","value":"model-00002-of-00002.safetensors: 100%"}},"149e1540ad6149e38550efbca20500c9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a65d22a67b0e42368e2789b7aadb57e2","max":67121608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55b7763789ce477aa90710546cc0cc2b","value":67121608}},"cbce53a9e29f47e68683dfc3dc3988fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1efcfbbdb5fb473abba403b4538660e4","placeholder":"​","style":"IPY_MODEL_dd6ebf534d4f4cb187e890d37aada266","value":" 67.1M/67.1M [00:00&lt;00:00, 171MB/s]"}},"efe68a4785354f33ae8200fd15d9a34c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d453c2a92eb447739baa14f8d83c974c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1da49a1040ff463f99ccd140724968eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a65d22a67b0e42368e2789b7aadb57e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55b7763789ce477aa90710546cc0cc2b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1efcfbbdb5fb473abba403b4538660e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd6ebf534d4f4cb187e890d37aada266":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f2e19f60b6144bc8b20c2c04f996b7c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01242a08cfe84b798b43a28ffd6e3b52","IPY_MODEL_0f88954373c44a678173290c8f99ec66","IPY_MODEL_98b63e9ba6904bf6829ef0738befc3ef"],"layout":"IPY_MODEL_cc9bd11270c94530831fad19750e1b60"}},"01242a08cfe84b798b43a28ffd6e3b52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c11a887d33c846f888130b17a083f58c","placeholder":"​","style":"IPY_MODEL_ccbbb59fff704b57b16bbfef3f1afb56","value":"Loading checkpoint shards: 100%"}},"0f88954373c44a678173290c8f99ec66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20d3806e83e743668350d7992db51bdc","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0741d8e9df7e43109e54dc9aeec9e983","value":2}},"98b63e9ba6904bf6829ef0738befc3ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe6298db36f4428a95af9a94da58d50e","placeholder":"​","style":"IPY_MODEL_ef9f3bcf7aa44caaa2d588b854a9277e","value":" 2/2 [00:01&lt;00:00,  1.48s/it]"}},"cc9bd11270c94530831fad19750e1b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c11a887d33c846f888130b17a083f58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccbbb59fff704b57b16bbfef3f1afb56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20d3806e83e743668350d7992db51bdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0741d8e9df7e43109e54dc9aeec9e983":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fe6298db36f4428a95af9a94da58d50e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef9f3bcf7aa44caaa2d588b854a9277e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ea7fc309d0c493bafec1a03914264cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_076278c7e45a4ac4b0f597a71462d568","IPY_MODEL_c207c37ddc7149ffaf8e0bdfb2437e45","IPY_MODEL_d631743977174e95a365b348ead3e74b"],"layout":"IPY_MODEL_1b6c27d329f340bbbcb8249132345a42"}},"076278c7e45a4ac4b0f597a71462d568":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5876370392949a7aaa9df035cfc1e64","placeholder":"​","style":"IPY_MODEL_84303f05754841529f9ae802b68316fa","value":"generation_config.json: 100%"}},"c207c37ddc7149ffaf8e0bdfb2437e45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7fbf55a131247349e2be7d4197a6161","max":137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_383d62cf278342e6825dab7f989c4929","value":137}},"d631743977174e95a365b348ead3e74b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6f4b87a05f7431b8e4a5b8104d6202a","placeholder":"​","style":"IPY_MODEL_4ddef1f7f8b64482ae42746819976c0c","value":" 137/137 [00:00&lt;00:00, 18.0kB/s]"}},"1b6c27d329f340bbbcb8249132345a42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5876370392949a7aaa9df035cfc1e64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84303f05754841529f9ae802b68316fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7fbf55a131247349e2be7d4197a6161":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"383d62cf278342e6825dab7f989c4929":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6f4b87a05f7431b8e4a5b8104d6202a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ddef1f7f8b64482ae42746819976c0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c35d898e1bd44939c4293cdaf49c0de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f21a633265674c46843cefb55dda3689","IPY_MODEL_0af66e17253642958959b1d7974cd5d2","IPY_MODEL_637d9b9097f04237871a9fd6d3119512"],"layout":"IPY_MODEL_b3faecd3c2984ceca759895d5a8b07f3"}},"f21a633265674c46843cefb55dda3689":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e85aba775a51485da7786fa6a7963642","placeholder":"​","style":"IPY_MODEL_42a201eb911c4ca8b64dc0cb6eb9ff16","value":"Loading checkpoint shards: 100%"}},"0af66e17253642958959b1d7974cd5d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05c92b79a49e4a768b00fbf252a25c0b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f9bb0cac65f4f879a062cedb69f6550","value":2}},"637d9b9097f04237871a9fd6d3119512":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf3434e522ba4e13a27f217a31ef6e3a","placeholder":"​","style":"IPY_MODEL_08340fd705384a6ba78bebf7c45ba8ff","value":" 2/2 [00:01&lt;00:00,  1.61s/it]"}},"b3faecd3c2984ceca759895d5a8b07f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e85aba775a51485da7786fa6a7963642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42a201eb911c4ca8b64dc0cb6eb9ff16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05c92b79a49e4a768b00fbf252a25c0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f9bb0cac65f4f879a062cedb69f6550":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf3434e522ba4e13a27f217a31ef6e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08340fd705384a6ba78bebf7c45ba8ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d3e75825ced4e1e811a7fb96f24ddcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_602382f40c6d4407b9cf02f6b7373325","IPY_MODEL_18e0f9afd5344da2be1bf9ce5ce689f8","IPY_MODEL_ba06836a71e94b709bea2e564b73de8b"],"layout":"IPY_MODEL_465246d8ef3e45d6b6649773e87559a0"}},"602382f40c6d4407b9cf02f6b7373325":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf1d84f1fa594868ba9e29d95884ca51","placeholder":"​","style":"IPY_MODEL_a5c1588cd3f34ba5a532b12f912a85f0","value":"model.safetensors: 100%"}},"18e0f9afd5344da2be1bf9ce5ce689f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_787311b2ada44fe4b954ae5707cdf32d","max":2071334097,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3850a3ad05234498a002af62defdfb8a","value":2071334097}},"ba06836a71e94b709bea2e564b73de8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6d6c9f899f44e7380a1985319c92b90","placeholder":"​","style":"IPY_MODEL_6578c955a3e94e28ace5caea3c77c77e","value":" 2.07G/2.07G [00:07&lt;00:00, 320MB/s]"}},"465246d8ef3e45d6b6649773e87559a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf1d84f1fa594868ba9e29d95884ca51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c1588cd3f34ba5a532b12f912a85f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"787311b2ada44fe4b954ae5707cdf32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3850a3ad05234498a002af62defdfb8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6d6c9f899f44e7380a1985319c92b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6578c955a3e94e28ace5caea3c77c77e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5857b8f550724772bb23359fd231b17f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03b8e31dd84c4d34895ecadb6a381490","IPY_MODEL_61e4f681189c401e855bb6a602232ce5","IPY_MODEL_57e32f87c53047b39acc9c711da11608"],"layout":"IPY_MODEL_b9bd7d2f2f3e4137815542ac5e5d9d7e"}},"03b8e31dd84c4d34895ecadb6a381490":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84bf8adcb7404de6ac9e1aa09dd8270d","placeholder":"​","style":"IPY_MODEL_22d26f1db41b414b942e5e3aad38092a","value":"generation_config.json: 100%"}},"61e4f681189c401e855bb6a602232ce5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_891a3f6056bf4b0a93a4321fcee78ee5","max":154,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8333504dda54bf18a5d690454bc6c18","value":154}},"57e32f87c53047b39acc9c711da11608":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf4425c8a69a41c9af896bf28e10afeb","placeholder":"​","style":"IPY_MODEL_2bd3412456ef42d68af35bc3a39613dd","value":" 154/154 [00:00&lt;00:00, 19.7kB/s]"}},"b9bd7d2f2f3e4137815542ac5e5d9d7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84bf8adcb7404de6ac9e1aa09dd8270d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22d26f1db41b414b942e5e3aad38092a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"891a3f6056bf4b0a93a4321fcee78ee5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8333504dda54bf18a5d690454bc6c18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf4425c8a69a41c9af896bf28e10afeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bd3412456ef42d68af35bc3a39613dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}