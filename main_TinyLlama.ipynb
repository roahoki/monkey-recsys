{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "205c6de8",
      "metadata": {
        "id": "205c6de8"
      },
      "source": [
        "# Propuesta de proyecto: Uso de muestreo repetitivo para mejorar el rendimiento de una LLM en recomendación conversacional"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G91y3WGR8JVS",
      "metadata": {
        "id": "G91y3WGR8JVS"
      },
      "source": [
        "Este notebook asume que se está ejecutando en Google Colab, y que el dataset `LLM-Redial` disponible en https://drive.google.com/drive/folders/1TIP4PFm9z0C4R4--KnHoWuiB1uK-dv5m se encuentra descargado en el drive del usuario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Zpy6FRKqFfjT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpy6FRKqFfjT",
        "outputId": "a49a9299-6899-4368-deb3-2a24e1d15e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "uop1TotjGGPP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uop1TotjGGPP",
        "outputId": "adfad4d9-cce9-4abc-aa38-6eaa291585fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Tools.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "source_path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/Tools.py'\n",
        "destination_path = '/content/Tools.py'\n",
        "\n",
        "shutil.copy(source_path, destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Xs5gDWtwGbge",
      "metadata": {
        "id": "Xs5gDWtwGbge"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/LLM_Redial.zip'\n",
        "extract_path = '/content/LLM_Redial'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "kxJXGpWdomUL",
      "metadata": {
        "id": "kxJXGpWdomUL"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "try:\n",
        "    dill.load_session('/content/gdrive/MyDrive/Proyecto LLMonkeys/sessions/TinyLlama/TinyLlama_notebook_env.db')\n",
        "except FileNotFoundError:\n",
        "    print(\"El archivo no existe\")\n",
        "except dill.UnpicklingError:\n",
        "    print(\"Archivo no válido\")\n",
        "except EOFError:\n",
        "    print('EOFError')\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "495d7471",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "d22992f3800a4bf292381d88ae0983f7",
            "6bafa869a0b743639698de4b15355129",
            "c552dab192514e5b82d736b6b198341a",
            "87fb46dc134d42849dae6058b8364a69",
            "d69220dbc8d94b008596396ba2724543",
            "4c5c05ab3c404eb9a3c31675c35db881",
            "bd7732db69eb496a9b7cfe56108fb715",
            "2e219922291c46fa9b2f43e76e9b8fb6",
            "108f1486713c4df9944ac375f6b6d7bb",
            "0396cf2d2c6f407ca2780d7d668b9b12",
            "7523b7928dae4f6f883d8e329998461b",
            "256339e2bc3f4946bbe404ede4a61531",
            "81e6f25f72434aceb7683844698dc1e2",
            "2151948aa2fb4d49b9901178892d406c",
            "6ca1bf148a534274921bb7a4e2c95bcb",
            "e44cd19e39e548e38bb81506d6d04049",
            "91a14b04666f45db8c32e5d36e506371",
            "405c1affea274673b80c0feff11c0aa9",
            "e97442d3d21747a7a408f1c6d1d1bd69",
            "dfda19a2e9444a988c2c20816d81c7fd",
            "73fe5c06c2c24d8e8c31dfdf3c4bbfd5",
            "0f8a1dbf840d445d9fa0130336fba93f",
            "33b9d54fae76499f8079fe8566f3b2df",
            "536777284de3457c92087e79bfed57d1",
            "c6206456674c4033b8464ca420d2677f",
            "80d6ac94fff84190bc0dbd003b146e56",
            "f334a3640ef04481941cdb5ac609bac3",
            "f3d0d7f250e8415b9ef112216e057263",
            "a6069265f5144019a093e331d0104cec",
            "27a3e82bc8c04b8a836d57d017da369e",
            "c381e29f55974e5b9a6f24d0d11cf63a",
            "e08ceedd9bbb4a91b1bcb7183092e4dd",
            "2ccc72f6e2964c359e1c156c92ff4003",
            "8a96dadaae0e4ade8859b14f9104b1dc",
            "1314441608154e788f6cfa08df192d12",
            "b1e5e0b744274421bcb22415b622148c",
            "cbd9a093a84a443db2c9105bd7f13931",
            "dd0d5eef698544daa50cb41f31f17a9c",
            "99254525fcdf4473b34534ae7c88394b",
            "77a03fd46332459db319b51fe7db8e2c",
            "d3f8c688f4a945c3ab9d55a25f46301a",
            "7fbaddbb3acc4b5cb01e236facd74dbd",
            "6bbd296aead1487590f91827c40771c7",
            "eb231b054f9649bbbefcf74887a18d7a"
          ]
        },
        "id": "495d7471",
        "outputId": "a3baa14d-7e5c-4c21-ca94-70d192674735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d22992f3800a4bf292381d88ae0983f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "256339e2bc3f4946bbe404ede4a61531"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b9d54fae76499f8079fe8566f3b2df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a96dadaae0e4ade8859b14f9104b1dc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c9f178ea",
      "metadata": {
        "id": "c9f178ea"
      },
      "outputs": [],
      "source": [
        "import Tools as t\n",
        "\n",
        "path = \"./LLM_Redial/Movie\"\n",
        "final_data_path = '{}/final_data.jsonl'.format(path)\n",
        "Conversation_path = '{}/Conversation.txt'.format(path)\n",
        "user_map_path = '{}/user_ids.json'.format(path)\n",
        "item_map_path = '{}/item_map.json'.format(path)\n",
        "\n",
        "final_data = t.read_jsonl(final_data_path)\n",
        "user_map = t.read_json(user_map_path)\n",
        "item_map = t.read_json(item_map_path)\n",
        "Conversation = t.read_dialogue(Conversation_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para limpiar el entorno y guardar las variables relevantes"
      ],
      "metadata": {
        "id": "tbkknIrVmsd_"
      },
      "id": "tbkknIrVmsd_"
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "import dill\n",
        "\n",
        "def cleanup_for_dill_serialization():\n",
        "    \"\"\"\n",
        "    Limpia todas las variables pesadas que pueden causar problemas con dill\n",
        "    Mantiene solo los outputs y variables esenciales\n",
        "    \"\"\"\n",
        "    # Variables que debes eliminar ANTES de dill.dump_session()\n",
        "    variables_to_delete = [\n",
        "        'model', 'base_model', 'config', 'pipe',\n",
        "\n",
        "        # Tensores y objetos de PyTorch\n",
        "        'inputs', 'output_ids', 'outputs',\n",
        "\n",
        "        # Variables temporales del loop\n",
        "        'decoded', 'prompt', 'messages', 'ctx', 'msg',\n",
        "\n",
        "        # Indices y variables de control\n",
        "        'i', 'n', 'k',\n",
        "    ]\n",
        "\n",
        "    # Lista de variables que SÍ quieres mantener\n",
        "    variables_to_keep = [\n",
        "        'item_map',\n",
        "        'Conversation',\n",
        "        'model_name',\n",
        "        'output_r'\n",
        "        'outputs_mp'\n",
        "        'outputs_z_s',\n",
        "        'outputs_f_s',\n",
        "        'outputs_ft_s',\n",
        "        'outputs_z_n',\n",
        "        'outputs_f_n',\n",
        "        'outputs_ft_n',\n",
        "        'rand_conversations',\n",
        "        'num_test_items',\n",
        "        'train_conv',\n",
        "        'test_conv',\n",
        "        'few_shot_users',\n",
        "        'num_test_items',\n",
        "        'few_shot_data'\n",
        "    ]\n",
        "\n",
        "    # Obtener todas las variables globales\n",
        "    global_vars = list(globals().keys())\n",
        "\n",
        "    # Eliminar variables específicamente problemáticas\n",
        "    for var_name in variables_to_delete:\n",
        "        if var_name in globals():\n",
        "            print(f\"   ├── Eliminando: {var_name}\")\n",
        "            try:\n",
        "                del globals()[var_name]\n",
        "            except:\n",
        "                print(f\"No se pudo eliminar {var_name}\")\n",
        "\n",
        "    vars_to_remove = []\n",
        "    for var_name in global_vars:\n",
        "        if var_name.startswith('_'):  # Variables privadas\n",
        "            continue\n",
        "\n",
        "        if var_name in variables_to_keep:  # No eliminar variables importantes\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            var_obj = globals().get(var_name)\n",
        "            var_type = str(type(var_obj))\n",
        "\n",
        "            # Detectar objetos problemáticos\n",
        "            problematic_types = [\n",
        "                'transformers',\n",
        "                'peft',\n",
        "                'torch.nn',\n",
        "                'pipeline',\n",
        "                'PreTrainedModel',\n",
        "                'PreTrainedTokenizer',\n",
        "                'PeftModel',\n",
        "                'Tensor'\n",
        "            ]\n",
        "\n",
        "            if any(prob_type in var_type for prob_type in problematic_types):\n",
        "                vars_to_remove.append(var_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            vars_to_remove.append(var_name)\n",
        "\n",
        "    # Eliminar variables problemáticas detectadas\n",
        "    for var_name in vars_to_remove:\n",
        "        print(f\"   ├── Eliminando: {var_name}\")\n",
        "        try:\n",
        "            del globals()[var_name]\n",
        "        except:\n",
        "            print(f\"No se pudo eliminar: {var_name}\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Verificar tamaño de variables mantenidas\n",
        "    print(\"\\n📊 Variables mantenidas:\")\n",
        "    for var_name in variables_to_keep:\n",
        "        if var_name in globals():\n",
        "            var_obj = globals()[var_name]\n",
        "            try:\n",
        "                if hasattr(var_obj, '__len__'):\n",
        "                    print(f\"   ├── {var_name}: {len(var_obj)} elementos\")\n",
        "                else:\n",
        "                    print(f\"   ├── {var_name}: {type(var_obj)}\")\n",
        "            except:\n",
        "                print(f\"   ├── {var_name}: (no se puede medir)\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# FUNCIÓN PRINCIPAL PARA TU CASO\n",
        "def cleanup_after_lora_generation():\n",
        "    \"\"\"\n",
        "    Limpieza específica después de generar con modelo LoRA\n",
        "    \"\"\"\n",
        "    print(\"🎯 Limpieza específica para modelo LoRA...\")\n",
        "\n",
        "    # Variables específicas de tu código LoRA\n",
        "    lora_specific_vars = [\n",
        "        'peft_model_path',\n",
        "        'config',           # PeftConfig\n",
        "        'base_model',       # Modelo base\n",
        "        'model',           # PeftModel final\n",
        "        'tokenizer',       # Tokenizer\n",
        "        'pipe',           # Pipeline\n",
        "        'inputs',          # Tensors de input\n",
        "        'output_ids',      # Tensors de output IDs\n",
        "        'prompt',          # Prompt generado\n",
        "        'messages',        # Mensajes del chat template\n",
        "        'ctx',            # Context string\n",
        "        'msg',            # Message string\n",
        "        'decoded',        # String decodificado\n",
        "        'outputs',        # Lista temporal (no outputs_ft_s)\n",
        "    ]\n",
        "\n",
        "    for var_name in lora_specific_vars:\n",
        "        if var_name in globals():\n",
        "            print(f\"   ├── Eliminando: {var_name}\")\n",
        "            try:\n",
        "                del globals()[var_name]\n",
        "            except Exception as e:\n",
        "                print(f\"   │   └── Error: {e}\")\n",
        "\n",
        "    # Limpieza general\n",
        "    cleanup_for_dill_serialization()\n",
        "\n",
        "def limpiar_y_guardar():\n",
        "  cleanup_after_lora_generation()\n",
        "  path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/sessions/TinyLlama/TinyLlama_notebook_env.db'\n",
        "  with open(path, 'wb') as f:\n",
        "      dill.dump_session(f)"
      ],
      "metadata": {
        "id": "76eC882Smq-8"
      },
      "id": "76eC882Smq-8",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para retornar la respuesta del modelo como una lista de nombres"
      ],
      "metadata": {
        "id": "SZkhMuOgm5eB"
      },
      "id": "SZkhMuOgm5eB"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def format_ans(ans, n):\n",
        "    answer = \"None\"\n",
        "    try:\n",
        "        answer_list = []\n",
        "        current_pos = 0\n",
        "\n",
        "        for j in range(1, n + 1):\n",
        "            # Busca el patrón del número y el inicio del texto\n",
        "            pattern_start = f\"{j}. \"\n",
        "            start_index = ans.find(pattern_start, current_pos)\n",
        "\n",
        "            if start_index == -1:\n",
        "                break  # Si no se encuentra el número, salimos del bucle\n",
        "\n",
        "            start_text = start_index + len(pattern_start)\n",
        "\n",
        "            # Busca el final del texto: el inicio del siguiente número O un \" - \"\n",
        "            next_number_start = ans.find(f\"{j + 1}. \", start_text)\n",
        "            dash_start = ans.find(\" - \", start_text)\n",
        "\n",
        "            end_text = -1\n",
        "\n",
        "            # Determina el final del texto basado en la primera ocurrencia\n",
        "            if next_number_start != -1 and dash_start != -1:\n",
        "                end_text = min(next_number_start, dash_start)\n",
        "            elif next_number_start != -1:\n",
        "                end_text = next_number_start\n",
        "            elif dash_start != -1:\n",
        "                end_text = dash_start\n",
        "            else:\n",
        "                # Si no hay siguiente número ni \" - \", toma hasta el final de la línea o la cadena\n",
        "                end_line = ans.find(\"\\n\", start_text)\n",
        "                if end_line != -1:\n",
        "                    end_text = end_line\n",
        "                else:\n",
        "                    end_text = len(ans)\n",
        "\n",
        "            if end_text == -1: # Si no se encontró un final válido, toma hasta el final de la cadena\n",
        "                end_text = len(ans)\n",
        "\n",
        "            movie_name = ans[start_text:end_text].strip()\n",
        "            answer_list.append(movie_name)\n",
        "            current_pos = end_text # Actualiza la posición para la próxima búsqueda\n",
        "\n",
        "        if not answer_list: # Si no se encontraron películas\n",
        "             return \"Formato de respuesta incorrecto\", i\n",
        "\n",
        "        answer_str = \", \".join([f'{movie}' for movie in answer_list])\n",
        "        answer = f\"{i}. {answer_str}\\n\"\n",
        "        i += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        answer = f\"Error: {e}\"\n",
        "\n",
        "    finally:\n",
        "        pattern = r\"\\(\\d{4}\\)\"\n",
        "        answer_list = [m.replace('\\\"', '') for m in answer_list]\n",
        "        answer_list = [re.sub(pattern, '', m)[:-1] for m in answer_list]\n",
        "        return answer_list"
      ],
      "metadata": {
        "id": "Juqn42WWm4pO"
      },
      "id": "Juqn42WWm4pO",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "14e7c87a",
      "metadata": {
        "id": "14e7c87a"
      },
      "source": [
        "### Separación de diálogos en train y test, cuidando que todas las conversaciones de un usuario en particular se encuentren en sólo train o sólo en test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "93ada744",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ada744",
        "outputId": "8c78efe7-68ae-49f8-a875-84d4a3ca03f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "658 2473 3131 10089\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "path = './LLM_Redial/Movie/final_data.jsonl'\n",
        "\n",
        "with open(path, 'r', encoding='utf-8') as file:\n",
        "    data = [json.loads(line) for line in file]\n",
        "n_conversations = 10089\n",
        "train_len = n_conversations * 0.8\n",
        "test_len = n_conversations * 0.2\n",
        "\n",
        "train_conv = []\n",
        "test_conv = []\n",
        "used_users = []\n",
        "\n",
        "aux = []\n",
        "\n",
        "while len(aux) < test_len:\n",
        "    try:\n",
        "        convs = []\n",
        "        random.seed(42)\n",
        "        user_id = random.choice(list(set(user_map.keys())^set(used_users)))\n",
        "        # print(user_id)\n",
        "        used_users.append(user_id)\n",
        "        user_data = next((item[user_id] for item in data if user_id in item), None)\n",
        "        user_conversations = user_data.get(\"Conversation\", [])\n",
        "        for i in range(len(user_conversations)):\n",
        "            selected_conversation = user_conversations[i]\n",
        "            conversation_details = list(selected_conversation.values())[0]\n",
        "            conversation_id = conversation_details[\"conversation_id\"]\n",
        "            if conversation_id != 10088:\n",
        "                conversation = Conversation[Conversation.index(f\"{conversation_id}\\n\"):Conversation.index(f\"{conversation_id+1}\\n\")]\n",
        "            else:\n",
        "                conversation = Conversation[Conversation.index(f\"{conversation_id}\\n\"):]\n",
        "\n",
        "            convs.append(conversation)\n",
        "            aux.append(conversation)\n",
        "        test_conv.append([user_id,convs])\n",
        "    except ValueError:\n",
        "        print(\"ValueError: \", user_id, f\"{conversation_id}\\n\")\n",
        "\n",
        "for user_id in list(set(user_map.keys()) ^ set(used_users)):\n",
        "    try:\n",
        "        convs = []\n",
        "        user_data = next((item[user_id] for item in data if user_id in item), None)\n",
        "        user_conversations = user_data.get(\"Conversation\", [])\n",
        "        for i in range(len(user_conversations)):\n",
        "            selected_conversation = user_conversations[i]\n",
        "            conversation_details = list(selected_conversation.values())[0]\n",
        "            conversation_id = conversation_details[\"conversation_id\"]\n",
        "            if conversation_id != 10088:\n",
        "                conversation = Conversation[Conversation.index(f\"{conversation_id}\\n\"):Conversation.index(f\"{conversation_id+1}\\n\")]\n",
        "            else:\n",
        "                conversation = Conversation[Conversation.index(f\"{conversation_id}\\n\"):]\n",
        "\n",
        "            convs.append(conversation)\n",
        "        train_conv.append([user_id,convs])\n",
        "    except ValueError:\n",
        "        print(\"ValueError: \", user_id, f\"{conversation_id}\\n\")\n",
        "\n",
        "print(len(test_conv), len(train_conv), len(test_conv) + len(train_conv), n_conversations)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0426f46b",
      "metadata": {
        "id": "0426f46b"
      },
      "source": [
        "### Selección aleatoria de diálogos para testear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "QRWLZzGdRg4g",
      "metadata": {
        "id": "QRWLZzGdRg4g"
      },
      "outputs": [],
      "source": [
        "num_test_items = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "29c1fa03",
      "metadata": {
        "id": "29c1fa03"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "rand_conversations = []\n",
        "for n in range(num_test_items):\n",
        "\n",
        "  random.seed(n)\n",
        "  rand_user = random.choice(test_conv)\n",
        "  user_id = rand_user[0]\n",
        "  user_conversation  = random.choice(rand_user[1])\n",
        "\n",
        "  user_data = next((item[user_id] for item in data if user_id in item), None)\n",
        "  convs = user_data.get(\"Conversation\", [])\n",
        "  for i in range(len(rand_user[1])):\n",
        "    if user_conversation == rand_user[1][i]:\n",
        "      rand_user_conv_id = i\n",
        "  dialog = \"\\n\\n\".join(user_conversation.split(\"\\n\\n\")[1:4])\n",
        "  dialog_id = user_conversation.split(\"\\n\\n\")[0]\n",
        "  dialog_ground_truth = list(convs[rand_user_conv_id].values())[0][\"rec_item\"]\n",
        "  rand_conversations.append([rand_user_conv_id, dialog, user_data, dialog_id, dialog_ground_truth])\n",
        "  # print(user_conversation[user_conversation.index(\"User:\"):-2])\n",
        "  # print(list(convs[rand_user_conv_id].values())[0][\"rec_item\"])\n",
        "  # print(list(convs[rand_user_conv_id].values())[0][\"rec_item\"])\n",
        "  # print(dialog)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agregamos las interacciones históricas a la lista"
      ],
      "metadata": {
        "id": "_JjdzL2crA_D"
      },
      "id": "_JjdzL2crA_D"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "32f884ad",
      "metadata": {
        "id": "32f884ad"
      },
      "outputs": [],
      "source": [
        "for i in range(num_test_items):\n",
        "  user_data = rand_conversations[i][2]\n",
        "  rand_user_interactions = user_data.get(\"history_interaction\", [])\n",
        "  rand_user_interactions = [item_map[m] for m in rand_user_interactions]\n",
        "  rand_conversations[i].append(rand_user_interactions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seleccionamos aleatoriamente los datos de Few shot desde train"
      ],
      "metadata": {
        "id": "lwDqdAOmrEh1"
      },
      "id": "lwDqdAOmrEh1"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fRZjdrKHj0kW",
      "metadata": {
        "id": "fRZjdrKHj0kW"
      },
      "outputs": [],
      "source": [
        "few_shot_data = []\n",
        "random.seed(42)\n",
        "few_shot_users = random.sample(train_conv, 5)\n",
        "\n",
        "for u in few_shot_users:\n",
        "  user_data = next((item[u[0]] for item in data if u[0] in item), None)\n",
        "  user_interactions = user_data.get(\"history_interaction\", [])\n",
        "  user_interactions = [item_map[m] for m in user_interactions]\n",
        "\n",
        "  conversation = min(u[1], key=len)\n",
        "  conversation[conversation.index(\"User:\"):-2]\n",
        "  convs = user_data.get(\"Conversation\", [])\n",
        "  for c in convs:\n",
        "    user_likes = list(c.values())[0][\"user_likes\"]\n",
        "    user_dislikes = list(c.values())[0][\"user_dislikes\"]\n",
        "    recs= list(c.values())[0][\"rec_item\"]\n",
        "\n",
        "    user_likes = [item_map[m] for m in user_likes]\n",
        "    user_dislikes = [item_map[m] for m in user_dislikes]\n",
        "    recs = [item_map[m] for m in recs]\n",
        "  few_shot_data.append({\n",
        "      # \"user_interactions\": user_interactions,\n",
        "      \"conversation\": conversation,\n",
        "      # \"user_likes\": user_likes,\n",
        "      # \"user_dislikes\": user_dislikes,\n",
        "      # \"recs\": recs\n",
        "  })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "guy_SY1wevkC",
      "metadata": {
        "id": "guy_SY1wevkC"
      },
      "source": [
        "# Generación de 10 listas de recomendación de 10 películas en 3 modelos distintos, Random, Most Popular y LLM TinyLlama:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VHy8kbG0RStH",
      "metadata": {
        "id": "VHy8kbG0RStH"
      },
      "source": [
        "## Random:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4xvX3jG2Rexq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvX3jG2Rexq",
        "outputId": "6f8a8db8-f5f8-4c71-a15a-77e5b8f4038b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Into the Abyss', \"TYLER PERRY'S A MADEA CHRISTMAS\", 'The Trip to Italy (original uncut version) [UK import, Region 2 PAL format]', \"We're No Angels VHS\", 'Les Choristes (2004) / The Chorus', 'Person of Interest: Complete Season 1', 'Shaolin Soccer', 'Louise Brooks - Looking for Lulu', 'Tucker &amp; Dale vs. Evil', 'Ken Burns: Prohibition'], [\"We're No Angels VHS\", 'Found', 'Wall Street', 'Return of Frank James VHS', 'Dick VHS', 'Winning Team VHS', 'Big Business VHS', 'The Uninvited', 'Weimar Republic', 'The Curse of the Jade Scorpion VHS'], ['Godsend', 'Ghost Rider: Spirit of Vengeance', 'Conqueror Worm VHS', 'Haywire', 'Scott &amp; Bailey: Season 1 Regions 2 &amp; 4', 'Who Framed Roger Rabbit', 'Autumn in New York VHS', 'Charmed: Season 7', \"Marvin's Room\", 'Okami-san and Her Seven Companions: Complete Collection'], ['The Best of Friends, Vol. 1-2 VHS', 'Teenage Mutant Ninja Turtles: (Teenage Mutant Ninja Turtles / Secret of the Ooze / Turtles in Time / TMNT)', 'Grim VHS', 'The Love Guru', 'I Vitelloni', 'Black Book 2006', 'Old Yeller VHS', 'Empire', 'James and the Giant Peach Walt Disney Pictures Presents  VHS', 'Vincent &amp; Theo'], ['Abraham Lincoln vs Zombies', 'The Ultimate Video Collection', \"April Fool's Day VHS\", 'History of the World Part 1 VHS', 'The Good Thief', 'Legally Blonde 2: Red, White &amp; Blonde', 'Certified Copy', 'Layer Cake', 'Deadgirl', 'The Graduate'], ['Day of the Locust VHS', 'Twice-told Tales', 'Nightmare City', 'Ouija', '9 1/2 Ninjas VHS', \"Another Man's Poison VHS\", \"The Beatles Anthology Collector's Set VHS\", 'Carousel VHS', 'Lark Rise to Candleford: Season 2', 'The Grass Is Greener'], ['Deceived VHS', 'Diary of a Chambermaid', 'Bewitched: Season 1', 'Here Comes Garfield VHS', 'Coyote Ugly', 'Desperado VHS', 'Ordinary People VHS', 'Friday The 13th Four-Pack', 'Christmas Caper', 'WWF Survivor Series 2001: Team WWF vs. Team Alliance - Winner Take All'], ['It Happened Tomorrow VHS', \"The Band's Visit\", 'Dark House', 'Emperor', 'Central Intelligence', 'Hardware VHS', 'Calvary 2014', 'The Fault In Our Stars', 'The Buccaneers VHS', 'Age of Innocence VHS'], ['Virus VHS', 'Hammer Films: The Icons of Suspense Collection (Stop Me Before I Kill! / Cash on Demand / The Snorkel / Maniac / Never Take Candy from a Stranger / and more)', 'Wonder Boys', 'Stealing Harvard VHS', 'Them VHS', 'Odd Man Out', 'Doctor Who - Robots of Death VHS', 'Alexander', 'The River King', 'Salmon Fishing in the Yemen'], ['A Murder of Crows', 'The Phantom of the Opera VHS', 'Ice Age: Dawn of the Dinosaurs', 'Mountain Men VHS', 'Jack the Giant Killer VHS', 'Drive Me Crazy VHS', 'If I Were You', 'Adventures of Milo &amp; Otis VHS', 'Expelled: No Intelligence Allowed', 'Great Race VHS']]\n",
            "[['Prayers for Bobby', 'The Simpsons - The Complete Seventh Season', 'Gaslight VHS', \"Charlie Chan Collection: Volume 3 (Charlie Chan's Secret / Charlie Chan at Monte Carlo / Charlie Chan on Broadway / The Black Camel)\", 'My Old Lady', 'The Three Stooges Collection, Vol. 8: 1955-1959', 'Tomorrow,_When_the_War_Began', 'A Face in the Crowd VHS', 'The Fourth Man VHS', 'The Texas Chain Saw Massacre'], ['Murder My Sweet VHS', 'Marley', 'The Land That Time Forgot', 'Shirley Temple: Littlest Rebel VHS', 'Take Me Home', 'Defiled, The: We Are All Meat', 'Disney Sing Along Songs: Friend Like Me: Volume Eleven VHS', 'Altitude', 'Justice League: Season 1', 'Universal Soldier: The Return'], ['Bad Girls VHS', \"Colosseum - A Gladiator's Story/Pompeii - The Last Day\", 'Titan A.E. VHS', 'Poltergeist', 'The Bitter Tears of Petra Von Kant VHS', 'Stone Cold', 'The Beautiful Country', 'Evil Dead VHS', 'Demons 2 - The Nightmare Returns', '4 Movie Marathon: Classic Western Collection (Albuquerque / Whispering Smith / The Duel at Silver Creek / War Arrow)'], ['We Are Marshall', 'Columbo: The Complete Sixth &amp; Seventh Seasons', 'Only the Strong VHS', 'Battle of Los Angeles', 'The Great American Songbook', \"Kelly's Heroes / Movie VHS\", 'A Simple Plan', 'Kingpin VHS', 'Cirque Du Soleil: Worlds Away', '24: Live Another Day 2014'], ['Caligula VHS', 'Mammoth', \"Rambo: The Complete Collector's Set\", 'Superman - The Last Son of Krypton VHS', 'The Informer VHS', 'Trouble with the Curve', 'South Park - The Complete First Season', 'Universal Soldier: The Return', 'West of Memphis', 'Hero'], ['Batman: Bad Blood', ' Juana De Arco (Joan of Art)', 'Sand Sharks [Region 2]', 'Electric Dreams VHS', 'Vera - Series 4', 'Champ VHS', 'Cousins VHS', 'A Night at the Roxbury VHS', 'Holiday in Handcuffs', 'Pitch Perfect'], ['Salaam Bombay VHS', 'Welcome to Me', 'North of Hell', 'Dr. Giggles VHS', 'Tortilla Soup', 'The Pit and The Pendulum VHS', 'Ichi the Killer', 'Horror Express', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Wilby Wonderful'], ['Black Sheep', '1408 Full Screen Edition', 'George Carlin - Life Is Worth Losing', 'Millennium - The Complete First Season', 'Rollerball VHS', 'Bitter Moon VHS', 'Born Yesterday VHS', 'The Gingerdead Man', 'Winged Migration', 'The Women VHS'], ['The Special Edition CLOSE ENCOUNTERS OF THE THIRD KIND Deluxe Widescreen Presentation Laserdisc (LD NOT DVD)', 'Heathers VHS', 'In the Realm of the Senses', 'The Sound of Music Live!', 'Digging Up the Marrow', \"Coal Miner's Daughter VHS\", 'The Englishman Who Went Up a Hill VHS', 'Masterpiece Theatre: Elizabeth I - The Virgin Queen', 'Will &amp; Grace - Season One', 'Never Back Down'], ['To Kill a Mockingbird', 'Coriolanus', 'Spider Forest', 'What Maisie Knew', 'Children Of The Corn: Genesis', 'The Legend of Lizzie Borden', 'Asylum', '9 Songs', 'The Outer Limits - The Original Series, Season 2', 'Another Thin Man VHS']]\n",
            "[['Mindhunters', 'Harry Potter and the Prisoner of Azkaban', 'Adventureland', 'Django Unchained', 'Milk Money VHS', 'Looney Tunes Super Stars: Pep&eacute; Le Pew - Zee Best of Zee Best', 'The Magnificent Seven VHS', 'Hollow Man', 'Knife in the Water VHS', 'Joint Security Area'], [\"Santa's Slay\", 'Doctor Who - Black Orchid anglais', 'Beat the Devil', 'A Brilliant Young Mind', 'Boogeymen - The Killer Compilation VHS', 'Proof of Life', \"Rodgers &amp; Hammerstein's Cinderella VHS\", 'Mystery Science Theater 3000: Shorts 2/Catalina Caper/Skydivers VHS', 'Crazies VHS', 'Resident Evil - Apocalypse'], ['The Adventures of Sherlock Holmes', 'The Mirror VHS', 'Micki &amp; Maude VHS', 'Midsomer Murders - Set 21', 'All Superheroes Must Die', 'The Tudors: Season 3', 'WWE: Wrestlemania XX VHS', 'Footnote', 'Far Country VHS', 'Soul Eater: The Meister Collection'], ['Sniper: Reloaded', '22 Bullets', 'You Kill Me', 'Versus', 'Sherlock Holmes - Pursuit to Algiers VHS', 'Animaniacs: Vol. 1 (DVD)', 'Columbo: The Complete Sixth &amp; Seventh Seasons', 'Mississippi Grind Digital', '2010: The Year We Make Contact VHS', 'Uhf VHS'], ['Pieces of April', 'Pure Luck VHS', 'Sleuth', 'Midsomer Murders: Set Ten (Second Sight / Hidden Depths / Sauce for the Goose / Midsomer Rhapsody)', \"Oss 117 - Le Caire, Nid d'Espions\", 'ER: Season 2', 'Grisbi VHS', 'Route 66 - Season 1, Vol. 1', 'Friends: Season 6', 'Dylan Dog: Dead of Night'], ['The Last Kiss', 'The IT Crowd - Series 1 [Non-US Format, PAL, Region 2, Import]', 'Freaks of Nature', 'Big Heat VHS', 'Deathwatch', 'The Enforcer VHS', 'A Thief of Time', 'The Anniversary VHS', 'Beautiful Boy', 'Mad Men: Season 1'], ['Splinter', 'Sands Of Oblivion', 'No Good Deed [DVD]', 'Cronos Subtitled  VHS', 'Weeds: Season 3', 'Bones', ' The Mentalist', 'Bigger Than Life', 'Blood &amp; Sand VHS', 'An Affair of Love'], ['Undisputed VHS', 'The Giant Behemoth VHS', 'Black or White', \"OCEAN'S TWELVE (WS) (DVD)\", ' CJ7', 'Strictly Ballroom VHS', 'Scrubs - The Complete First Season', 'Vincent &amp; Theo', \"In Harm's Way VHS\", 'Caligula VHS'], [\"Don't Be Afraid of the Dark\", 'Plunder Road VHS', 'Day Watch / Dnevnoy Dozor - (PAL/R5 - Russian Import)', 'Lost Horizon (1973)', 'End of the Line', 'Friends - The Complete First Season VHS', 'Get Low', 'Walking Tall', 'Diary of a Wimpy Kid: Dog Days', 'X-Men: First Class'], ['10 Cloverfield Lane', 'The Reading Room', 'The Thin Red Line VHS', 'To Be Or Not to Be VHS', 'Pushing Daisies:S1 (DVD)', 'Sparks', 'The Tracey Fragments', 'Miss Meadows', 'Lila &amp; Eve', 'Be Cool VHS']]\n",
            "[['Copper: Season 2', 'The Business of Strangers VHS', 'Dr. Giggles VHS', 'Program VHS', 'The Beaver', 'V: Season 2', 'The Girl with the Dragon Tattoo', 'Carnival of Souls', 'Searching for Bobby Fischer VHS', 'Wendy and Lucy'], ['The Skulls', 'Passchendaele', ' Live In London', \"Alice's Adventures In Wonderland\", 'The Lion King 1 1/2', 'Strike Witches: Season 2', 'Above the Rim VHS', 'Journey Into Fear VHS', '12 MEN OF CHRISTMAS (RENTAL READY)', 'The Polar Express'], ['Ultimate Avengers 2', 'Eyes Wide Open', 'Island of Fire VHS', 'Here Comes the Boom', 'The Raid', 'Remember the Night VHS', 'The Grand Seduction', 'The Twilight Saga: Eclipse', \"Jane Austen's Pride and Prejudice Six Piece Collector's VHS\", 'Great Beauty'], ['Soul Surfer (2011)', 'Terminator Salvation', 'State and Main', 'The Book Thief', 'Inspector Morse: Dead of Jericho VHS', 'Body of Lies', 'Ride Along', 'George Carlin - Life Is Worth Losing', 'Duma', 'Dead Man VHS'], ['Curse of Chucky', 'Ken Burns: The Roosevelts', 'The Scapegoat', 'Kung Fu Panda 2', 'The White Queen - Complete Series The White Queen: Series 1  NON-USA FORMAT, PAL, Reg.2 United Kingdom', 'Prophecy 3: Ascent VHS', 'The Blade Trilogy: (Blade / Blade II / Blade: Trinity)', 'Captain Phillips Steelbook', 'Bio-Dome VHS', 'The Twilight Zone: Season 5'], ['Mr Nobody', 'Now You See Me', 'Sidewalks of New York', 'Meet The Spartans', '24 - Season 4 2005 Keifer Sutherland; William Devane; Kim Raver', 'Antitrust VHS', 'These Final Hours', 'Dr. Seuss: The Lorax', 'Ted Bundy', 'For Multi-titled'], ['Drawn Together: Season 1', 'The Boy in the Striped Pajamas', 'Pushing Tin VHS', 'Encounters at the End of the World', 'The Invention of Lying', 'Bury My Heart at Wounded Knee', 'Reach Me', 'Quatermass And The Pit [DVD] (12)', 'Blink VHS', ' The Merry Gentleman'], ['They Came to Cordura VHS', 'Wonder Woman: S1 (DVD)', 'The Grifters', 'Stalingrad [World War II] [English Subtitles] [2013]', 'The People Vs George Lucas', 'The Beatles - Magical Mystery Tour VHS', 'Children of the Corn VHS', 'Caesar and Cleopatra VHS', 'Family Guy, Volume Five', 'Citizenfour anglais'], ['Ancient Aliens: Season 6, Volume 2', 'Haunter', 'Drag Me To Hell anglais', 'The Purge: Anarchy', 'The Manchurian Candidate', 'Chloe', 'The Desperate Hours', 'G.I. Bro VHS', ' Damages', 'Frankenfish'], ['Max Manus: Man of War', 'Lagaan: Once Upon a Time in India', 'Crimes of Passion VHS', 'Very Bad Things', 'Queen Margot VHS', 'The Silence of the Lambs VHS', 'Save the Tiger VHS', 'Phoebe in Wonderland', 'Dead Birds', 'To Serve Them All My Days Miniseries  VHS']]\n",
            "[['Charlie St. Cloud', 'Transformers 1-3', 'The Head', 'Open City VHS', 'Oldboy', 'Death Note 2: The Last Name', 'Young Tom Edison VHS', 'Journey to the Center of the Earth', 'Cabin Fever 3: Patient Zero', 'Six Feet Under - The Complete Fifth Season'], ['Anna Christie VHS', \"Laura Mckenzie's Travel Tips: New Zealand VHS\", 'Tender Trap VHS', 'Blade:Series (DVD)', 'Conquest of Space', 'Inherent Vice', 'Psych: The Complete Sixth Season', 'True Crime VHS', 'First Power VHS', 'Dear Frankie'], ['The White Balloon VHS', 'Warlock', 'Night of the Demons VHS', 'The Trial of Billy Jack', \"Foyle's War - Series 1 Complete 2002\", 'Hogfather', 'Southern Comfort VHS', 'Life-Size VHS', 'Zoom - Academy for Superheroes', 'The Secret'], ['Spy: Susan Cooper Undercover', 'Terms of Endearment VHS', 'Righteous Kill', 'Buffy &amp; Angel Chronicle Vol 1 VHS', 'Friends: Season 2', 'Leroy &amp; Stitch', 'Musa VHS', 'The Stepford Wives', 'Killdozer [VHS]', 'Final Exam 1981  VHS'], ['A Most Wanted Man', 'No Highway In The Sky VHS', 'Cats &amp; Dogs: The Revenge of Kitty Galore', 'Movies 4 You - Sci Fi Classics (The Man from Planet X / Beyond the Time Barrier / The Time Travelers / The Angry Red Planet)', 'Nochnoy dozor', 'Righteous Kill', 'For Your Consideration', 'The Carson Collection - His Favorite Moments from The Tonight Show 1962-1992  VHS', 'Desperate Housewives: Season 4', 'Spider'], ['40 Pounds of Trouble VHS', 'Johnny Got His Gun VHS', 'The Girl with the Dragon Tattoo', ' Nine', 'Gilda VHS', 'Northern Exposure: The Complete First and Second Seasons', 'Homefront', 'Boa VHS', 'Silk - Season 1 Set Silk - Season One  NON-USA FORMAT, PAL, Reg.2 United Kingdom', 'Never Forever'], ['The Bowery Boys Collection: Volume Three', 'Creepshow 2 VHS', 'Space Camp', 'Monty Python and the Holy Grail', 'Survivor - The Complete First Season', 'Left Behind - World at War', 'Planet of the Vampires', 'Beneath the Darkness', 'Everybody Loves Raymond: Season 7', 'St. Vincent'], ['The Wedding Ringer', 'Chopping Mall VHS', 'Mulan/Mulan II', 'Death Tunnel', 'Battle of the Bulge VHS', 'X-Men: The Phoenix Saga', 'Samurai Jack - The Premiere Movie VHS', 'Ice Princess', 'Major League II VHS', 'Despicable Me'], ['Intruders', 'Control', ' Drillbit Taylor (Unrated Extended Survival Edition)', ' Sanctuary', \"Lorna's Silence [Region 2]\", ' Get Smart Season 2', 'Sleepaway Camp II: Unhappy Campers', '30 Minutes or Less', 'New Tricks: Season 9', 'Morituri VHS'], ['WWE: Bad Blood 2004', 'Doctor Who - Battlefield anglais', 'Adventures of Superman - The Complete Fifth and Sixth Seasons', 'McFarland, USA', 'The Muppet Show: Season 1', 'Surrogates', 'Paul Lynde Halloween Special', 'The Man Without A Face VHS', 'Transformers: Season 1', 'Band of Brothers / The Pacific']]\n",
            "[[\"Mr. Holland's Opus VHS\", 'Forsaking All Others VHS', 'Message in a Bottle VHS', 'Obsession VHS', 'Overnight VHS', 'Summer With Monika', 'Lenny VHS', 'Justice League - The New Frontier', 'The Dark Knight Rises', 'A Little Princess VHS'], ['Wall Street', 'X - The Movie VHS', 'The Greatest American Hero - Season One', 'The Lover VHS', 'Species', 'Laverne &amp; Shirley - The Complete First Season', \"Meek's Cutoff\", 'Wanted Dead or Alive - The Complete Series', 'The Brotherhood of Satan', 'Doctor Who: Frontios'], ['Asylum [VHS]', 'Housesitter', 'East-West', 'Star Trek The Next Generation - The Complete Sixth Season', 'The Grass Is Greener', 'Leap Year', 'Little Women VHS', 'Rocky &amp; Bullwinkle &amp; Friends:  The Complete Series', \"Jason's Lyric VHS\", ' Underworld'], ['Jimmy Neutron - Boy Genius VHS', 'Gone in 60 Seconds', 'The Longest Day VHS', 'The Whole Truth', 'There Was a Crooked Man VHS', 'Wonder Boys', ' Cars 2', 'Clash of the Titans VHS', 'The Haunted World of El Superbeasto', 'Risky Business'], ['WWE: SummerSlam 2002', 'Gammera the Invincible', 'The Lone Ranger - 6 full length episodes', 'Batman vs. Robin', 'Predestination', 'Island of Terror VHS', 'The Classic Sci-Fi Ultimate Collection: Volume 1 &amp; 2', 'Pollyanna VHS', 'Gung Ho VHS', 'Last Will and Testament of Rosalind Leigh'], ['Perfect Blue rated edition  VHS', ' Planet 51', 'She VHS', 'Empire of the Sun', '51 Birch Street', 'The Most Dangerous Man in America: Daniel Ellsberg and the Pentagon Papers', 'The Crazies', 'Object of My Affection VHS', \"Mama's Family: Season 4\", 'WWF: Wrestlemania XII VHS'], ['The Life Before Her Eyes', 'Little Buddha VHS', \"Women's Murder Club\", ' Doctor Who', \"Grindhouse Double Feature: Count Dracula's Great Love / Maneater of Hydra\", 'Bronco Billy Snap Case', 'In the Name Of', 'Dances with Wolves (VHS 8768)', 'Diva VHS', 'The Flower of My Secret'], [\"From Dusk Till Dawn 3: The Hangman's Daughter\", 'Columbo:Murder By the Book VHS', 'Men In Black - La Trilogia (3 Dvd)', 'Another Day in Paradise VHS', 'Jennifer Lopez: The Reel Me', 'Star Trek VI - The Undiscovered Country VHS', 'The Legend of Hercules (Blu-ray)', 'Mute Witness VHS', 'Ribbon Magic VHS', 'The Film Crew: The Giant of Marathon'], ['Crazy/ Beautiful', 'Horsemen', 'The Blob', 'Sex And Death 101', 'Antibodies', 'D.O.A. VHS', 'Black Swan VHS', 'Corrina Corrina VHS', 'Stories We Tell', 'Savannah Smiles'], ['Unbreakable', 'The Dreamers', 'Star Trek - The Original Series, Vol. 4, Episodes 8 &amp; 9: Charlie X/ Balance of Terror', 'Mr. Majestyk VHS', 'Dream House', \"Stephen King's The Stand VHS\", 'CSI: Crime Scene Investigation: Season 3', 'Doctor Who - Kinda VHS', 'Skyfall', 'Kiss of Death VHS']]\n",
            "[['Route 666', 'Submarine', 'Doctor Who: The Next Doctor', 'I Love Lucy - The Complete Fourth Season', 'Magic in the Moonlight', ' Return to Sleepaway Camp', 'The Way of the Gun', 'Bone Tomahawk', 'Battle Beyond the Stars', 'Stories We Tell'], ['Megafault', 'I Walk Alone (1948)', 'In Darkness', \"Razor's Edge VHS\", 'Kentucky Fried Movie', '21 Grams', 'Stoker', 'Night of the Living Dead VHS', 'The New Guy VHS', 'Dallas (2012): S1 (DVD)'], ['Leprechaun 2 VHS', 'The Lion King 1 1/2', 'Mad City', 'Deuce Bigalow: Male Gigolo', 'Icons of Horror Collection: Sam Katzman (The Giant Claw / Creature with the Atom Brain / Zombies of Mora Tau / The Werewolf)', 'Humoresque VHS', 'Spider Baby VHS', 'Digging to China', 'Good Bye Lenin!', 'Joan of Arcadia - The Second Season'], ['Friday Night Lights', 'The King', 'Sushi Girl allemand', 'GUMBALL RALLY (DVD)', 'Collateral', 'Rec', 'Skyjacked VHS', 'The Hedgehog', 'Looking: Season 1', 'The Asphyx 25th Anniversary'], ['Student Bodies VHS', 'Alien Nation - The Complete Series', 'Batman: The Dark Knight Returns - Part 1', 'Your Friends &amp; Neighbors VHS', 'Midnight Game, The', 'My All American', 'Walt Disney Treasures: The Hardy Boys The Mickey Mouse Club 1956-1957', 'Internal Affairs VHS', 'Star Trek Fan Collective - Time Travel', 'Barbershop 2: Back in Business'], ['Blood Feast', 'New World', 'V: Season 2', 'My Soul to Take', 'Doctor Who - Terror of the Autons VHS', \"The ABC's of Death\", 'ParaNorman', ' Ghost Town (Blu-Ray) /BR', 'Radio City Christmas Spectacular', 'Who Framed Roger Rabbit'], ['Spike Lee Joint Collection (Clockers / Jungle Fever / Do the Right Thing / Mo` Better Blues / Crooklyn)', 'Zulu', 'Star Trek VI - The Undiscovered Country VHS', 'Flight of the Conchords: Season 1', 'Music of the Heart VHS', 'Great Lie VHS', 'Night Crossing', 'The Golden Girls: Season 4', 'Diana Vreeland: The Eye Has to Travel', \"King Kong (The Huntsman: Winter's War Fandango Cash Version) [Blu-ray]\"], ['Xena: Warrior Princess - Season 1', 'True Crime VHS', 'Under Fire VHS', 'Charmed: The Complete 5th Season', 'Midnight Express', 'Mannequin &amp; Mannequin 2: On the Move', 'Beautiful Girls VHS', 'Metallica Through the Never', 'Moonlight Mile', 'War of the Arrows'], ['Tale of Tales ( Il racconto dei racconti ) [ NON-USA FORMAT, PAL, Reg.2 Import - Italy ]', 'Lilo &amp; Stitch 2: Stitch Has a Glitch', 'Jesse Stone: Sea Change', 'Safe House', 'Johnson Family Vacation', 'A Walk in the Sun / Go for Broke (Double Feature)', 'DreamWorks Dragons: Gift of the Night Fury', 'Crazy Heart', 'Smothered - The Great Smothers Brothers Censorship Wars VHS', 'Michael Jackson: HIStory: Video Greatest Hits VHS'], ['Versus', 'Planes (Mandarin Chinese Edition)', 'Overnight VHS', 'Farscape', 'Airport 77 VHS', 'Psycho Beach Party', 'Tim', 'Will &amp; Grace - Season Four', \"The Abbott &amp; Costello Show: Who's On First VHS\", 'Mirage VHS']]\n",
            "[['Breakout', ' Rachel Getting Married', 'The Italian', 'Entrapment VHS', 'Wild', 'Haywire', 'Metropolis Moroder version  VHS', 'Rescue Me: Season 2', 'The Muppets', 'The Bela Lugosi Collection: (Murders in the Rue Morgue / The Black Cat / The Raven / The Invisible Ray / Black Friday)'], ['Naked VHS', 'Jeff Dunham: Controlled Chaos', 'The Eagle', 'Lawless Street VHS', 'The Water Diviner 2015', 'True Lies VHS', 'The Brady Bunch Movie VHS', 'Attack on Titan: Part 1', 'It Takes a Thief Magnificent Thief  VHS', 'Wake Wood'], ['Tarzan the Ape Man VHS', 'Buffy the Vampire Slayer - The Complete Seventh Season', \"Pan's Labyrinth - Limited Edition Mondo X Steelbook [Blu-ray - DVD]\", 'Chinaman [Region 2]', 'Terror of Mechagodzilla', 'I Want to Live VHS', '55 Days at Peking VHS', 'Survivor', 'Profiler - Season One', 'Bloody Reunion'], ['Mystic Pizza VHS', 'Some Guy Who Kills People', ' Hunger [Region 2]', 'A Cry in the Dark', 'Untamed', 'Community: Season 1', 'Filth (2013) [ NON-USA FORMAT, PAL, Reg.2 Import - United Kingdom ]', 'Safe Conduct', 'Hostel', 'Castle of Cagliostro VHS'], ['The Island President', ' Place of Execution', 'Under the Tuscan Sun VHS', 'King David VHS', 'Screwed', 'South Park: Season 3', 'Mark of the Devil VHS', 'Paul McCartney: Back in the U.S. - Live 2002 Concert Film', \"Miracle at Christmas: Ebbie's Story\", 'The Long Good Friday VHS'], ['The Way, Way Back', 'Poltergeist II / Poltergeist III', 'The Dark Valley', 'Boy A', 'Mongol: The Early Years of Genghis Khan', 'Wyvern: Maneater Series', 'Atlas Shrugged II: The Strike', 'Bones', 'Here on Earth VHS', 'Sleepaway Camp II: Unhappy Campers'], ['Teen Witch VHS', 'Ticks VHS', 'Johnny Tremain VHS', 'The Simple Life of Noah Dearborn VHS', 'Batman:Mask of the Phantasm Spanish Edition  VHS', 'Conrack VHS', 'Walking With Dinosaurs', 'Micmacs', 'All in the Family : Season 3', 'Son Of No One, The'], ['The Mothman Prophecies', 'Rise: Blood Hunter', 'Freedomland', 'A Simple Plan', 'Powder VHS', 'Vincent &amp; Theo', 'Family Ties: Season 3', 'Avanti VHS', \"Dave Chappelle: Killin' Them Softly\", \"Troy: Director's Cut\"], ['Anaconda 3: Offspring', 'Just Shoot Me - Seasons One and Two', 'Tully', 'Being Human: Season 1', 'Eye of the Beholder VHS', 'Incendies', 'The Last Mimzy', 'El Mariachi / Desperado', 'The Sisterhood of the Traveling Pants 2', 'The Natural VHS'], ['My Name is Nobody (1973) ( Il Mio nome &egrave; Nessuno )', 'Requiem for a Dream Unrated Edition  VHS', 'The Little Rascals Collection', 'Here Comes the Boom', 'Zorro VHS', 'Bubbe Meises Bubbe Stories VHS', 'Scars of Dracula VHS', 'Alice in Chains - Music Bank - The Videos', 'Charlie Countryman', 'Legend Of The Fist: The Return of Chen Zhen [2010, HK] [EcoPac] DVD']]\n",
            "[[\"George Carlin: It's Bad For Ya\", 'Attack of the Puppet People VHS', 'His Girl Friday', 'Gacy', 'Popeye The Sailor: 1933-1938: The Complete First Volume', 'Snow White &amp; Three Stooges VHS', 'Young Winston VHS', 'Lizzie Borden', 'P2 Theatrical Release', 'DEEP SEA IMAX (DVD)'], ['Eye of the Beast: Maneater Series', 'Witch Hunter Robin: Arrival - Volume 1', 'The Sound of Music', 'Dead Space: Downfall', 'Like It Is VHS', 'Only the Strong VHS', 'Hood of the Living Dead', 'The Bible - Jeremiah VHS', 'Snows of Kilimanjaro VHS', 'Leroy &amp; Stitch'], ['Keeping Up Appearances: The Full Bouquet', 'The Deliberate Stranger VHS', 'Kicking &amp; Screaming', 'Crossing Guard VHS', 'INTO GREAT SILENCE/LE GRAND SILENCE', 'Monsieur Ibrahim', 'Bewitched: Season 3', 'My Week with Marilyn', 'Gnomeo &amp; Juliet', 'Henry: Portrait of a Serial Killer'], ['Mephisto anglais', 'Uncle Nino', 'Marley', 'Batman Begins', 'Earth Vs the Spider VHS', 'Dungeons and Dragons: Wrath of the Dragon God', 'The Visitant', 'Nitro Girls Swimsuit Calendar Special VHS', '45 Years 2015', 'Mr Turner 2014'], ['Humanoids From The Deep VHS', ' Life (David Attenborough-Narrated Version) [Blu-ray] (2010) (Region Free)', 'Chris Rock - Bigger and Blacker VHS', 'Brass Bottle VHS', 'The Rules of the Game VHS', 'London Spy - Series 1 2015', 'Grosse Pointe Blank', 'Vol. 2', 'Inferno VHS', 'Madagascar'], ['It Takes Two VHS', 'The Game', 'Ministry of Fear', 'Dolly Dearest VHS', 'Honey I Blew Up the Kid Clamshell Case  VHS', 'Death Takes a Holiday VHS', 'The Melody of Oblivion: Monotone', 'Satan Bug VHS', 'The Shakiest Gun in the West VHS', 'One For the Money'], ['The Code', 'Outlander: Season One - Volume Two', 'Arrow anglais', 'TCM Archives: Forbidden Hollywood Collection - Volume One (Waterloo Bridge / Baby Face / Red-Headed Woman)', 'The Anniversary VHS', 'Argo', 'Arrested Development: Season 3', 'Strictly Ballroom VHS', 'Near Death', 'A Place to Call Home, Season 1'], ['In the Bedroom VHS', 'The Purge', 'Deja Vu', 'Digging to China', 'Dahmer VHS', 'Superman/Shazam!: The Return of Black Adam', 'The Stepfather', 'The Human Stain', 'Futurama: Volume Four', 'Micki &amp; Maude VHS'], ['Norma Rae VHS', 'Bad Words', 'The Outer Limits', 'Rise: Blood Hunter', 'The Place Promised in Our Early Days', 'The Last Days of Disco VHS', 'The Hunger Games: Mockingjay Part 1 2015', 'Yes Man', 'The Tourist', 'Under Siege 2: Dark Territory&quot; in Spanish  VHS'], ['El Bola', '30 Days of Night: Dark Days', 'Alvin and the Chipmunks: Chipwrecked Family Icons', 'Election', 'Long Ships VHS', 'American Pie - The Naked Mile', 'Honeymooners 2005  Full Chk Honeymooners 2005  Full Chk', ' Wild River [Region 2]', 'The Last Kiss', 'The Beatles - Magical Mystery Tour VHS']]\n",
            "[['Kid Galahad VHS', 'True Detective', 'TCM Greatest Classic Films Collection: John Wayne Westerns (The Cowboys / Fort Apache / Rio Bravo / The Searchers)', 'Lockout', 'The Flying Serpent', 'Game Change', 'Creature from the Black Lagoon', 'Radio City Christmas Spectacular', 'Cypher', 'The Rutles - All You Need is Cash VHS'], ['The Last Kiss', 'The Matrix Revolutions', 'Sling Blade VHS', 'The Bitter Tears of Petra Von Kant VHS', 'Voyage to the Bottom of the Sea / Fantastic Voyage', 'Cranes Are Flying VHS', 'J&eacute;sus de Montr&eacute;al VHS', 'Little Rascals VHS', 'Doctor Who - Planet of the Daleks VHS', '10,000 B.C.'], ['The Monster Legacy Gift Set: (Frankenstein / Dracula / The Wolf Man)', 'The Stepford Wives VHS', \"Man's Favorite Sport VHS\", 'Mystery Science Theater 3000 - Cave Dwellers VHS', 'The Cary Grant Boxed Set: (Holiday / Only Angels Have Wings / The Talk of the Town / His Girl Friday / The Awful Truth)', 'Black Sabbath VHS', 'The Way Back', 'The Emerald Forest', 'Tootsie VHS', 'Shattered Glass'], ['Farce Of The Penguins (Ff)', \"Hart's War\", 'Killing Zoe VHS', 'Barbershop 2: Back in Business', 'Walt Disney Treasures - The Complete Pluto, Volume One', 'Flawless VHS', 'The Princess and the Warrior', '&quot;Love Is All You Need?&quot; Short Film - Theatrical Version', 'Crunch Yoga Mama/Baby Songs Favorites VHS', 'Doctor Who - Battlefield anglais'], [' Journey to the Center of the Earth', 'The Best of Friends, Vol. 1-2 VHS', \"Employees' Entrance Forbidden Hollywood  VHS\", '7 Below', 'First Kid VHS', 'Silent Night, Bloody Night', 'The Gorilla Bela Lugosi', 'Never Back Down', 'Infinite Stratos Complete Collection', 'Tool Box Murders'], ['Super 8', 'The East', \"Everybody's Fine\", ' Doctor Who', 'Kim VHS', 'The Simple Life of Noah Dearborn VHS', 'The Bible - Solomon', 'Science Fiction Theatre', 'Whip It', \"It's Alive\"], ['Five Graves to Cairo VHS', 'House of Cards: Season 2', 'Austin Powers: International Man of Mystery/The Spy Who Shagged Me/Goldmember', 'Shock', 'Black Rock Digital', 'What Price Glory VHS', 'The Special Edition CLOSE ENCOUNTERS OF THE THIRD KIND Deluxe Widescreen Presentation Laserdisc (LD NOT DVD)', 'Dawn of the Dead VHS', 'Broken Flowers', 'Babylon 5: The Lost Tales'], [\"NAT'L  LAMPOONS CHRISTMAS VACATION 2 (DV\", 'The Hunchback of Notre Dame / The Hunchback of Notre Dame II', 'The Man From Snowy River VHS', 'Ghost Rider: Spirit of Vengeance', 'Skyline', 'Sex Drive Unrated', \"Dr. Terror's House of Horrors\", 'The Special Relationship', 'Deadline', 'The Story of G.I. Joe'], ['The Last Brickmaker in America', 'Ex Machina 2015', 'Crawling Eye VHS', 'The Cure VHS', 'Imaginary Witness: Hollywood and the Holocaust', 'Christmas Story ( Joulutarina ) ( En Julber&auml;ttelse ) [ NON-USA FORMAT, PAL, Reg.2 Import - Finland ]', 'The Best of Times', 'Kung Fu: The Complete Series Collection', 'The Samurai Trilogy VHS', 'Get Smart Season 3'], ['Scooby-Doo! Camp Scare', \"Miller's Crossing VHS\", 'Blue Thunder', 'Protocol', 'Terror Trap', \"Bridget Jones's Diary\", 'City of God', 'Gentlemen Broncos', 'Crimes of Passion VHS', ' The Mentalist']]\n",
            "[['Life in the Undergrowth', 'Cabin Fever Region 2', 'Rififi', 'Save the Tiger VHS', 'War of the Worlds 2: The Next Wave', \"You Can't Do That on Television\", 'White VHS', 'Dear Zachary: A Letter to a Son About His Father', 'Antichrist', 'The High and the Mighty'], ['King David VHS', 'The Eyes of Tammy Faye', 'Wrangler: Anatomy of an Icon', 'Music and Lyrics', 'Alone in the Dark', 'Gran Torino', 'Snow White &amp; the Huntsman', ' Year One (Theatrical &amp; Unrated Edition)', 'Mr. Deeds Goes to Town', 'A Taste of Romance'], ['Boomerang VHS', 'Shivers', 'Bandits', 'Silk', \"A Bug's Life\", 'Psych: The Complete First Season', 'The X-Files - The Complete Seasons 1-9', 'Star Trek: Nemesis', 'Classic Film Noir (The Man Who Cheated Himself / The Hitchhiker / Detour / D.O.A / Too Late for Tears / and more)', 'Dangerous Crossing'], ['Last Chance Harvey', \"Mr. Moto's Last Warning VHS\", 'Star Wars: Episode III - Revenge of the Sith (Mandarin Chinese Edition)', ' Moola', ' Damages', 'The Rocker', '24 - Season 7 2009 Kiefer Sutherland; Cherry Jones', 'Cowboys &amp; Aliens', 'Night of the Demons VHS', 'Oldboy'], ['The Giant Behemoth VHS', \"Walt Disney's Classic The Jungle Book Clamshell\", 'Hell in the Pacific VHS', 'Come Back, Little Sheba', 'Decoys [DVD] (2005) DVD', 'Bitter Moon VHS', 'Unfriended', \"One Night at McCool's\", 'Major League II VHS', 'Rush VHS'], ['Saturday Night Live - The Best of Chris Farley VHS', 'A Double Life', 'Night Shift VHS', 'Katyn Aka Post mortem', 'Extras: The Complete Series', 'Evil Dead VHS', 'Octopussy VHS', 'Scooby Doo Wrestlemania anglais', 'How to Marry a Millionaire VHS', 'The Royal Tenenbaums'], ['The Oranges', 'Tales from the Crypt: The Complete Seasons 1-7', 'Mammoth', 'New In Town', 'Stake Land', 'Leverage: Season 2', 'The Mortal Instruments: City of Bones', 'Treme: Season 1', 'Caesar and Cleopatra VHS', ' Observe and Report'], ['To Wong Foo Thanks for Everything VHS', ' Away We Go', 'Where Do We Go Now?', \"Wayne's World 2 VHS\", 'Scoop', 'Megafault', 'The Fall of the Roman Empire VHS', 'Buffalo Soldiers', 'Doctor Dolittle VHS', 'The Wicked'], ['The Blue Gardenia VHS', '3rd Rock from the Sun: Season 6', 'Love Happens', 'Donnie Darko', 'Sorcerer', 'Hell House', 'The Comebacks', 'The Beyond VHS', 'Me Myself I VHS', 'Targets VHS'], ['The Paul Newman Collection: (Harper / The Drowning Pool / The Left-Handed Gun / The Mackintosh Man / Pocket Money / and more)', 'The Visitant', 'Labor Pains', 'Bio-Dome VHS', 'Used Cars VHS', 'Passage to Marseille VHS', 'The Grudge 3', 'WWF: SummerSlam VHS', 'Jeeves &amp; Wooster - The Complete Series', 'Pocahontas and Pocahontas 2 anglais']]\n",
            "[['Jay and Silent: Bob Strike Back', 'Extraction', 'Zapped VHS', 'Eden Log', \"A Hard Day's Night\", 'Hole in the Wall / Go &lsquo;Head On', 'Man From Snowy River', 'Samurai Champloo: The Complete Series', 'Animaniacs: Vol. 1 (DVD)', 'Ash vs Evil Dead - The Complete First Season'], ['Ashby', '8 Seconds VHS', 'Haunter', 'Mystery Classics: (The Shadow Strikes / A Shot In The Dark / Slightly Honorable / Shadows on the Stairs)', 'Blue Thunder', 'SCTV: Volume 1 - Network 90', 'Superman: Unbound', 'Birdman of Alcatraz VHS', 'The Three Stooges Collection, Vol. 8: 1955-1959', 'A Goofy Movie Walt Disney Pictures Presents  VHS'], ['Secrets &amp; Lies VHS', 'Four Days in September VHS', 'Ice Station Zebra VHS', 'Saving Grace', 'The Great Caruso VHS', 'Born Free VHS', ' Adam-12', \"Woman's World VHS\", 'Warner Brothers Home Entertainment Academy Awards Animation Collection - 15 Winners, 26 Nominees', 'Tootsie VHS'], ['Lullaby of Broadway VHS', 'Pawn Shop Chronicles', 'WEST WING: S2 (DVD)', 'Annie', 'Madagascar', 'Disney Sing Along Songs: Friend Like Me: Volume Eleven VHS', 'Another Earth', 'Shuttle', 'The Bubble', 'Metropolitan VHS'], ['The Man on the Train', 'When the Levees Broke: A Requiem In Four Acts', 'Alvin and the Chipmunks 3: Chipwrecked', 'Sparkle', 'TCM Greatest Classic Films Collection: John Wayne Westerns (The Cowboys / Fort Apache / Rio Bravo / The Searchers)', 'Crazy Heart', 'Rebel Without a Cause VHS', 'Doctor Who - The Complete BBC Series 2', 'Merry In-Laws', 'Old Man &amp; The Sea VHS'], ['Welcome to Sarajevo VHS', 'Little Vampire VHS', 'Rosario + Vampire: CAPU2 Season 2', 'Yankee Doodle Dandy Classic Musicals Collection  VHS', 'Lady of Burlesque VHS', 'He Got Game', 'Tenderness', 'Born into Brothels', 'Sherlock Holmes', 'Nutty Professor II: The Klumps'], ['Northern Exposure: The Complete Sixth Season', 'Her', 'The Company You Keep', 'Set Up', 'Joy Ride 2: Dead Ahead', 'Wolverine', 'Home On The Range', 'Songs from the Second Floor', 'Jolene', 'Defcon 2012'], ['The Sopranos - The Complete Third Season VHS', 'The Queen of Versailles', 'Sugar', 'Assassination Games', 'American Psycho VHS', 'Streets Of Blood', 'Flower Drum Song VHS', 'Q &amp; A', 'Mulan VHS', 'Mrs. Palfrey at the Claremont'], ['Sherlock: Season 2', 'Shivers', 'Talk to Her', 'The Film Crew: Wild Women of Wongo', 'Rocky &amp; Bullwinkle &amp; Friends - The Complete Second Season', 'Woman Scorned', ' Planet 51', \"WWE: The Best of Saturday Night's Main Event\", 'One Million Years Bc VHS', \"It's a Gift VHS\"], ['Midnight Run VHS', 'Point Blank', '3:10 to Yuma [Theatrical Release]', 'Ranma 1/2 - The Digital Dojo - Boxed Set: Season 1', 'A Fistful of Dynamite VHS', 'Three on a Match VHS', 'Taxi', 'Hole in the Wall / Go &lsquo;Head On', 'Veep: Season 1', 'Evidence of a Haunting']]\n",
            "[['Best Exotic Marigold Hotel 2', 'Fantastic Mr. Fox', 'My Soul to Take', 'Alex Cross (Dvd,2012)', 'The King Kong Collection: (King Kong / Son of Kong / Mighty Joe Young)', 'The Fly / Return of the Fly', 'Kolchak: The Night Stalker (complete Series!)', 'Tremors 5: Bloodlines', \"Heaven's Lost Property: Season 1\", 'Frasier: Season 3'], ['Facing Windows', 'Seven VHS', 'Perfect Blue rated edition  VHS', 'Joshua', 'Ballad of a Soldier VHS', 'Falling Skies: The Complete 4th', 'American Wedding', 'She VHS', 'Killer Mermaid', 'Wing Commander VHS'], ['Clockwise VHS', 'Great St. Louis Bank Robbery VHS', 'The Time Tunnel - Volume One', 'Sssssss VHS', 'Legend of the Black Scorpion', 'Mother Lode VHS', 'The Pact', 'Teen Wolf VHS', 'Against the Ropes', 'Any Given Sunday VHS'], ['TCM Greatest Classic Films Collection: (Show Boat / Annie Get Your Gun / Kiss Me Kate / Seven Brides for Seven Brothers)', 'The Manson Family', 'Riddick: The Complete Collection', 'Scalphunters VHS', 'Ilsa - She Wolf of the SS VHS', 'Jeff: Who Lives at Home', 'Wait Till Your Father Gets Home S1 (DVD)', 'Silk Stockings VHS', 'The Thaw', \"King Kong (The Huntsman: Winter's War Fandango Cash Version) [Blu-ray]\"], ['Madagascar', 'Harper VHS', 'Stitches', 'The Very First Jeeves &amp; Wooster VHS', 'Men in War', 'Legend of Hell House', 'Abbott &amp; Costello Meet the Monsters Collection - Laserdisc (Laser Disc)', 'Left Behind - World at War', 'The Mickey Rooney &amp; Judy Garland Collection: (Babes in Arms / Babes on Broadway / Girl Crazy / Strike Up the Band)', 'Monster Man'], ['The Goodbye Girl VHS', 'Bah, Humduck! A Looney Tunes Christmas', 'Couples Retreat', 'Bruce Almighty', 'Godzilla vs. The Sea Monster VHS', 'Sahara', 'The Lone Ranger', 'The Paul Newman Collection: (Harper / The Drowning Pool / The Left-Handed Gun / The Mackintosh Man / Pocket Money / and more)', 'New World', 'Deadgirl'], ['War of the Arrows', 'The Wire: Season 3', 'Neon Genesis Evangelion: Collection 0:4 - Episodes 12-14', 'Heavy Metal VHS', 'Valiant', 'Burn Notice: Season 5', 'Alligator People VHS', 'Fathom', \"I'll Be There\", 'Sweet Dreams'], [\"Cory Everson's Basic Sculpting System with Weights: Hips, Thighs, Calves VHS\", 'Extremely Loud &amp; Incredibly Close', 'The Blob', \"Terror Tales from the 'Hood, Volume 4\", 'Safe Conduct', 'For Keeps', 'Alfred Hitchcock: The Essentials Collection', ' Under The Bombs', 'Creepshow 2 VHS', ' House of Saddam'], ['In the Shadow of the Moon', 'Totally Nude Aerobics VHS', 'Jane Got A Gun', 'Night of Dark Shadows VHS', 'Adventures of Rocky and Bullwinkle VHS', 'Enter Nowhere', 'Falcon Rising', 'The Martian Chronicles VHS', 'Beneath the Planet of the Apes VHS', 'Last Love'], ['The X-Files - The Complete Ninth Season', 'Bulworth VHS', 'Tekkon Kinkreet', 'T-Men VHS', 'The Bubble', '30 Days of Night: Dark Days', 'The Brainiac (1962) Classic Sci-fi and Horror Movie DVD-R', 'The Losers', 'Bus Stop VHS', 'The Martian Chronicles VHS']]\n",
            "[['Slightly Scarlet VHS', 'Robinson Crusoe on Mars', \"Artie Lange's Beer League featuring Artie Lange &amp; Ralph Macchio\", 'Girls Will Be Girls', 'Monte Carlo', 'Joseph Campbell and The Power of Myth with Bill Moyers Six Pack  VHS', 'How to Marry a Millionaire VHS', 'The Green Prince', 'Jet Li - Hero', 'The Girl with the Dragon Tattoo'], ['Doctor Who: The Next Doctor', 'Education Of Charlie Banks', 'The Wolfman (2010)', 'Jericho - The Complete Series', 'Julius Caesar VHS', \"That's My Mama - The Complete First Season\", 'The Green Inferno', 'Gemma Bovery 2014  NON-USA FORMAT, PAL, Reg.0 France', 'Goodbye World', 'The Next Three Days'], ['Flying Swords of Dragon Gate(Blu-ray) (2-D) (Hong Kong Version)(Region A with English Subtitles)', 'Count Dracula anglais', 'Undisputed', 'Science Fiction Theatre', 'Tucker:  The Man and His Dream', 'Tuskegee Airmen VHS', 'The Lobster', 'Uncle Nino', 'Burn Notice: Season 6', 'Northern Exposure: The Complete Sixth Season'], ['Stalingrad [World War II] [English Subtitles] [2013]', 'Shallow Ground', ' The Zombie Diaries', 'Wild Strawberries VHS', 'Friday Night Lights', 'Gridlocked', 'Love Story VHS', \"Lady &amp; The Tramp II: Scamp's Adventure\", 'Rahxephon - Complete Collection', 'Modern Family: Season 2'], ['Undertow', 'The In Crowd', 'The Killer', '4 Film Favorites: John Wayne (Back to Bataan, Flying Leathernecks, Operation Pacific, They Were Expendable)', 'Witness VHS', 'Frequency (DVD)', 'A Star Is Born--Restored Version VHS', \"JFK Director's Cut\", 'The Dressmaker', 'Killing Season'], ['Washington Square VHS', 'Murder By Death VHS', 'Curb Your Enthusiasm: Season 6', 'Defiant Ones VHS', 'The Siege', \"That '70s Show: Season 2\", 'A Very Merry Daughter Of The Bride', 'Miami Vice: Season Two', 'Beginning of the End VHS', 'Star Trek The Next Generation - The Complete Fifth Season'], ['Grizzly VHS', '4 Film Favorites: Dirty Harry (Dirty Harry, The Enforcer, Magnum Force, Sudden Impact)', 'Ring Around the Rosie', 'The Office: Season Three', 'Doctor Who - Silver Nemesis VHS', \"TCM Greatest Classic Films Collection: Romantic Comedies (Adam's Rib / Woman of the Year / The Philadelphia Story / Bringing Up Baby)\", 'Mark of the Devil VHS', \"Burke's Law: Season 1, vol. 1\", 'The Untouchables: The Complete Series Black &amp; White', 'Into the Woods VHS'], ['Dutch abe', 'Ondskan [Region 2]', 'Ghost World Dol  VHS', 'JETSONS, THE:SEASON ONE  (DVD)', 'Auto Focus VHS', 'VERA', 'New In Town', 'She Done Him Wrong VHS', 'The Mummy Returns VHS', 'Doctor Who - Silver Nemesis VHS'], ['K-9 VHS', 'Cloudy with a Chance of Meatballs 2', 'Ransom VHS', 'Mad Men: Season 4', 'The Counterfeiters', 'Jesse Stone: Thin Ice', 'Psych: The Complete Fifth Season', 'Casa de Mi Padre', 'Baraka', 'Feast'], ['The Exorcist III', 'Scooby Doo Wrestlemania anglais', 'The Crocodile Hunter - Collision Course', 'The Big Wedding Digital', 'Stormy Weather VHS', 'Im Juli.', 'The Office: Season Three', 'Britney Spears - Greatest Hits - My Prerogative', 'Oblivion VHS', 'Hawaii Five-O: Season 1']]\n",
            "[['The Forsyte Saga, Series 2', 'Any Which Way You Can/ Every Which Way But Loose anglais', 'Automaton Transfusion', 'The Lion King 1 1/2', 'Aladdin VHS  1995', 'Mr. Belvedere: Seasons One &amp; Two', 'Dexter: The Complete Final Season', 'The Red Balloon VHS', 'Othello VHS', 'Clean Shaven'], ['The Wild Wild West: Season 3', 'Married... with Children: Season 6', 'Get Real VHS', 'The Hobbit: An Unexpected Journey', 'Electra Glide in Blue VHS', 'Madagascar', 'I Am Zozo', 'All Is Lost 2013', 'Dolphin Tale 2', \"Chaney Vase/Sorcerer's Apprentice VHS\"], ['As Time Goes By: Complete Original Series', 'March of the Wooden Soldiers VHS', 'Hedwig and the Angry Inch', 'Creepshow III: Tales of Murder, Mayhem and Madness', 'Sometimes in April', 'Sick Girl masters Of Horror', 'Right At Your Door', 'The Fourth Man VHS', \"Monty Python and the Holy Grail / Monty Python's Life of Brian\", \"Charlie's Angels: The Complete Series\"], ['5 Fingers VHS', 'The Black Dahlia', 'Madman', 'The Wood VHS', 'Holes VHS', 'Merlin: Season 1', 'The Last Templar', 'Cliffhanger VHS', 'Universal Horror: Classic Movie Archive (The Black Cat / Man Made Monster / Horror Island / Night Monster / Captive Wild Woman)', 'Pinky VHS'], ['The Comeback - The Complete Only Season', 'Death Note 2: The Last Name', 'Reno 911! - Miami', 'Of Mice and Men', 'The Taking of Deborah Logan', \"Gulliver's Travels VHS\", 'Conquest of Space', 'WWF: Backlash 2000 VHS', 'A Four Letter Word', 'Criminal Minds: Season 8'], ['Scarlet Street VHS', 'Blue Steel VHS', 'Resident Evil: Afterlife', 'Simply Irresistible', 'The Boy in the Striped Pajamas', 'Columbo: The Complete First Season', 'Bad Dreams VHS', 'Smart People', 'Rawhide - The Complete First Season', 'Monte Carlo/Aquamarine [DVD]'], ['The Charge of the Light Brigade VHS', 'Neverland', 'Experiment', 'The Minus Man', 'The Damned United', 'TALENTED MR. RIPLEY', 'Family Ties: Season 1', 'Mcmillan &amp; Wife: Season 2', 'The Life Before Her Eyes', 'Scary Movie 2'], ['Snowball Express VHS', 'Suspiria VHS', 'Phoenix (2014) [ NON-USA FORMAT, Blu-Ray, Reg.B Import - Germany ]', 'Medium Raw', 'The Fourth Man VHS', 'Kiss of Death VHS', \"Everybody's Fine\", 'Eat Pray Love', 'Dead And Breakfast R', '28 Days Later'], ['The Little Rascals Collection', 'Black Snake Moan [Theatrical Release]', 'Love and Other Disasters', 'Sitting Pretty VHS', 'Diary of a Chambermaid', 'A Man Named Pearl  SET', 'Lark Rise to Candleford: Season 2', 'Doctor Who - The Time Warrior anglais', 'The Numbers Station', 'Ice Station Zebra VHS'], ['Old Yeller VHS', \"Mystery Classics - 50 Movie Pack: Algiers - Bulldog Drummond Escapes - Dick Tracy Meets Gruesome - The Man on the Eiffel Tower - Mr. Moto's Last Warning + 45 more!\", 'Charlie St. Cloud', ' Flirting With Forty', \"King Kong (The Huntsman: Winter's War Fandango Cash Version) [Blu-ray]\", 'Conspiracy', 'Mephisto VHS', 'Date Movie', 'Wish I Was Here', 'HELTER SKELTER (FF) (DVD)']]\n",
            "[['Pawn', 'Pow Wow Highway VHS', \"I'll Be There\", 'When Worlds Collide VHS', 'Kundun VHS', 'The Legend of Lizzie Borden', 'Face', 'Letters to Juliet', 'The Seventh Sign', 'The Next Best Thing VHS'], ['Cocaine Cowboys', 'Hobbit 3: The Battle of the Five Armies', \"Wayne's World 2 VHS\", 'Undertow', 'Sailor Moon Super S VHS', 'Fatherland VHS', 'The Cat and the Canary', 'Under the Sun', 'Thirteen Ghosts', 'A Fistful of Dynamite VHS'], ['Phantom', 'In the Mood for Love', 'Witness VHS', 'Diary of a Chambermaid', 'Adventures of Robin Hood VHS', 'The Pact', 'Associate VHS', 'Room at the Top', 'Dance with a Stranger VHS', 'Solstice'], ['Survivor', 'Paper Heart', 'X-Men VHS', 'The Rounders VHS', 'Compulsion VHS', 'Happiness', 'The Kingdom', \"Malibu's Most Wanted\", 'State of Play', 'Remington Steele - Season 1, Vol. 1'], ['Jersey Boys 2014', 'Antarctica: A Year On Ice', 'Zombeavers Region Free', 'The Stuff VHS', 'Out of the Blue - The Definitive Investigation of the UFO Phenomenon', 'Doctor Who &amp; The Daleks VHS', 'I, Frankenstein Digital', 'The Carson Collection - His Favorite Moments from The Tonight Show 1962-1992  VHS', \"OCEAN'S TWELVE (WS) (DVD)\", 'Kung Fu Killer'], ['The Crocodile Hunter - Collision Course VHS', \"Da Vinci's Demons: Season 1\", 'The Messenger: The Story of Joan of Arc VHS', 'Sabotage', 'Footloose', 'Commando VHS', 'Species Trilogy', 'A Nightmare on Elm Street 4: The Dream Master', 'Secret Agent', 'Good Hair'], ['The Contract', '10 Things I Hate About You VHS', 'Martin: Season 2', 'Highway Patrol Complete Season 3', 'The Complete Series Rumpole of the Bailey', \"Jane Austen's Pride and Prejudice Six Piece Collector's VHS\", \"The Complete Monty Python's Flying Circus\", 'Anne Frank - The Whole Story', 'Twin Sisters', \"L'&Eacute;treinte du serpent\"], ['Black Diamond Skiing VHS', 'Scooby-Doo', 'Belle And The Beast: A Christian Romance', 'Beauty and The Beast The Criterion Collection', 'The House By the Cemetery VHS', 'Star Trek - Deep Space Nine, Episode 6: Captive Pursuit VHS', 'The Losers', 'Wild China', 'The Spy Who Came in From the Cold VHS', 'The Wasp Woman VHS'], ['Ponyo (Mandarin Chinese Edition)', 'The Last Knights Digital', 'Invisible Ray VHS', 'The Outrage VHS', 'The Jeffersons: The Complete Series', 'Blood Work', 'Forbidden World', 'Hall Pass', 'Uptown Girls', 'Girls Will Be Girls'], ['An Officer and A Gentleman VHS', 'Kung Fu: The Complete Series Collection', 'Ash vs Evil Dead - The Complete First Season', 'Ong-Bak - The Thai Warrior', 'Muppet Treasure Island VHS', 'Pootie Tang', 'The Bible - Solomon', 'Shaft', 'Breaking the Waves VHS', 'The American President VHS']]\n",
            "[['Creepy Crawlers', 'Friends with Kids', \"Grey's Anatomy: Season 1\", 'Sci-Fi Creature Classics - 4-Movie Set - 20 Million Miles to Earth - The Giant Claw - It Came From Beneath The Sea - Mothra', 'Day of the Dead VHS', 'Femalien VHS', \"Love's Labour's Lost\", 'The Mystery Science Theater 3000 Collection - The Essentials: (Manos, the Hands of Fate / Santa Claus Conquers the Martians)', 'Hush Hush Sweet Charlotte VHS', 'Santa Clause 2'], ['Home On The Range', 'Terminator Genisys', 'Libeled Lady VHS', 'Troll Hunter 15', 'The Naked Kiss', 'The Road to Bali / On the Road to Hollywood', 'Lacombe, Lucien', 'The Vampire Bat', '12 Rounds 2: Reloaded', 'Los Aristogatos The Aristocats  VHS'], ['Doc Hollywood VHS', 'A Princess for Christmas', 'Bad Ass 2: Bad Asses', 'Captain Sindbad VHS', 'Irrational Man', 'Jackass - The Movie VHS', 'Mapp &amp; Lucia, Set 1 VHS', 'The West Wing: Season 1', 'Will &amp; Grace - Season One', 'Captive'], ['Midnite Movies Double Feature: The Masque of the Red Death / The Premature Burial', 'Women in Love VHS', 'Eye See You', 'Bobby Z', 'Diary of a Country Priest (1951) / Region Free DVD / Audio: English, French / Subtitle: English, Chinese / Starring: Claude Laydu, Nicole Ladmiral Director: Robert Bresson', 'Dam Busters', 'Seven VHS', 'THE SIXTH SENSE', 'Crazy, Stupid, Love', 'V - The Final Battle VHS'], ['Julia', 'Curse of the Demon VHS', 'Killer Joe', 'Adventures of Milo &amp; Otis VHS', 'Bless Me, Ultima', 'Lord Peter Wimsey: The Unpleasantness at the Bellona Club VHS', 'The Missing', 'The Invisible Woman', 'Murder, She Wrote: The Complete First Season', 'United States of Tara: Season 1'], ['Ally Mcbeal: The Complete Collection [Region 2]', 'Flicka', \"Kermit's Swamp Years\", 'His Girl Friday', 'Luther: Season 2', 'M*A*S*H - Season Four', 'Six Wives of Henry VIII / Elizabeth R', 'Irma La Douce VHS', 'Danielle Steel Collection: (Palomino / Secrets / Star / The Promise)', 'In July'], ['Eden [Blu-ray]', 'Kathy Ireland - Swimsuit Edition: Behind the Scenes VHS', 'Father of the Bride Part II VHS', 'Reindeer Games VHS', 'Death Sentence', 'Wise Blood', 'New World', 'Jennifer 8 VHS', 'The Complete Matrix Trilogy: (The Matrix/ The Matrix Reloaded/ The Matrix Revolutions)', 'Teenage Mutant Ninja Turtles III VHS'], ['The Breakfast Club', 'Dead Rising: Watchtower', 'Blue Collar Comedy Tour: One for the Road', 'The Brasher Doubloon', 'Ice Station Zebra VHS', 'Batman Beyond: Season 1', 'Byzantium', 'Bad Seed VHS', 'I.Q. VHS', 'A Night in Old Mexico'], ['Good Son VHS', 'Delivery Man', 'The Swan Princess VHS', 'Spartacus: War of the Damned: Season 3', 'Buffy &amp; Angel Chronicle Vol 1 VHS', 'Master of Ballantrae VHS', \"Mickey's Twice Upon a Christmas\", 'The Kennedys', 'Doctor Who - The Mark of the Rani VHS', 'Kinski: My Best Fiend'], ['Son of Paleface', 'Snake Eyes VHS', 'X-men 3: The Last Stand Icons', 'Grey Owl VHS', 'Night of the Scarecrow VHS', 'Late Spring', 'Buffy the Vampire Slayer - The Complete Seventh Season', 'Red Headed Woman VHS', 'Night Of The Living Dead', 'Mi-5 Digital']]\n",
            "[['Love Hina: Volume 1 - Moving In - Episodes 1-4', 'Obsession VHS', 'Mandingo VHS', 'Diabolique VHS', 'Crusade: The Complete Series', 'Invasion of Astro-Monster', 'Fluke VHS', 'The Marrying Man VHS', 'Thelma &amp; Louise [Blu-ray]', 'Macbeth VHS'], ['Broken', 'Everlasting Moments', 'Moonlighting - Season 3', 'Dahmer VHS', 'Hollows Grove', 'The Sheepman', 'Cast A Long Shadow', 'Sunshine Cleaning', 'A Double Life', \"Jeff Dunham's Very Special Christmas Special\"], ['Da Ali G Show - The Complete First Season', 'Loser', 'Old Man &amp; The Sea VHS', 'Tenacious D - The Complete Master Works', 'Star Wars: The Force Awakens', 'Kaze No Stigma: The Complete Series', 'Pompeii Pete', 'Read My Lips', 'Mimic: 3-Film Set Mimic / Mimic 2 / Mimic 3', 'Planet of the Vampires'], ['Country Remedy', 'Masters of Horror: Family', 'Stalingrad [World War II] [English Subtitles] [2013]', 'Mongol: The Early Years of Genghis Khan', 'The Dyatlov Pass Incident', 'The Boss', 'In Like Flint VHS', 'Monolith Monsters VHS', 'Married... with Children: Season 6', 'The Andy Griffith Show - The Complete Second Season'], ['Magnum P.I.: The Complete Series', 'Joseph VHS', \"Love's Long Journey\", 'Deep Red VHS', 'Skins VHS', 'Rodan / War of the Gargantuas', 'Band Of Brothers (DVD)', 'SCOOBY-DOO, WHERE ARE YOU? S3', 'Another Thin Man VHS', 'Nine Lives'], ['All in the Family : Season 3', 'True Story of Jesse James, The', \"It's Alive\", 'Survivor - The Complete First Season', 'Boardwalk Empire: Season 5', 'The Great Locomotive Chase VHS', 'Titanic VHS', 'The Office: Season Seven', 'Felon', 'Seinfeld: Season 8'], ['Superman: The Animated Series - Volume 1', ' 21 (Two-Disc Deluxe Edition)', 'Dead Rising: Watchtower', 'The Son', 'We Own the Night', 'The Muppet Show: Season 1', 'Shackleton - The Greatest Survival Story of All Time VHS', 'Chicago', 'A Town Like Alice VHS', 'Showtime'], ['Torchwood: Season 2', 'Head-On', 'Godzilla 2000', 'Samurai X - The Motion Picture', 'Give My Regards to Broad Street VHS', 'Mansfield Park VHS', 'Tinker Bell and the Lost Treasure', 'Under the Sun', 'Ransom VHS', 'Frankenstein Conquers The World'], ['Mr. Mom VHS', 'A Christmas Wish', 'A Kiss Before Dying VHS', 'Oorlogswinter [Region 2]', 'Being There VHS', \"Daredevil (Director's Cut) / Elektra [DVD]\", 'Shaun The Sheep - The Movie 2015', 'The Numbers Station', 'Men of War VHS', 'Pushing Daisies:S1 (DVD)'], ['Defendor', 'Anaconda 3: Offspring', 'Prince of the City VHS', 'Batman: The Complete Television Series', \"St Trinian's\", \"Margaret Cho - I'm the One That I Want\", 'Nico and Dani', 'Showtime', 'Divide, The', 'Indiana Jones and the Last Crusade']]\n",
            "[['In the Army Now VHS', 'Big Bad Mama', 'Christmas Evil', 'Elizabeth VHS', 'Yellowbeard VHS', 'The Substitute VHS', '12 Angry Men', 'Pootie Tang', 'Ali: Fear Eats the Soul', 'Great Balls of Fire VHS'], ['They Came Together Digital', 'Ninja', 'I Was a Teenage Werewolf VHS', 'Kansas City Confidential VHS', 'Not of This Earth VHS', 'The Slipper and the Rose VHS', 'Disney Sing Along Songs: Friend Like Me: Volume Eleven VHS', 'Looper', 'Hush Hush Sweet Charlotte VHS', 'The Comeback - The Complete Only Season'], ['Columbo - Complete Series NON-USA FORMAT, PAL, Reg.2.4 United Kingdom', 'House on Haunted Hill/The Last Man On Earth', \"Three's Company: Season 4\", 'The Zero Theorem 2014', 'Comanche Station VHS', \"Flash Gordon: Boxed Set (Space Soldiers/Flash Gordon's Trip To Mars/Flash Gordon Conquers The Universe)\", 'Starsky And Hutch: The Complete Collection', 'Homicidal', 'The Bodyguard Full Screen Edition', 'Goldfinger VHS'], ['Outland VHS', ' Criminal Minds', 'Little House on the Prairie', 'The Tower', '13 Sins', 'The Fox and the Hound / The Fox and the Hound 2', 'Near Death', 'The Cure VHS', 'The A-Team Complete Series (Seasons 1-5)', 'D2 - The Mighty Ducks VHS'], ['Enduring Love', 'Dark Mirror', \"You Can't Do That on Television\", '500 MPH Storm', 'Klown', 'Three Stooges in Orbit VHS', '4 Film Favorites: John Wayne (Back to Bataan, Flying Leathernecks, Operation Pacific, They Were Expendable)', 'Piranha 3DD', 'Amazing Stories: The Complete First Season', \"Will Ferrell: You're Welcome, America - A Final Night with George W. Bush\"], ['The Grifters', 'Hallmark Holiday Collection: Movie 4 Pack (Trading Christmas, Lucky Christmas, Case For Christmas, National Tree)', 'When Eight Bells Toll', 'Adam &amp; Steve', 'Black Moon Rising VHS', 'The Mill and the Cross', \"Elle S'appelait Sarah Sarah's Key\", 'LINE OF DUTY, SERIES 1', 'Flamingo Road VHS', 'Monsieur Verdoux'], ['Gorilla at Large / Mystery on Monster Island', \"Gus Van Sant's Last Days\", 'Battledogs', 'Cabinet of Dr Caligari VHS', 'Protocol', 'The Ward', 'Ghost Hunt: The Complete Series S.A.V.E.', 'The Second Best Exotic Marigold Hotel [DVD] [2015]', 'The Keep VHS', ' Extract'], ['The Abandoned', 'Cranes Are Flying VHS', 'Carriers', 'The Accidental Spy Theatrical Release', 'Honeymoon Machine VHS', 'Sex Drive 2008', 'Women  in the Ring VHS', 'Bloodrayne - Black Edition - Uncut', 'Up Close &amp; Personal VHS', 'An Inspector Calls (Region 3 DVD / Non USA Region) (English Subtitled)'], ['100 Feet: Unrated and Uncut', 'The Dead', 'Mighty Aphrodite VHS', 'Mazes and Monsters', 'Galactica 1980: Mankind Battles for Survival in Space', 'Couples Retreat', 'The Hundred-Foot Journey', 'This Sporting Life', ' Walled In', 'The Special Relationship'], ['In the Bedroom VHS', 'Meet Dave', 'Ray', 'Fun with Dick and Jane VHS', 'Wild Wild West VHS', 'Captain America (1990) Matt Salinger, Ronny Cox, Ned Beatty', 'Crash', 'Ghost of Goodnight Lane', 'Crank 2 [Theatical Release] [Theatrical Release]', 'Philomena']]\n",
            "[['The Double', 'The Incredibles (Mandarin Chinese Edition)', 'The Rescuers Collection: (The Rescuers / The Rescuers Down Under)', 'We Need to Talk About Kevin', 'Married with Children, Vol. 1 - The Most Outrageous Episodes', 'Charlie Chan Collection - Volume 4 (Charlie Chan in Honolulu / Charlie Chan in Reno / Charlie Chan at Treasure Island / City in Darkness)', 'Richard III VHS', 'Sleepaway Camp: Survival Kit', 'Julie VHS', 'Children of Paradise'], ['Star Trek - The Original Series, Vol. 20, Episodes 39 &amp; 40: Mirror Mirror/ The Deadly Years', 'Aqua Teen Hunger Force - Volume Three', 'Rain VHS', 'Lilo &amp; Stitch', 'Sister Act 2 VHS', 'Sealab 2021 - Season 1', 'Witness for the Prosecution VHS', \"You Can't Take It With You VHS\", 'Ancient Aliens: Season 4', 'Stone Cold VHS'], ['Tiptoes', 'The Reef', '24: Live Another Day 2014', 'Broken Lance VHS', 'Nanny McPhee Returns', 'The Reunion', 'A Perfect Murder VHS', 'Bite the Bullet VHS', 'Undefeated, The', 'Sound of My Voice'], ['September Dawn', 'Murder My Sweet VHS', 'Strike Witches: Season 2', 'Body Snatcher VHS', 'Flight of the Phoenix', 'Cleopatra VHS', 'Stories We Tell', 'Anastasia VHS', 'The Pursuit of Happyness', 'Parrish VHS'], ['Haunted VHS', 'The Bully Project', 'Dead Alive', 'Robot and Frank', 'Death on the Nile VHS', 'A Serious Man', 'Noble House', 'Harry Potter: Years 1-5', 'The Red Badge of Courage VHS', 'Neil Young - Heart of Gold [Import anglais]'], ['Ribbon Magic VHS', 'Marlene VHS', 'The Dark Crystal VHS', 'The Legend of Lizzie Borden', 'Weird Science VHS', 'Poor Little Rich Girl VHS', 'Suna no onna Woman in the Dunes  VHS', 'Edge of Seventeen', 'Dark Water', 'The Jolson Story VHS'], ['AFTERSHOCK [China, 2010][Uncut Special Edition]', 'Motion Picture Masterpieces Collection: (David Copperfield 1935 / Marie Antoinette 1938 / Pride and Prejudice 1940 / A Tale of Two Cities 1935 / Treasure Island 1934/ and more)', 'Longmire: S4 (DVD)', \"Santa Claus Is Comin' To Town VHS\", \"Monster's Ball\", 'He Was A Quiet Man', 'Hurt', 'Day the World Ended / The She-Creature', 'Circle of Friends VHS', 'Unfaithfully Yours VHS'], ['Star 80', 'Howard the Duck VHS', 'Drawn Together: Season 1', 'The Competition VHS', 'Appleseed: Alpha', 'The Judy Garland Show: Volume 1 - Shows 1-3', 'Salem Witch Trials featuring Kirstie Alley', 'Sherlock Holmes - Pursuit to Algiers VHS', 'The Dinner Game', 'Ondskan [Region 2]'], ['Toby Tyler', 'Kim VHS', 'The Kingdom', \"Devil's Playground\", 'The Rise &amp; Fall of WCW', 'The Outsiders', 'In Order of Disappearance ( Kraftidioten ) [ NON-USA FORMAT, PAL, Reg.2 Import - United Kingdom ]', \"'71 2014\", 'The Fall Guy: Season 1, Vol. 1', 'Southland Tales Theatrical Release'], ['Ballistic - Ecks vs. Sever VHS', 'Looney Tunes: Golden Collection Vol. 6', 'Tale of Tales ( Il racconto dei racconti ) [ NON-USA FORMAT, PAL, Reg.2 Import - Italy ]', 'Bad Timing', 'What Maisie Knew', ' Max Payne', 'People Will Talk VHS', 'Sylvia', 'Gnomeo &amp; Juliet', \"Mickey's Christmas Carol VHS\"]]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random.seed(44)\n",
        "all_movies = list(item_map.values())\n",
        "\n",
        "output_r = []\n",
        "for i in range(num_test_items):\n",
        "  output = []\n",
        "  for _ in range(10):\n",
        "      current_list = []\n",
        "      while len(current_list) < 10:\n",
        "          movie = random.choice(all_movies)\n",
        "\n",
        "          if movie not in current_list:\n",
        "              current_list.append(movie)\n",
        "\n",
        "      output.append(current_list)\n",
        "  output_r.append(output)\n",
        "\n",
        "for output in output_r:\n",
        "  print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3K6ml1GKS93G",
      "metadata": {
        "id": "3K6ml1GKS93G"
      },
      "source": [
        "## Most Popular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "TM2ucSP9TAUP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM2ucSP9TAUP",
        "outputId": "bdd3c32d-2cc9-49df-9c1f-7886c1426aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n",
            "[['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl'], ['The Lord of the Rings: The Fellowship of the Ring', 'The Sixth Sense VHS', 'The Lord of the Rings: The Return of the King', 'Terminator, The', 'Batman Begins', 'The Silence of the Lambs VHS', 'Finding Nemo (Mandarin Chinese Edition) [2 DVDs]', 'Spider-Man 2', 'Gladiator VHS', 'Pirates of the Caribbean: The Curse of the Black Pearl']]\n"
          ]
        }
      ],
      "source": [
        "movie_likes = {}\n",
        "for u in train_conv:\n",
        "  user = u[0]\n",
        "  user_data = next((item[user] for item in data if user in item), None)\n",
        "  convs = user_data.get(\"Conversation\", [])\n",
        "  for c in convs:\n",
        "    user_likes = list(c.values())[0][\"user_likes\"]\n",
        "    for m in user_likes:\n",
        "      try:\n",
        "        movie_likes[m] += 1\n",
        "      except:\n",
        "        movie_likes[m] = 1\n",
        "\n",
        "sorted_movie_likes = dict(sorted(movie_likes.items(), key=lambda item: item[1], reverse=True))\n",
        "top_10_movies = dict(list(sorted_movie_likes.items())[:10])\n",
        "\n",
        "outputs_mp = []\n",
        "for i in range(num_test_items):\n",
        "  outputs = []\n",
        "  for _ in range(10):\n",
        "    outputs.append([item_map[m] for m in list(top_10_movies.keys())])\n",
        "  outputs_mp.append(outputs)\n",
        "\n",
        "for output in outputs_mp:\n",
        "  print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv9AhC-ACVn1",
        "outputId": "8e31282e-2f27-41da-a730-eb50521a09ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"GPU disponible:\", torch.cuda.is_available())"
      ],
      "id": "iv9AhC-ACVn1"
    },
    {
      "cell_type": "markdown",
      "id": "3d798e82",
      "metadata": {
        "id": "3d798e82"
      },
      "source": [
        "## TinyLlama:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24214eec",
      "metadata": {
        "id": "24214eec"
      },
      "source": [
        "### Zero-Shot con interacciones históricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ed7afb73",
      "metadata": {
        "id": "ed7afb73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e84884-6cf4-43f5-fe30-cd4a930067a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "outputs_z_s = []\n",
        "for n in range(num_test_items):\n",
        "  k = 10\n",
        "  outputs = []\n",
        "  # Pipeline Initialization\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=model_name,\n",
        "      device_map=\"auto\",\n",
        "      torch_dtype=torch.float16,\n",
        "  )\n",
        "\n",
        "  ctx = (\n",
        "      \"YOU ARE A MOVIE RECOMMENDATION SYSTEM.\"\n",
        "      \"GENERATE A NUMBERED LIST OF 10 MOVIES. \\n\"\n",
        "      \"RULES: \\n\"\n",
        "      \"1. DO NOT write dialogs, explanations nor additional text or information. \\n\"\n",
        "      \"2. DO NOT repeat movies mentioned in the conversation. \\n\"\n",
        "      \"3. Response format: \\n\"\n",
        "      \"1. \\\"Movie name 1\\\" \\n\"\n",
        "      \"2. \\\"Movie name 2\\\" \\n\"\n",
        "      \"... \\n\"\n",
        "      \"10. \\\"Movie name 10\\\" \\n\"\n",
        "      \"Use ONLY this format and NOTHING else.\"\n",
        "  )\n",
        "\n",
        "  msg = (\n",
        "      \"Based on the following conversation: \\n\"\n",
        "      f\"{rand_conversations[n][1]} \\n\\n\"\n",
        "      \"And the movies the user has previously interaced with: \\n\"\n",
        "      f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n",
        "      \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n",
        "  )\n",
        "\n",
        "  messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n",
        "\n",
        "  prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "  inputs = pipe.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for i in range(k):\n",
        "          output_ids = pipe.model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=200,\n",
        "              do_sample=True,\n",
        "              temperature=0.7,\n",
        "              top_k=50,\n",
        "              top_p=0.95\n",
        "          )\n",
        "          decoded = pipe.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "          outputs.append(decoded)\n",
        "  outputs_z_s.append(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bpYn7Iyp3vJ4",
      "metadata": {
        "id": "bpYn7Iyp3vJ4"
      },
      "source": [
        "### Few-Shot con interacción histórica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "oJWzkxM73ynC",
      "metadata": {
        "id": "oJWzkxM73ynC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a5a26c-8700-4e9f-b268-f5f1f7190731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "k = 10\n",
        "outputs_f_s = []\n",
        "for n in range(num_test_items):\n",
        "  outputs = []\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=model_name,\n",
        "      device_map=\"auto\",\n",
        "      torch_dtype=torch.float16,\n",
        "  )\n",
        "\n",
        "  ctx = (\n",
        "      \"YOU ARE A MOVIE RECOMMENDATION SYSTEM.\"\n",
        "      \"GENERATE A NUMBERED LIST OF 10 MOVIES. \\n\"\n",
        "      \"RULES: \\n\"\n",
        "      \"1. DO NOT write dialogs, explanations nor additional text or information. \\n\"\n",
        "      \"2. DO NOT repeat movies mentioned in the conversation. \\n\"\n",
        "      \"3. Response format: \\n\"\n",
        "      \"1. \\\"Movie name 1\\\" \\n\"\n",
        "      \"2. \\\"Movie name 2\\\" \\n\"\n",
        "      \"... \\n\"\n",
        "      \"10. \\\"Movie name 10\\\" \\n\"\n",
        "      \"Use ONLY this format and NOTHING else.\"\n",
        "  )\n",
        "\n",
        "  msg = (\n",
        "      \"Based on these 4 examples: \\n\"\n",
        "      f\"{few_shot_data[0]}\\n\"\n",
        "      f\"{few_shot_data[1]}\\n\"\n",
        "      f\"{few_shot_data[2]}\\n\"\n",
        "      f\"{few_shot_data[3]}\\n\\n\"\n",
        "      \"And based on the following conversation: \\n\"\n",
        "      f\"{rand_conversations[n][1]} \\n\\n\"\n",
        "      \"And the movies the user has previously interaced with: \\n\"\n",
        "      f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n",
        "      \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n",
        "  )\n",
        "\n",
        "  prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "  inputs = pipe.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for i in range(k):\n",
        "          output_ids = pipe.model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=200,\n",
        "              do_sample=True,\n",
        "              temperature=0.7,\n",
        "              top_k=50,\n",
        "              top_p=0.95\n",
        "          )\n",
        "          decoded = pipe.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "          outputs.append(decoded)\n",
        "  outputs_f_s.append(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "path = '/content/gdrive/MyDrive/Proyecto LLMonkeys/sessions/TinyLlama/TinyLlama_notebook_env_fewshot.db'\n",
        "with open(path, 'wb') as f:\n",
        "    dill.dump_session(f)"
      ],
      "metadata": {
        "id": "rz9GClvdynA_"
      },
      "id": "rz9GClvdynA_",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tuning"
      ],
      "metadata": {
        "id": "Mr5beh1_2nRo"
      },
      "id": "Mr5beh1_2nRo"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers datasets accelerate peft bitsandbytes trl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "43fZvWmG3TFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa4d283-d281-49c1-971e-af816b2ff787"
      },
      "id": "43fZvWmG3TFh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.18.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"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\")"
      ],
      "metadata": {
        "id": "wPVY25F87MvP"
      },
      "id": "wPVY25F87MvP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_convs = []\n",
        "for u in train_conv:\n",
        "  all_convs.extend(u[1])"
      ],
      "metadata": {
        "id": "Qm9l1CBh4Eij"
      },
      "execution_count": 7,
      "outputs": [],
      "id": "Qm9l1CBh4Eij"
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_convs = random.sample(all_convs, 4000)"
      ],
      "metadata": {
        "id": "LrvlZg_5DUo8"
      },
      "execution_count": 8,
      "outputs": [],
      "id": "LrvlZg_5DUo8"
    },
    {
      "cell_type": "code",
      "source": [
        "def convertir_dialogo(texto):\n",
        "    salida = \"\"\n",
        "    for linea in texto.strip().splitlines():\n",
        "        if linea.startswith(\"User:\"):\n",
        "            salida += \"<|user|> \" + linea[6:].strip() + \"\\n\"\n",
        "        elif linea.startswith(\"Agent:\"):\n",
        "            salida += \"<|assistant|> \" + linea[7:].strip() + \"\\n\"\n",
        "    return {\"text\": salida.strip()}"
      ],
      "metadata": {
        "id": "3ZMth60PEJWr"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "3ZMth60PEJWr"
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_convs = [convertir_dialogo(c) for c in fine_tune_convs]"
      ],
      "metadata": {
        "id": "Moa5BHLaDjLK"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "Moa5BHLaDjLK"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    llm_int8_threshold=6.0,\n",
        "    llm_int8_skip_modules=None\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "ewRcVV3z2RGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692d09f6-884a-40d9-f691-921aa85ed961"
      },
      "id": "ewRcVV3z2RGa",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "def tokenize_fn(example):\n",
        "    # Tokenizamos, truncamos a 512 tokens como máximo y rellenamos\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "dataset = Dataset.from_list(fine_tune_convs)\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]  # ya no necesitamos el campo \"text\" crudo\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e4ed4ad97d2744deb7db73b4c6971c37",
            "13b7af25e97c4f1897d264f15f80126b",
            "ec9db92e48b447618d3d24a70921ef56",
            "ad391eacda8f4545b971f2d3f2a99815",
            "19879b90460a42aaad9215fc4e6586d1",
            "b2d26ca72f1c40078f3d46a6c02af713",
            "54313d695d3b41148ac55a39c93b5bb5",
            "852ca733c9634155b2a34c830215bb01",
            "391f2da1c1bb4841be2011cc280f55f0",
            "544e8447ed5346c8bc3e3d0b8e513cc6",
            "5719d88ad9324a4f9c7aca3b43ad39fc"
          ]
        },
        "id": "xRNO7htYNOAg",
        "outputId": "fda53e8f-43f5-4fbf-d18c-37ed11dd9051"
      },
      "id": "xRNO7htYNOAg",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4ed4ad97d2744deb7db73b4c6971c37"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune\",\n",
        "    per_device_train_batch_size=4,        # batch por GPU\n",
        "    gradient_accumulation_steps=8,        # acumular gradientes para simular un batch mayor\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,                            # entrenar en FP16\n",
        "    optim=\"paged_adamw_8bit\",             # usar optimizador 8-bit de bitsandbytes\n",
        "    logging_steps=20,\n",
        "    save_steps=500,\n",
        "    save_total_limit=3,\n",
        "    report_to=\"none\",                     # desactivar logs externos\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9XeROteOQIG",
        "outputId": "a68bf484-eebd-4892-f0ae-180ea16a3316"
      },
      "id": "Q9XeROteOQIG",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2\")\n",
        "tokenizer.save_pretrained(\"/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "b6XGbQMIJG35",
        "outputId": "ca1e63ea-fed8-45f3-bd92-a290cf92cbe5"
      },
      "id": "b6XGbQMIJG35",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 13:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.055400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.046100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.018300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.019900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.018500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/chat_template.jinja',\n",
              " '/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/tokenizer.model',\n",
              " '/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/added_tokens.json',\n",
              " '/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune-2/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# Paso 1: Cargar la configuración PEFT\n",
        "peft_model_path = \"/content/gdrive/MyDrive/Proyecto LLMonkeys/TinyLlama-fine-tune\"\n",
        "config = PeftConfig.from_pretrained(peft_model_path)\n",
        "\n",
        "# Paso 2: Cargar el modelo base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Paso 3: Aplicar los pesos LoRA al modelo base\n",
        "ft_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
        "\n",
        "# Paso 4: Cargar el tokenizer\n",
        "ft_tokenizer = AutoTokenizer.from_pretrained(peft_model_path)"
      ],
      "metadata": {
        "id": "S58uYKu5ZhiL"
      },
      "id": "S58uYKu5ZhiL",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "outputs_ft_s = []\n",
        "for n in range(num_test_items):\n",
        "  k = 10\n",
        "  outputs = []\n",
        "  # Pipeline Initialization\n",
        "  pipe = pipeline(\n",
        "      \"text-generation\",\n",
        "      model=model_name,\n",
        "      device_map=\"auto\",\n",
        "      torch_dtype=torch.float16,\n",
        "  )\n",
        "\n",
        "  ctx = (\n",
        "      \"YOU ARE A MOVIE RECOMMENDATION SYSTEM.\"\n",
        "      \"GENERATE A NUMBERED LIST OF 10 MOVIES. \\n\"\n",
        "      \"RULES: \\n\"\n",
        "      \"1. DO NOT write dialogs, explanations nor additional text or information. \\n\"\n",
        "      \"2. DO NOT repeat movies mentioned in the conversation. \\n\"\n",
        "      \"3. Response format: \\n\"\n",
        "      \"1. \\\"Movie name 1\\\" \\n\"\n",
        "      \"2. \\\"Movie name 2\\\" \\n\"\n",
        "      \"... \\n\"\n",
        "      \"10. \\\"Movie name 10\\\" \\n\"\n",
        "      \"Use ONLY this format and NOTHING else.\"\n",
        "  )\n",
        "\n",
        "  msg = (\n",
        "      \"Based on the following conversation: \\n\"\n",
        "      f\"{rand_conversations[n][1]} \\n\\n\"\n",
        "      \"And the movies the user has previously interaced with: \\n\"\n",
        "      f\"{random.sample(rand_conversations[n][5], min(10, len(rand_conversations[n][5])))}\\n\\n\"\n",
        "      \"Generate a list of 10 recommended movies (JUST NAMES, ONE PER LINE):\"\n",
        "  )\n",
        "\n",
        "  messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n",
        "\n",
        "  prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "  inputs = pipe.tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for i in range(k):\n",
        "          output_ids = pipe.model.generate(\n",
        "              **inputs,\n",
        "              max_new_tokens=200,\n",
        "              do_sample=True,\n",
        "              temperature=0.7,\n",
        "              top_k=50,\n",
        "              top_p=0.95\n",
        "          )\n",
        "          decoded = pipe.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "          outputs.append(decoded)\n",
        "  outputs_ft_s.append(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiCufUvsQ5R-",
        "outputId": "944b742e-9c18-4418-e2f0-1f47b31b47f4"
      },
      "id": "xiCufUvsQ5R-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kEEEo2aUjYsJ",
      "metadata": {
        "id": "kEEEo2aUjYsJ"
      },
      "source": [
        "## Evaluación de los modelos:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install rapidfuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYGxx_keqFtl",
        "outputId": "e13ace65-6d6a-4b3d-f4ad-5927226a22f0"
      },
      "id": "bYGxx_keqFtl",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m156.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5ckBE_kOquuF",
      "metadata": {
        "id": "5ckBE_kOquuF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from sklearn.metrics import ndcg_score\n",
        "import re\n",
        "import html\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def normalizar_titulo(titulo):\n",
        "    # Decode entidades HTML como &amp;\n",
        "    titulo = html.unescape(titulo)\n",
        "    # Minúsculas\n",
        "    titulo = titulo.lower()\n",
        "    # Eliminar puntuación excepto letras, números y &\n",
        "    titulo = re.sub(r\"[^a-z0-9& ]+\", \"\", titulo)\n",
        "    # Eliminar múltiples espacios\n",
        "    titulo = re.sub(r\"\\s+\", \" \", titulo).strip()\n",
        "    return titulo\n",
        "\n",
        "def comparar_titulos(t1, t2):\n",
        "    t1 = normalizar_titulo(t1)\n",
        "    t2 = normalizar_titulo(t2)\n",
        "    return fuzz.token_set_ratio(t1, t2)\n",
        "\n",
        "# Funciones generadas por DeepSeek\n",
        "def recall_at_k(generated_recommendations, ground_truth, k=10):\n",
        "    hits = 0\n",
        "    # Tomar las primeras K recomendaciones generadas\n",
        "    top_k = generated_recommendations[:k]\n",
        "    for e in top_k:\n",
        "      if comparar_titulos(e, ground_truth[0]) > 80:\n",
        "        hits = 1\n",
        "\n",
        "    # Evitar división por cero\n",
        "    return hits\n",
        "\n",
        "def ndcg_at_k(generated_recommendations, ground_truth, k=10):\n",
        "    # Crear una lista binaria de relevancia (1 si está en ground truth, 0 si no)\n",
        "    relevance = [1 if item in ground_truth else 0 for item in generated_recommendations[:k]]\n",
        "\n",
        "    # Crear el \"ideal ranking\" (todas las relevantes primero)\n",
        "    ideal_relevance = sorted(relevance, reverse=True)\n",
        "\n",
        "    # Calcular NDCG\n",
        "    return ndcg_score([relevance], [ideal_relevance])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W9dFcT15rGqg",
      "metadata": {
        "id": "W9dFcT15rGqg"
      },
      "source": [
        "### Recall@5 y NDCG@5:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610x8P6Krzdc",
      "metadata": {
        "id": "610x8P6Krzdc"
      },
      "source": [
        "### Random:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "HSP0uJwWe5JG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSP0uJwWe5JG",
        "outputId": "3bc679d5-c3ad-454c-ecbc-6a72e71a2797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.0 0.0\n"
          ]
        }
      ],
      "source": [
        "recall_r_1_5 = 0\n",
        "ndcg_r_1_5 = 0\n",
        "best_recall_r_5 = 0\n",
        "best_ndcg_r_5 = 0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Random sin sampling\n",
        "  recall_r_1_5 += recall_at_k(output_r[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "  ndcg_r_1_5 += ndcg_at_k(output_r[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "\n",
        "  # Random con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "  for l in output_r[i]:\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "  best_recall_r_5 += best_r\n",
        "  best_ndcg_r_5 += best_n\n",
        "\n",
        "print(recall_r_1_5/num_test_items, ndcg_r_1_5/num_test_items)\n",
        "print(best_recall_r_5/num_test_items, best_ndcg_r_5/num_test_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C0-S78tSsdE1",
      "metadata": {
        "id": "C0-S78tSsdE1"
      },
      "source": [
        "### Most Popular:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "EXrgfRTkjkd7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXrgfRTkjkd7",
        "outputId": "0cdaf904-a208-4c72-f6e5-5dc64c0b9f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.0 0.0\n"
          ]
        }
      ],
      "source": [
        "recall_mp_1_5 = 0\n",
        "ndcg_mp_1_5 = 0\n",
        "best_recall_mp_5 = 0\n",
        "best_ndcg_mp_5 = 0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Most Popular sin sampling\n",
        "  recall_mp_1_5 += recall_at_k(outputs_mp[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "  ndcg_mp_1_5 += ndcg_at_k(outputs_mp[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "\n",
        "  # Most Popular con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "  for l in outputs_mp[i]:\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "  best_recall_mp_5 += best_r\n",
        "  best_ndcg_mp_5 += best_n\n",
        "\n",
        "print(recall_mp_1_5/num_test_items, ndcg_mp_1_5/num_test_items)\n",
        "print(best_recall_mp_5/num_test_items, best_ndcg_mp_5/num_test_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7Qw82u4Os2mO",
      "metadata": {
        "id": "7Qw82u4Os2mO"
      },
      "source": [
        "### TinyLlama:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "z8V6EPI4nvqU",
      "metadata": {
        "id": "z8V6EPI4nvqU"
      },
      "outputs": [],
      "source": [
        "z_s_rec_lists = []\n",
        "i=1\n",
        "for outputs in outputs_z_s:\n",
        "  rec_lists = []\n",
        "  for out in outputs:\n",
        "      ans = format_ans(out[out.index(\"<|assistant|>\"):],10)\n",
        "      rec_lists.append(format_ans(out[out.index(\"<|assistant|>\"):],10))\n",
        "\n",
        "  # print(rec_lists)\n",
        "  z_s_rec_lists.append(rec_lists)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "KFtGD754n0ao",
      "metadata": {
        "id": "KFtGD754n0ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11df07b-4d05-448c-9444-e9bca00ebbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15 0.024355738985992397\n",
            "0.3 0.050382510846739906\n"
          ]
        }
      ],
      "source": [
        "recall_zs_1_5 = 0\n",
        "ndcg_zs_1_5 = 0\n",
        "best_recall_zs_5 = 0.0\n",
        "best_ndcg_zs_5 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Zero-shot sin sampling\n",
        "  # print(i)\n",
        "  recall_zs_1_5 += recall_at_k(z_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "  if len(z_s_rec_lists[i][0]) > 0:\n",
        "    ndcg_zs_1_5 += ndcg_at_k(z_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "\n",
        "  # Zero-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in z_s_rec_lists[i]:\n",
        "    if len(l) > 0:\n",
        "      recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "      ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_zs_5 += best_r\n",
        "  best_ndcg_zs_5 += best_n\n",
        "print(recall_zs_1_5/num_test_items, ndcg_zs_1_5/num_test_items)\n",
        "print(best_recall_zs_5/num_test_items, best_ndcg_zs_5/num_test_items)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_s_rec_lists = []\n",
        "i=1\n",
        "for outputs in outputs_f_s:\n",
        "  rec_lists = []\n",
        "  for out in outputs:\n",
        "      ans = format_ans(out[out.index(\"<|assistant|>\"):],10)\n",
        "      rec_lists.append(format_ans(out[out.index(\"<|assistant|>\"):],10))\n",
        "\n",
        "  # print(rec_lists)\n",
        "  f_s_rec_lists.append(rec_lists)"
      ],
      "metadata": {
        "id": "2AGf4D8nxxsF"
      },
      "id": "2AGf4D8nxxsF",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in f_s_rec_lists:\n",
        "  print(len(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuCLjGPjE42I",
        "outputId": "d55b0c10-82e8-4620-8da9-f21cb9131a51"
      },
      "id": "cuCLjGPjE42I",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_fs_1_5 = 0\n",
        "ndcg_fs_1_5 = 0\n",
        "best_recall_fs_5 = 0.0\n",
        "best_ndcg_fs_5 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Few-shot sin sampling\n",
        "  # print(f\"\\n{f_s_rec_lists[i][0]}\")\n",
        "  # print([item_map[m] for m in rand_conversations[i][4]])\n",
        "  recall_fs_1_5 += recall_at_k(f_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "  if len(f_s_rec_lists[i][0]) > 0:\n",
        "    ndcg_fs_1_5 += ndcg_at_k(f_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "\n",
        "  # Few-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in f_s_rec_lists[i]:\n",
        "    if len(l) > 0:\n",
        "      recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "      ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_fs_5 += best_r\n",
        "  best_ndcg_fs_5 += best_n\n",
        "print(recall_fs_1_5/num_test_items, ndcg_fs_1_5/num_test_items)\n",
        "print(best_recall_fs_5/num_test_items, best_ndcg_fs_5/num_test_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzbGGXLXxbXH",
        "outputId": "75c4779a-4d94-47ce-c7b9-44ea41db12c2"
      },
      "id": "hzbGGXLXxbXH",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_s_rec_lists = []\n",
        "i=1\n",
        "for outputs in outputs_ft_s:\n",
        "  rec_lists = []\n",
        "  for out in outputs:\n",
        "      ans = format_ans(out[out.index(\"<|assistant|>\"):],10)\n",
        "      if len(ans) >= 10:\n",
        "        rec_lists.append(format_ans(out[out.index(\"<|assistant|>\"):],10))\n",
        "        # print(rec_lists)\n",
        "\n",
        "  # print(rec_lists)\n",
        "  ft_s_rec_lists.append(rec_lists)"
      ],
      "metadata": {
        "id": "tqfJ6hgyRMrN"
      },
      "id": "tqfJ6hgyRMrN",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recall_fts_1_5 = 0\n",
        "ndcg_fts_1_5 = 0\n",
        "best_recall_fts_5 = 0.0\n",
        "best_ndcg_fts_5 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Few-shot sin sampling\n",
        "  # print(f\"\\n{ft_s_rec_lists[i][0]}\")\n",
        "  # print([item_map[m] for m in rand_conversations[i][4]])\n",
        "  recall_fts_1_5 += recall_at_k(ft_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "  ndcg_fts_1_5 += ndcg_at_k(ft_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "\n",
        "  # Few-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in ft_s_rec_lists[i]:\n",
        "    # print(l)\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=5)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_fts_5 += best_r\n",
        "  best_ndcg_fts_5 += best_n\n",
        "print(recall_fts_1_5/num_test_items, ndcg_fts_1_5/num_test_items)\n",
        "print(best_recall_fts_5/num_test_items, best_ndcg_fts_5/num_test_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ1TgaF3RSd4",
        "outputId": "268a24ba-a48a-425e-f4bf-6517866afb34"
      },
      "id": "zQ1TgaF3RSd4",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2 0.0\n",
            "0.3 0.03846399052874361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qmki7Uk51XRq",
      "metadata": {
        "id": "qmki7Uk51XRq"
      },
      "source": [
        "### Recall@10 y NDCG@10:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fWBnd3Sk1n2_",
      "metadata": {
        "id": "fWBnd3Sk1n2_"
      },
      "source": [
        "### Random:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "gQymTKdhyKJU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQymTKdhyKJU",
        "outputId": "89a85cc0-e440-418f-90b2-d1cdd6e32a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.05 0.0\n"
          ]
        }
      ],
      "source": [
        "recall_r_1_10 = 0\n",
        "ndcg_r_1_10 = 0\n",
        "best_recall_r_10 = 0\n",
        "best_ndcg_r_10 = 0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Random sin sampling\n",
        "  recall_r_1_10 += recall_at_k(output_r[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "  ndcg_r_1_10 += ndcg_at_k(output_r[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "\n",
        "  # Random con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "  for l in output_r[i]:\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "  best_recall_r_10 += best_r\n",
        "  best_ndcg_r_10 += best_n\n",
        "\n",
        "print(recall_r_1_10/num_test_items, ndcg_r_1_10/num_test_items)\n",
        "print(best_recall_r_10/num_test_items, best_ndcg_r_10/num_test_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9Ywi5qlc2wAj",
      "metadata": {
        "id": "9Ywi5qlc2wAj"
      },
      "source": [
        "### Most Popular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "7a-oAWCM2xRq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a-oAWCM2xRq",
        "outputId": "4217f6c9-4de5-42da-d8f0-bd8303c0ccc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.0 0.0\n"
          ]
        }
      ],
      "source": [
        "recall_mp_1_10 = 0\n",
        "ndcg_mp_1_10 = 0\n",
        "best_recall_mp_10 = 0\n",
        "best_ndcg_mp_10 = 0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Most Popular sin sampling\n",
        "  recall_mp_1_10 += recall_at_k(outputs_mp[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "  ndcg_mp_1_10 += ndcg_at_k(outputs_mp[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "\n",
        "  # Most Popular con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "  for l in outputs_mp[i]:\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "  best_recall_mp_10 += best_r\n",
        "  best_ndcg_mp_10 += best_n\n",
        "\n",
        "print(recall_mp_1_10/num_test_items, ndcg_mp_1_10/num_test_items)\n",
        "print(best_recall_mp_10/num_test_items, best_ndcg_mp_10/num_test_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ulcmQkL925xU",
      "metadata": {
        "id": "ulcmQkL925xU"
      },
      "source": [
        "### TinyLlama"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_vUG0JzS27dP",
      "metadata": {
        "id": "_vUG0JzS27dP"
      },
      "source": [
        "Zero-Shot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "V2-5q7OS2658",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2-5q7OS2658",
        "outputId": "709f10ed-3ff2-4973-df9e-a113b509fff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.15 0.01968644076715747\n",
            "0.3 0.050382510846739906\n"
          ]
        }
      ],
      "source": [
        "recall_zs_1_10 = 0\n",
        "ndcg_zs_1_10 = 0\n",
        "best_recall_zs_10 = 0.0\n",
        "best_ndcg_zs_10 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Zero-shot sin sampling\n",
        "  if len(z_s_rec_lists[i][0]) > 0:\n",
        "    recall_zs_1_10 += recall_at_k(z_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    ndcg_zs_1_10 += ndcg_at_k(z_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "\n",
        "  # Zero-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in z_s_rec_lists[i]:\n",
        "    if len(l) > 0:\n",
        "      recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "      ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_zs_10 += best_r\n",
        "  best_ndcg_zs_10 += best_n\n",
        "print(recall_zs_1_10/num_test_items, ndcg_zs_1_10/num_test_items)\n",
        "print(best_recall_zs_10/num_test_items, best_ndcg_zs_10/num_test_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TfxN0Sbb3MQU",
      "metadata": {
        "id": "TfxN0Sbb3MQU"
      },
      "source": [
        "Few-Shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "eTt6k8Rm3NAE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTt6k8Rm3NAE",
        "outputId": "304d2090-8e92-41ad-ca94-76f009667cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 0.0\n",
            "0.05 0.0\n"
          ]
        }
      ],
      "source": [
        "recall_fs_1_10 = 0\n",
        "ndcg_fs_1_10 = 0\n",
        "best_recall_fs_10 = 0.0\n",
        "best_ndcg_fs_10 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Few-shot sin sampling\n",
        "  # print(f\"\\n{f_s_rec_lists[i][0]}\")\n",
        "  # print([item_map[m] for m in rand_conversations[i][4]])\n",
        "  if len(f_s_rec_lists[i][0]) > 0:\n",
        "    recall_fs_1_10 += recall_at_k(f_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    ndcg_fs_1_10 += ndcg_at_k(f_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "\n",
        "  # Few-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in f_s_rec_lists[i]:\n",
        "    if len(l) > 0:\n",
        "      recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "      ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_fs_10 += best_r\n",
        "  best_ndcg_fs_10 += best_n\n",
        "print(recall_fs_1_10/num_test_items, ndcg_fs_1_10/num_test_items)\n",
        "print(best_recall_fs_10/num_test_items, best_ndcg_fs_10/num_test_items)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall_fts_1_10 = 0\n",
        "ndcg_fts_1_10 = 0\n",
        "best_recall_fts_10 = 0.0\n",
        "best_ndcg_fts_10 = 0.0\n",
        "\n",
        "for i in range(num_test_items):\n",
        "  # Few-shot sin sampling\n",
        "  # print(f\"\\n{ft_s_rec_lists[i][0]}\")\n",
        "  # print([item_map[m] for m in rand_conversations[i][4]])\n",
        "  recall_fts_1_10 += recall_at_k(ft_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "  ndcg_fts_1_10 += ndcg_at_k(ft_s_rec_lists[i][0], [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "\n",
        "  # Few-shot con sampling\n",
        "  best_r = 0.0\n",
        "  best_n = 0.0\n",
        "\n",
        "  for l in ft_s_rec_lists[i]:\n",
        "    recall = recall_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    ndcg = ndcg_at_k(l, [item_map[m] for m in rand_conversations[i][4]], k=10)\n",
        "    if recall > best_r:\n",
        "      best_r = recall\n",
        "    if ndcg > best_n:\n",
        "      best_n = ndcg\n",
        "\n",
        "  best_recall_fts_10 += best_r\n",
        "  best_ndcg_fts_10 += best_n\n",
        "print(recall_fts_1_10/num_test_items, ndcg_fts_1_10/num_test_items)\n",
        "print(best_recall_fts_10/num_test_items, best_ndcg_fts_10/num_test_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bb9hE3VYSz6",
        "outputId": "1438a74f-1b6d-49b7-bcc7-d5756147db82"
      },
      "id": "8bb9hE3VYSz6",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2 0.0\n",
            "0.3 0.036161691583200956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "UzWXLtfi3XxD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzWXLtfi3XxD",
        "outputId": "5cd31d5d-95e7-4ecd-fca1-2e24e675a769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random:\n",
            "Sin sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.0, NDCG@10: 0.0\n",
            "Con sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.05, NDCG@10: 0.0\n",
            "\n",
            "Most Popular:\n",
            "Sin sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.0, NDCG@10: 0.0\n",
            "Con sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.0, NDCG@10: 0.0\n",
            "\n",
            "Zero-Shot con interacciones históricas:\n",
            "Sin sampling: Recall@5: 0.15, NDCG@5: 0.024355738985992397, Recall@10: 0.15, NDCG@10: 0.01968644076715747\n",
            "Con sampling: Recall@5: 0.3, NDCG@5: 0.050382510846739906, Recall@10: 0.3, NDCG@10: 0.050382510846739906\n",
            "\n",
            "Few-Shot con interacciones históricas:\n",
            "Sin sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.0, NDCG@10: 0.0\n",
            "Con sampling: Recall@5: 0.0, NDCG@5: 0.0, Recall@10: 0.05, NDCG@10: 0.0\n",
            "\n",
            "Fine-tuned con interacciones históricas:\n",
            "Sin sampling: Recall@5: 0.2, NDCG@5: 0.0, Recall@10: 0.2, NDCG@10: 0.0\n",
            "Con sampling: Recall@5: 0.3, NDCG@5: 0.03846399052874361, Recall@10: 0.3, NDCG@10: 0.036161691583200956\n"
          ]
        }
      ],
      "source": [
        "print(\"Random:\")\n",
        "print(f\"Sin sampling: Recall@5: {recall_r_1_5/num_test_items}, NDCG@5: {ndcg_r_1_5/num_test_items}, Recall@10: {recall_r_1_10/num_test_items}, NDCG@10: {ndcg_r_1_10/num_test_items}\")\n",
        "print(f\"Con sampling: Recall@5: {best_recall_r_5/num_test_items}, NDCG@5: {best_ndcg_r_5/num_test_items}, Recall@10: {best_recall_r_10/num_test_items}, NDCG@10: {best_ndcg_r_10/num_test_items}\")\n",
        "\n",
        "print(\"\\nMost Popular:\")\n",
        "print(f\"Sin sampling: Recall@5: {recall_mp_1_5/num_test_items}, NDCG@5: {ndcg_mp_1_5/num_test_items}, Recall@10: {recall_mp_1_10/num_test_items}, NDCG@10: {ndcg_mp_1_10/num_test_items}\")\n",
        "print(f\"Con sampling: Recall@5: {best_recall_mp_5/num_test_items}, NDCG@5: {best_ndcg_mp_5/num_test_items}, Recall@10: {best_recall_mp_10/num_test_items}, NDCG@10: {best_ndcg_mp_10/num_test_items}\")\n",
        "\n",
        "# print(\"\\nZero-Shot sin interacciones históricas:\")\n",
        "# print(f\"Sin sampling: Recall@5: {recall_zn_1_5/num_test_items}, NDCG@5: {ndcg_zn_1_5/num_test_items}, Recall@10: {recall_zn_1_10/num_test_items}, NDCG@10: {ndcg_zn_1_10/num_test_items}\")\n",
        "# print(f\"Con sampling: Recall@5: {best_recall_zn_5/num_test_items}, NDCG@5: {best_ndcg_zn_5/num_test_items}, Recall@10: {best_recall_zn_10/num_test_items}, NDCG@10: {best_ndcg_zn_10/num_test_items}\")\n",
        "\n",
        "print(\"\\nZero-Shot con interacciones históricas:\")\n",
        "print(f\"Sin sampling: Recall@5: {recall_zs_1_5/num_test_items}, NDCG@5: {ndcg_zs_1_5/num_test_items}, Recall@10: {recall_zs_1_10/num_test_items}, NDCG@10: {ndcg_zs_1_10/num_test_items}\")\n",
        "print(f\"Con sampling: Recall@5: {best_recall_zs_5/num_test_items}, NDCG@5: {best_ndcg_zs_5/num_test_items}, Recall@10: {best_recall_zs_10/num_test_items}, NDCG@10: {best_ndcg_zs_10/num_test_items}\")\n",
        "\n",
        "# print(\"\\nFew-Shot sin interacciones históricas:\")\n",
        "# print(f\"Sin sampling: Recall@5: {recall_fn_1_5/num_test_items}, NDCG@5: {ndcg_fn_1_5/num_test_items}, Recall@10: {recall_fn_1_10/num_test_items}, NDCG@10: {ndcg_fn_1_10/num_test_items}\")\n",
        "# print(f\"Con sampling: Recall@5: {best_recall_fn_5/num_test_items}, NDCG@5: {best_ndcg_fn_5/num_test_items}, Recall@10: {best_recall_fn_10/num_test_items}, NDCG@10: {best_ndcg_fn_10/num_test_items}\")\n",
        "\n",
        "print(\"\\nFew-Shot con interacciones históricas:\")\n",
        "print(f\"Sin sampling: Recall@5: {recall_fs_1_5/num_test_items}, NDCG@5: {ndcg_fs_1_5/num_test_items}, Recall@10: {recall_fs_1_10/num_test_items}, NDCG@10: {ndcg_fs_1_10/num_test_items}\")\n",
        "print(f\"Con sampling: Recall@5: {best_recall_fs_5/num_test_items}, NDCG@5: {best_ndcg_fs_5/num_test_items}, Recall@10: {best_recall_fs_10/num_test_items}, NDCG@10: {best_ndcg_fs_10/num_test_items}\")\n",
        "\n",
        "print(\"\\nFine-tuned con interacciones históricas:\")\n",
        "print(f\"Sin sampling: Recall@5: {recall_fts_1_5/num_test_items}, NDCG@5: {ndcg_fts_1_5/num_test_items}, Recall@10: {recall_fts_1_10/num_test_items}, NDCG@10: {ndcg_fts_1_10/num_test_items}\")\n",
        "print(f\"Con sampling: Recall@5: {best_recall_fts_5/num_test_items}, NDCG@5: {best_ndcg_fts_5/num_test_items}, Recall@10: {best_recall_fts_10/num_test_items}, NDCG@10: {best_ndcg_fts_10/num_test_items}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWy3oCvI4PsI",
        "outputId": "b07de7da-b4f9-4e37-f646-db8b74cb7e4b"
      },
      "id": "JWy3oCvI4PsI",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LlamaForCausalLM(\n",
              "  (model): LlamaModel(\n",
              "    (embed_tokens): Embedding(32000, 2048)\n",
              "    (layers): ModuleList(\n",
              "      (0-21): 22 x LlamaDecoderLayer(\n",
              "        (self_attn): LlamaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): LlamaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
              "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
              "    (rotary_emb): LlamaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "import gc\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from scipy.stats import entropy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def extract_answer(text, question_text):\n",
        "    \"\"\"Extrae la respuesta del texto generado\"\"\"\n",
        "    # Buscar después de \"Answer:\" o similar\n",
        "    patterns = [r\"Answer:\\s*(.+?)(?:\\n|$)\", r\"answer:\\s*(.+?)(?:\\n|$)\", r\"Answer is\\s*(.+?)(?:\\n|$)\"]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "\n",
        "    # Si no encuentra patrón, tomar lo que viene después del prompt\n",
        "    try:\n",
        "        # Dividir por el texto de la pregunta y tomar la parte después\n",
        "        parts = text.split(\"Answer:\")\n",
        "        if len(parts) > 1:\n",
        "            return parts[-1].strip().split('\\n')[0].strip()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def calculate_uncertainty_metrics_lightweight(outputs_per_paraphrase, paraphrases):\n",
        "    \"\"\"\n",
        "    Calcula métricas de incertidumbre usando Input Clarification Ensembling\n",
        "\n",
        "    Args:\n",
        "        outputs_per_paraphrase: Lista de listas, cada sublista contiene outputs para una paráfrasis\n",
        "        paraphrases: Lista de paráfrasis usadas\n",
        "\n",
        "    Returns:\n",
        "        dict con métricas de incertidumbre\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Extraer respuestas limpias\n",
        "    all_answers = []\n",
        "    answers_by_paraphrase = []\n",
        "\n",
        "    for i, outputs in enumerate(outputs_per_paraphrase):\n",
        "        paraphrase_answers = []\n",
        "        for output in outputs:\n",
        "            answer = extract_answer(output, paraphrases[i])\n",
        "            paraphrase_answers.append(answer)\n",
        "            all_answers.append(answer)\n",
        "        answers_by_paraphrase.append(paraphrase_answers)\n",
        "\n",
        "    # 2. Calcular frecuencias de respuestas\n",
        "    answer_counts = Counter(all_answers)\n",
        "    total_responses = len(all_answers)\n",
        "\n",
        "    # 3. INCERTIDUMBRE TOTAL (Shannon Entropy de todas las respuestas)\n",
        "    probs = np.array(list(answer_counts.values())) / total_responses\n",
        "    total_uncertainty = entropy(probs, base=2)  # bits\n",
        "\n",
        "    # 4. INCERTIDUMBRE ALEATORIA (promedio de entropías por paráfrasis)\n",
        "    aleatoric_uncertainties = []\n",
        "    for answers in answers_by_paraphrase:\n",
        "        local_counts = Counter(answers)\n",
        "        local_probs = np.array(list(local_counts.values())) / len(answers)\n",
        "        if len(local_probs) > 1:\n",
        "            aleatoric_uncertainties.append(entropy(local_probs, base=2))\n",
        "        else:\n",
        "            aleatoric_uncertainties.append(0.0)\n",
        "\n",
        "    aleatoric_uncertainty = np.mean(aleatoric_uncertainties)\n",
        "\n",
        "    # 5. INCERTIDUMBRE EPISTÉMICA (diferencia)\n",
        "    epistemic_uncertainty = total_uncertainty - aleatoric_uncertainty\n",
        "\n",
        "    # 6. Métricas adicionales\n",
        "    unique_answers = len(set(all_answers))\n",
        "    most_common_answer, most_common_count = answer_counts.most_common(1)[0]\n",
        "    confidence = most_common_count / total_responses\n",
        "\n",
        "    # 7. Consistencia entre paráfrasis\n",
        "    consistency_scores = []\n",
        "    for i in range(len(paraphrases)):\n",
        "        for j in range(i+1, len(paraphrases)):\n",
        "            # Comparar respuestas más frecuentes de cada paráfrasis\n",
        "            answers_i = Counter(answers_by_paraphrase[i])\n",
        "            answers_j = Counter(answers_by_paraphrase[j])\n",
        "\n",
        "            most_common_i = answers_i.most_common(1)[0][0] if answers_i else \"\"\n",
        "            most_common_j = answers_j.most_common(1)[0][0] if answers_j else \"\"\n",
        "\n",
        "            # Similaridad simple (exacta o parcial)\n",
        "            if most_common_i.lower().strip() == most_common_j.lower().strip():\n",
        "                consistency_scores.append(1.0)\n",
        "            else:\n",
        "                # Similaridad parcial usando tokens comunes\n",
        "                tokens_i = set(most_common_i.lower().split())\n",
        "                tokens_j = set(most_common_j.lower().split())\n",
        "                if tokens_i and tokens_j:\n",
        "                    jaccard = len(tokens_i.intersection(tokens_j)) / len(tokens_i.union(tokens_j))\n",
        "                    consistency_scores.append(jaccard)\n",
        "                else:\n",
        "                    consistency_scores.append(0.0)\n",
        "\n",
        "    consistency = np.mean(consistency_scores) if consistency_scores else 0.0\n",
        "\n",
        "    return {\n",
        "        'total_uncertainty': float(total_uncertainty),\n",
        "        'aleatoric_uncertainty': float(aleatoric_uncertainty),\n",
        "        'epistemic_uncertainty': float(epistemic_uncertainty),\n",
        "        'confidence': float(confidence),\n",
        "        'unique_answers': int(unique_answers),\n",
        "        'most_common_answer': str(most_common_answer),\n",
        "        'consistency_across_paraphrases': float(consistency),\n",
        "        'answer_distribution': {str(k): int(v) for k, v in answer_counts.items()},\n",
        "        'num_paraphrases': len(paraphrases),\n",
        "        'samples_per_paraphrase': len(outputs_per_paraphrase[0]) if outputs_per_paraphrase else 0\n",
        "    }\n",
        "\n",
        "def calculate_logit_uncertainty_lightweight(model, tokenizer, paraphrases, device=\"cuda\", cleanup=True):\n",
        "    \"\"\"\n",
        "    Versión optimizada que limpia memoria agresivamente\n",
        "    \"\"\"\n",
        "    print(\"Calculando incertidumbre por logits (versión ligera)...\")\n",
        "\n",
        "    uncertainties_per_paraphrase = []\n",
        "    logits_stats = []\n",
        "\n",
        "    for i, paraphrase in enumerate(paraphrases):\n",
        "        print(f\"Procesando logits para paráfrasis {i+1}/{len(paraphrases)}\")\n",
        "\n",
        "        ctx = \"You are an oracle who only responds with short and concise answers.\"\n",
        "        msg = f\"Answer the following question: {paraphrase}\\nAnswer:\"\n",
        "        messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n",
        "\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            next_token_logits = outputs.logits[0, -1, :].cpu()  # Mover a CPU inmediatamente\n",
        "\n",
        "            # Calcular probabilidades y entropía\n",
        "            probs = torch.softmax(next_token_logits, dim=-1)\n",
        "            uncertainty = entropy(probs.numpy(), base=2)\n",
        "            uncertainties_per_paraphrase.append(float(uncertainty))\n",
        "\n",
        "            # Guardar solo estadísticas básicas, no los logits completos\n",
        "            logits_stats.append({\n",
        "                'mean': float(next_token_logits.mean()),\n",
        "                'std': float(next_token_logits.std()),\n",
        "                'max': float(next_token_logits.max()),\n",
        "                'min': float(next_token_logits.min())\n",
        "            })\n",
        "\n",
        "            # Limpiar memoria inmediatamente\n",
        "            del outputs, next_token_logits, probs, inputs\n",
        "            if cleanup:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "    # Calcular métricas finales sin guardar arrays grandes\n",
        "    mean_uncertainty = np.mean(uncertainties_per_paraphrase)\n",
        "    std_uncertainty = np.std(uncertainties_per_paraphrase)\n",
        "\n",
        "    return {\n",
        "        'logit_uncertainties_per_paraphrase': uncertainties_per_paraphrase,\n",
        "        'mean_logit_uncertainty': float(mean_uncertainty),\n",
        "        'std_logit_uncertainty': float(std_uncertainty),\n",
        "        'logits_stats_summary': {\n",
        "            'mean_of_means': float(np.mean([s['mean'] for s in logits_stats])),\n",
        "            'mean_of_stds': float(np.mean([s['std'] for s in logits_stats])),\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "sIndZYYaOO60"
      },
      "id": "sIndZYYaOO60",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuración\n",
        "model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # o el modelo que uses\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Cargar modelo y tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Paráfrasis de la pregunta\n",
        "paraphrases = [\n",
        "    \"What year did the Berlin Wall fall?\",\n",
        "    \"When did the Berlin Wall come down?\",\n",
        "    \"In which year was the Berlin Wall demolished?\",\n",
        "    \"What year did the fall of the Berlin Wall occur?\",\n",
        "    \"When was the Berlin Wall brought down?\",\n",
        "    \"In what year did the Berlin Wall collapse?\",\n",
        "    \"What year did they tear down the Berlin Wall?\",\n",
        "    \"When did the destruction of the Berlin Wall happen?\",\n",
        "    \"In which year did the Berlin Wall get demolished?\",\n",
        "    \"What year marked the fall of the Berlin Wall?\"\n",
        "]\n",
        "\n",
        "# Generar respuestas con sampling\n",
        "outputs_per_paraphrase = []\n",
        "k = 5  # Número de samples por paráfrasis\n",
        "\n",
        "print(\"Generando respuestas...\")\n",
        "for i, paraphrase in enumerate(paraphrases):\n",
        "    print(f\"Procesando paráfrasis {i+1}/{len(paraphrases)}: {paraphrase}\")\n",
        "\n",
        "    outputs = []\n",
        "    ctx = \"You are an oracle who only responds with short and concise answers.\"\n",
        "    msg = f\"Answer the following question: {paraphrase}\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n",
        "\n",
        "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    for j in range(k):\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_k=50,\n",
        "                top_p=0.95,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decodificar solo la parte nueva (sin el prompt)\n",
        "            new_tokens = output_ids[0][inputs['input_ids'].shape[1]:]\n",
        "            decoded = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "            outputs.append(decoded)\n",
        "\n",
        "    outputs_per_paraphrase.append(outputs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXg4zGJy4D6e",
        "outputId": "3268e98d-e674-4820-8f71-d54775586785"
      },
      "id": "vXg4zGJy4D6e",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando respuestas...\n",
            "Procesando paráfrasis 1/10: What year did the Berlin Wall fall?\n",
            "Procesando paráfrasis 2/10: When did the Berlin Wall come down?\n",
            "Procesando paráfrasis 3/10: In which year was the Berlin Wall demolished?\n",
            "Procesando paráfrasis 4/10: What year did the fall of the Berlin Wall occur?\n",
            "Procesando paráfrasis 5/10: When was the Berlin Wall brought down?\n",
            "Procesando paráfrasis 6/10: In what year did the Berlin Wall collapse?\n",
            "Procesando paráfrasis 7/10: What year did they tear down the Berlin Wall?\n",
            "Procesando paráfrasis 8/10: When did the destruction of the Berlin Wall happen?\n",
            "Procesando paráfrasis 9/10: In which year did the Berlin Wall get demolished?\n",
            "Procesando paráfrasis 10/10: What year marked the fall of the Berlin Wall?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "include_logits = True\n",
        "cleanup_model = True"
      ],
      "metadata": {
        "id": "WuCMGEixYJQF"
      },
      "id": "WuCMGEixYJQF",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*50)\n",
        "print(\"CALCULANDO INCERTIDUMBRE (VERSIÓN OPTIMIZADA)...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Calcular métricas básicas de incertidumbre\n",
        "uncertainty_metrics = calculate_uncertainty_metrics_lightweight(outputs_per_paraphrase, paraphrases)\n",
        "\n",
        "# 2. Calcular métricas de logits si se solicita\n",
        "logit_metrics = None\n",
        "if include_logits and model is not None and tokenizer is not None:\n",
        "    logit_metrics = calculate_logit_uncertainty_lightweight(\n",
        "        model, tokenizer, paraphrases, device, cleanup=True\n",
        "    )\n",
        "\n",
        "# 3. LIMPIAR MODELO DE MEMORIA SI SE SOLICITA\n",
        "if cleanup_model and model is not None:\n",
        "    print(\"Limpiando modelo de memoria...\")\n",
        "    del model\n",
        "    if tokenizer is not None:\n",
        "        del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"✓ Modelo removido de memoria\")\n",
        "\n",
        "# 4. Mostrar resultados\n",
        "print(f\"\\n📊 MÉTRICAS DE INCERTIDUMBRE:\")\n",
        "print(f\"├── Incertidumbre Total: {uncertainty_metrics['total_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Incertidumbre Aleatoria: {uncertainty_metrics['aleatoric_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Incertidumbre Epistémica: {uncertainty_metrics['epistemic_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Confianza: {uncertainty_metrics['confidence']:.3f}\")\n",
        "print(f\"├── Respuestas únicas: {uncertainty_metrics['unique_answers']}\")\n",
        "print(f\"├── Consistencia entre paráfrasis: {uncertainty_metrics['consistency_across_paraphrases']:.3f}\")\n",
        "print(f\"└── Respuesta más común: '{uncertainty_metrics['most_common_answer']}'\")\n",
        "\n",
        "if logit_metrics:\n",
        "    print(f\"\\n🔢 MÉTRICAS DE LOGITS:\")\n",
        "    print(f\"├── Incertidumbre promedio: {logit_metrics['mean_logit_uncertainty']:.3f} bits\")\n",
        "    print(f\"├── Desviación estándar: {logit_metrics['std_logit_uncertainty']:.3f} bits\")\n",
        "    print(f\"└── Media de logits: {logit_metrics['logits_stats_summary']['mean_of_means']:.3f}\")\n",
        "\n",
        "# 5. Interpretación\n",
        "print(f\"\\n🧠 INTERPRETACIÓN:\")\n",
        "if uncertainty_metrics['epistemic_uncertainty'] > uncertainty_metrics['aleatoric_uncertainty']:\n",
        "    print(\"├── El modelo tiene más incertidumbre sobre QUÉ responder\")\n",
        "    print(\"└── → Sugiere falta de conocimiento específico\")\n",
        "else:\n",
        "    print(\"├── El modelo tiene más incertidumbre sobre CÓMO responder\")\n",
        "    print(\"└── → Sugiere ambigüedad inherente en la pregunta\")\n",
        "\n",
        "if uncertainty_metrics['consistency_across_paraphrases'] > 0.8:\n",
        "    print(\"├── Alta consistencia entre paráfrasis\")\n",
        "elif uncertainty_metrics['consistency_across_paraphrases'] > 0.5:\n",
        "    print(\"├── Consistencia moderada entre paráfrasis\")\n",
        "else:\n",
        "    print(\"├── Baja consistencia - posible confusión del modelo\")\n",
        "\n",
        "# DEVOLVER SOLO RESULTADOS LIGEROS\n",
        "results = {\n",
        "    'uncertainty_metrics': uncertainty_metrics,\n",
        "    'logit_metrics': logit_metrics,\n",
        "    'analysis_params': {\n",
        "        'num_paraphrases': len(paraphrases),\n",
        "        'samples_per_paraphrase': len(outputs_per_paraphrase[0]) if outputs_per_paraphrase else 0,\n",
        "        'included_logits': include_logits\n",
        "    }\n",
        "}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7IbxEarPAV0",
        "outputId": "28aff982-0159-42e2-ce68-a225bc5bfd33"
      },
      "id": "J7IbxEarPAV0",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "CALCULANDO INCERTIDUMBRE (VERSIÓN OPTIMIZADA)...\n",
            "==================================================\n",
            "Respuestas extraídas:\n",
            "Paráfrasis 1: [\"The Berlin Wall fell in 1989, on November 9, 1989, when East Germany's government announced the end of the wall separating East and West Berlin.\", 'The Berlin Wall fell on November 9, 1989, marking the end of the Cold War and the division of East and West Germany.', 'The Berlin Wall fell on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union.', 'The Berlin Wall fell on November 9, 1989, which was 24 years ago.', 'The Berlin Wall fell on November 9, 1989, at 03:15 a.m. CET (Central European Time) in the early morning hours of November 9, 1989.']\n",
            "Paráfrasis 2: ['The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union.', \"The Berlin Wall came down on November 9, 1989, on the evening of that day. The Soviet Union's fall from power and the subsequent peaceful reunification of Germany marked a historic turning point in Europe's history\", 'The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union. The wall was constructed by the East German government to keep East Germans from escaping to', 'The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Eastern Bloc.', 'The Berlin Wall came down on November 9, 1989, after the Soviet Union had officially withdrawn its troops from the eastern part of Germany. This event marked the end of the Cold War and the collapse of the Eastern B']\n",
            "Paráfrasis 3: ['The Berlin Wall was demolished on November 9, 1989.', 'In 1989, the Berlin Wall was demolished.', 'The question states that you are an oracle who only responds with short and concise answers. The answer to the question is in 1989, when the Berlin Wall was demolished.', 'In 1989, the Berlin Wall was demolished, which marked the end of the Cold War and the division of Europe.', 'The Berlin Wall was demolished in 1989, which was the year the wall was officially dismantled.']\n",
            "Paráfrasis 4: ['The fall of the Berlin Wall occurred in 1989, not 1984 as stated in the given text.', 'The fall of the Berlin Wall occurred in 1989, which was 31 years ago.', 'The fall of the Berlin Wall occurred in 1989, which was also the year that the Soviet Union officially dismantled its military presence in the country.', 'The fall of the Berlin Wall occurred in 1989.', 'The fall of the Berlin Wall occurred in 1989, not in 1987.']\n",
            "Paráfrasis 5: ['The Berlin Wall was brought down on November 9, 1989, by East German soldiers with a barricade made of concrete and barbed wire.', 'The Berlin Wall was brought down on November 9, 1989, after the Soviet Union allowed German citizens to travel freely for the first time in decades.', 'The Berlin Wall was brought down on November 9, 1989, when East German border guards opened fire on a group of demonstrators attempting to cross the border from West Berlin into East Germany. The event led to the collapse of', 'The Berlin Wall was brought down on November 9, 1989, by the East German government, following a series of protests and demonstrations that began on November 9, 1989, calling for the release of', 'The Berlin Wall was brought down on October 3, 1989, by a group of East German soldiers and civilians, led by East German General Walter Ulbricht, who had been sent to negotiate with the West German']\n",
            "Paráfrasis 6: ['The Berlin Wall collapsed in 1989, at the beginning of the fall of the Berlin Wall.', 'The Berlin Wall collapsed in 1989, not in 1981 as stated in the given material.', 'The Berlin Wall collapsed in 1989, the year 1989.', 'The Berlin Wall collapsed on November 9, 1989, in the early hours of the morning.', 'The Berlin Wall collapsed on November 9, 1989, marking the end of the Cold War and the fall of the Soviet Union.']\n",
            "Paráfrasis 7: ['The year when the Berlin Wall was torn down is not specified in the given text.', 'The question is not directly related to the given material.', 'that it was on November 9, 1989, when East Germany officially announced its independence from the Soviet Union and the wall was removed.', '1989.', 'The question does not specify a year for which they tear down the Berlin Wall.']\n",
            "Paráfrasis 8: ['The destruction of the Berlin Wall happened on November 9, 1989, when Soviet forces removed the border barrier that had separated East and West Berlin for over 28 years.', 'The destruction of the Berlin Wall happened on November 9, 1989, when East German troops and police forcibly removed barbed wire and blockades from the eastern side of the city, allowing West Berliners to cross over', 'The destruction of the Berlin Wall happened on November 9, 1989, when East German officials unveiled a new wall that sealed off East Berlin from the rest of West Berlin. The wall had been built as a symbol of', 'The destruction of the Berlin Wall happened on November 9, 1989, when East Germany officially abandoned its border with the West and began to open its borders to West Germans. The Wall had been erected in 196', 'The destruction of the Berlin Wall happened on October 3, 1989, after the fall of the Soviet Union.']\n",
            "Paráfrasis 9: ['The Berlin Wall got demolished in 1989, during the Cold War era.', 'The Berlin Wall was demolished on November 9, 1989, in the early hours of the morning after the German Democratic Republic (GDR) government announced its intention to dismantle it.', 'The Berlin Wall got demolished on August 15, 1961, in the early hours of the morning.', 'The Berlin Wall got demolished in 1989.', 'The Berlin Wall was demolished on November 9, 1989.']\n",
            "Paráfrasis 10: [\"The fall of the Berlin Wall occurred in 1989, marking the end of the Cold War and the end of the Soviet Union's control over East Germany.\", 'The fall of the Berlin Wall occurred in 1989, not 1989 as stated in the given text.', 'The fall of the Berlin Wall occurred in 1989, which was a year before the question was asked.', 'The fall of the Berlin Wall occurred in 1989, not in 1984.', 'The fall of the Berlin Wall, which occurred in 1989, marked the end of the Cold War and the collapse of the Soviet Union. The fall of the wall was a turning point in history, signaling the end of a long']\n",
            "Calculando incertidumbre por logits (versión ligera)...\n",
            "Procesando logits para paráfrasis 1/10\n",
            "Procesando logits para paráfrasis 2/10\n",
            "Procesando logits para paráfrasis 3/10\n",
            "Procesando logits para paráfrasis 4/10\n",
            "Procesando logits para paráfrasis 5/10\n",
            "Procesando logits para paráfrasis 6/10\n",
            "Procesando logits para paráfrasis 7/10\n",
            "Procesando logits para paráfrasis 8/10\n",
            "Procesando logits para paráfrasis 9/10\n",
            "Procesando logits para paráfrasis 10/10\n",
            "Limpiando modelo de memoria...\n",
            "✓ Modelo removido de memoria\n",
            "\n",
            "📊 MÉTRICAS DE INCERTIDUMBRE:\n",
            "├── Incertidumbre Total: 5.604 bits\n",
            "├── Incertidumbre Aleatoria: 2.322 bits\n",
            "├── Incertidumbre Epistémica: 3.282 bits\n",
            "├── Confianza: 0.040\n",
            "├── Respuestas únicas: 49\n",
            "├── Consistencia entre paráfrasis: 0.233\n",
            "└── Respuesta más común: 'The Berlin Wall was demolished on November 9, 1989.'\n",
            "\n",
            "🔢 MÉTRICAS DE LOGITS:\n",
            "├── Incertidumbre promedio: 0.926 bits\n",
            "├── Desviación estándar: 0.528 bits\n",
            "└── Media de logits: -1.714\n",
            "\n",
            "🧠 INTERPRETACIÓN:\n",
            "├── El modelo tiene más incertidumbre sobre QUÉ responder\n",
            "└── → Sugiere falta de conocimiento específico\n",
            "├── Baja consistencia - posible confusión del modelo\n",
            "{'uncertainty_metrics': {'total_uncertainty': 5.603856189774723, 'aleatoric_uncertainty': 2.3219280948873626, 'epistemic_uncertainty': 3.281928094887361, 'confidence': 0.04, 'unique_answers': 49, 'most_common_answer': 'The Berlin Wall was demolished on November 9, 1989.', 'consistency_across_paraphrases': 0.2328805773295286, 'answer_distribution': {\"The Berlin Wall fell in 1989, on November 9, 1989, when East Germany's government announced the end of the wall separating East and West Berlin.\": 1, 'The Berlin Wall fell on November 9, 1989, marking the end of the Cold War and the division of East and West Germany.': 1, 'The Berlin Wall fell on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union.': 1, 'The Berlin Wall fell on November 9, 1989, which was 24 years ago.': 1, 'The Berlin Wall fell on November 9, 1989, at 03:15 a.m. CET (Central European Time) in the early morning hours of November 9, 1989.': 1, 'The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union.': 1, \"The Berlin Wall came down on November 9, 1989, on the evening of that day. The Soviet Union's fall from power and the subsequent peaceful reunification of Germany marked a historic turning point in Europe's history\": 1, 'The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Soviet Union. The wall was constructed by the East German government to keep East Germans from escaping to': 1, 'The Berlin Wall came down on November 9, 1989, marking the end of the Cold War and the collapse of the Eastern Bloc.': 1, 'The Berlin Wall came down on November 9, 1989, after the Soviet Union had officially withdrawn its troops from the eastern part of Germany. This event marked the end of the Cold War and the collapse of the Eastern B': 1, 'The Berlin Wall was demolished on November 9, 1989.': 2, 'In 1989, the Berlin Wall was demolished.': 1, 'The question states that you are an oracle who only responds with short and concise answers. The answer to the question is in 1989, when the Berlin Wall was demolished.': 1, 'In 1989, the Berlin Wall was demolished, which marked the end of the Cold War and the division of Europe.': 1, 'The Berlin Wall was demolished in 1989, which was the year the wall was officially dismantled.': 1, 'The fall of the Berlin Wall occurred in 1989, not 1984 as stated in the given text.': 1, 'The fall of the Berlin Wall occurred in 1989, which was 31 years ago.': 1, 'The fall of the Berlin Wall occurred in 1989, which was also the year that the Soviet Union officially dismantled its military presence in the country.': 1, 'The fall of the Berlin Wall occurred in 1989.': 1, 'The fall of the Berlin Wall occurred in 1989, not in 1987.': 1, 'The Berlin Wall was brought down on November 9, 1989, by East German soldiers with a barricade made of concrete and barbed wire.': 1, 'The Berlin Wall was brought down on November 9, 1989, after the Soviet Union allowed German citizens to travel freely for the first time in decades.': 1, 'The Berlin Wall was brought down on November 9, 1989, when East German border guards opened fire on a group of demonstrators attempting to cross the border from West Berlin into East Germany. The event led to the collapse of': 1, 'The Berlin Wall was brought down on November 9, 1989, by the East German government, following a series of protests and demonstrations that began on November 9, 1989, calling for the release of': 1, 'The Berlin Wall was brought down on October 3, 1989, by a group of East German soldiers and civilians, led by East German General Walter Ulbricht, who had been sent to negotiate with the West German': 1, 'The Berlin Wall collapsed in 1989, at the beginning of the fall of the Berlin Wall.': 1, 'The Berlin Wall collapsed in 1989, not in 1981 as stated in the given material.': 1, 'The Berlin Wall collapsed in 1989, the year 1989.': 1, 'The Berlin Wall collapsed on November 9, 1989, in the early hours of the morning.': 1, 'The Berlin Wall collapsed on November 9, 1989, marking the end of the Cold War and the fall of the Soviet Union.': 1, 'The year when the Berlin Wall was torn down is not specified in the given text.': 1, 'The question is not directly related to the given material.': 1, 'that it was on November 9, 1989, when East Germany officially announced its independence from the Soviet Union and the wall was removed.': 1, '1989.': 1, 'The question does not specify a year for which they tear down the Berlin Wall.': 1, 'The destruction of the Berlin Wall happened on November 9, 1989, when Soviet forces removed the border barrier that had separated East and West Berlin for over 28 years.': 1, 'The destruction of the Berlin Wall happened on November 9, 1989, when East German troops and police forcibly removed barbed wire and blockades from the eastern side of the city, allowing West Berliners to cross over': 1, 'The destruction of the Berlin Wall happened on November 9, 1989, when East German officials unveiled a new wall that sealed off East Berlin from the rest of West Berlin. The wall had been built as a symbol of': 1, 'The destruction of the Berlin Wall happened on November 9, 1989, when East Germany officially abandoned its border with the West and began to open its borders to West Germans. The Wall had been erected in 196': 1, 'The destruction of the Berlin Wall happened on October 3, 1989, after the fall of the Soviet Union.': 1, 'The Berlin Wall got demolished in 1989, during the Cold War era.': 1, 'The Berlin Wall was demolished on November 9, 1989, in the early hours of the morning after the German Democratic Republic (GDR) government announced its intention to dismantle it.': 1, 'The Berlin Wall got demolished on August 15, 1961, in the early hours of the morning.': 1, 'The Berlin Wall got demolished in 1989.': 1, \"The fall of the Berlin Wall occurred in 1989, marking the end of the Cold War and the end of the Soviet Union's control over East Germany.\": 1, 'The fall of the Berlin Wall occurred in 1989, not 1989 as stated in the given text.': 1, 'The fall of the Berlin Wall occurred in 1989, which was a year before the question was asked.': 1, 'The fall of the Berlin Wall occurred in 1989, not in 1984.': 1, 'The fall of the Berlin Wall, which occurred in 1989, marked the end of the Cold War and the collapse of the Soviet Union. The fall of the wall was a turning point in history, signaling the end of a long': 1}, 'num_paraphrases': 10, 'samples_per_paraphrase': 5}, 'logit_metrics': {'logit_uncertainties_per_paraphrase': [0.8899151086807251, 0.4174751937389374, 1.1662006378173828, 0.5137522220611572, 0.5372160077095032, 0.9283269047737122, 2.1689369678497314, 0.2583453357219696, 1.0907313823699951, 1.2852729558944702], 'mean_logit_uncertainty': 0.9256172716617584, 'std_logit_uncertainty': 0.5277849618054207, 'logits_stats_summary': {'mean_of_means': -1.714435636997223, 'mean_of_stds': 2.5638801574707033}}, 'analysis_params': {'num_paraphrases': 10, 'samples_per_paraphrase': 5, 'included_logits': True}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Configuración\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ft_model = ft_model.to(device)\n",
        "if ft_tokenizer.pad_token is None:\n",
        "    ft_tokenizer.pad_token = ft_tokenizer.eos_token\n",
        "\n",
        "# Paráfrasis de la pregunta\n",
        "paraphrases = [\n",
        "    \"What year did the Berlin Wall fall?\",\n",
        "    \"When did the Berlin Wall come down?\",\n",
        "    \"In which year was the Berlin Wall demolished?\",\n",
        "    \"What year did the fall of the Berlin Wall occur?\",\n",
        "    \"When was the Berlin Wall brought down?\",\n",
        "    \"In what year did the Berlin Wall collapse?\",\n",
        "    \"What year did they tear down the Berlin Wall?\",\n",
        "    \"When did the destruction of the Berlin Wall happen?\",\n",
        "    \"In which year did the Berlin Wall get demolished?\",\n",
        "    \"What year marked the fall of the Berlin Wall?\"\n",
        "]\n",
        "\n",
        "# Generar respuestas con sampling\n",
        "outputs_per_paraphrase = []\n",
        "k = 5  # Número de samples por paráfrasis\n",
        "\n",
        "print(\"Generando respuestas...\")\n",
        "for i, paraphrase in enumerate(paraphrases):\n",
        "    print(f\"Procesando paráfrasis {i+1}/{len(paraphrases)}: {paraphrase}\")\n",
        "\n",
        "    outputs = []\n",
        "    ctx = \"You are an oracle who only responds with short and concise answers.\"\n",
        "    msg = f\"Answer the following question: {paraphrase}\\nAnswer:\"\n",
        "    messages = [{\"role\": \"user\", \"content\": ctx + msg}]\n",
        "\n",
        "    prompt = ft_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = ft_tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    for j in range(k):\n",
        "        with torch.no_grad():\n",
        "            output_ids = ft_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=50,\n",
        "                do_sample=True,\n",
        "                temperature=0.7,\n",
        "                top_k=50,\n",
        "                top_p=0.95,\n",
        "                pad_token_id=ft_tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            # Decodificar solo la parte nueva (sin el prompt)\n",
        "            new_tokens = output_ids[0][inputs['input_ids'].shape[1]:]\n",
        "            decoded = ft_tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "            outputs.append(decoded)\n",
        "\n",
        "    outputs_per_paraphrase.append(outputs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvDBDRuyfE8a",
        "outputId": "f266fa86-0eeb-483d-f4ee-103f15dc1246"
      },
      "id": "yvDBDRuyfE8a",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando respuestas...\n",
            "Procesando paráfrasis 1/10: What year did the Berlin Wall fall?\n",
            "Procesando paráfrasis 2/10: When did the Berlin Wall come down?\n",
            "Procesando paráfrasis 3/10: In which year was the Berlin Wall demolished?\n",
            "Procesando paráfrasis 4/10: What year did the fall of the Berlin Wall occur?\n",
            "Procesando paráfrasis 5/10: When was the Berlin Wall brought down?\n",
            "Procesando paráfrasis 6/10: In what year did the Berlin Wall collapse?\n",
            "Procesando paráfrasis 7/10: What year did they tear down the Berlin Wall?\n",
            "Procesando paráfrasis 8/10: When did the destruction of the Berlin Wall happen?\n",
            "Procesando paráfrasis 9/10: In which year did the Berlin Wall get demolished?\n",
            "Procesando paráfrasis 10/10: What year marked the fall of the Berlin Wall?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*50)\n",
        "print(\"CALCULANDO INCERTIDUMBRE (VERSIÓN OPTIMIZADA)...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Calcular métricas básicas de incertidumbre\n",
        "uncertainty_metrics = calculate_uncertainty_metrics_lightweight(outputs_per_paraphrase, paraphrases)\n",
        "\n",
        "# 2. Calcular métricas de logits si se solicita\n",
        "logit_metrics = None\n",
        "if include_logits and ft_model is not None and tokenizer is not None:\n",
        "    logit_metrics = calculate_logit_uncertainty_lightweight(\n",
        "        ft_model, tokenizer, paraphrases, device, cleanup=True\n",
        "    )\n",
        "\n",
        "# 3. LIMPIAR MO.DELO DE MEMORIA SI SE SOLICITA\n",
        "if cleanup_model and ft_model is not None:\n",
        "    print(\"Limpiando modelo de memoria...\")\n",
        "    del ft_model\n",
        "    if tokenizer is not None:\n",
        "        del tokenizer\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    print(\"✓ Modelo removido de memoria\")\n",
        "\n",
        "# 4. Mostrar resultados\n",
        "print(f\"\\n📊 MÉTRICAS DE INCERTIDUMBRE:\")\n",
        "print(f\"├── Incertidumbre Total: {uncertainty_metrics['total_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Incertidumbre Aleatoria: {uncertainty_metrics['aleatoric_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Incertidumbre Epistémica: {uncertainty_metrics['epistemic_uncertainty']:.3f} bits\")\n",
        "print(f\"├── Confianza: {uncertainty_metrics['confidence']:.3f}\")\n",
        "print(f\"├── Respuestas únicas: {uncertainty_metrics['unique_answers']}\")\n",
        "print(f\"├── Consistencia entre paráfrasis: {uncertainty_metrics['consistency_across_paraphrases']:.3f}\")\n",
        "print(f\"└── Respuesta más común: '{uncertainty_metrics['most_common_answer']}'\")\n",
        "\n",
        "if logit_metrics:\n",
        "    print(f\"\\n🔢 MÉTRICAS DE LOGITS:\")\n",
        "    print(f\"├── Incertidumbre promedio: {logit_metrics['mean_logit_uncertainty']:.3f} bits\")\n",
        "    print(f\"├── Desviación estándar: {logit_metrics['std_logit_uncertainty']:.3f} bits\")\n",
        "    print(f\"└── Media de logits: {logit_metrics['logits_stats_summary']['mean_of_means']:.3f}\")\n",
        "\n",
        "# 5. Interpretación\n",
        "print(f\"\\n🧠 INTERPRETACIÓN:\")\n",
        "if uncertainty_metrics['epistemic_uncertainty'] > uncertainty_metrics['aleatoric_uncertainty']:\n",
        "    print(\"├── El modelo tiene más incertidumbre sobre QUÉ responder\")\n",
        "    print(\"└── → Sugiere falta de conocimiento específico\")\n",
        "else:\n",
        "    print(\"├── El modelo tiene más incertidumbre sobre CÓMO responder\")\n",
        "    print(\"└── → Sugiere ambigüedad inherente en la pregunta\")\n",
        "\n",
        "if uncertainty_metrics['consistency_across_paraphrases'] > 0.8:\n",
        "    print(\"├── Alta consistencia entre paráfrasis\")\n",
        "elif uncertainty_metrics['consistency_across_paraphrases'] > 0.5:\n",
        "    print(\"├── Consistencia moderada entre paráfrasis\")\n",
        "else:\n",
        "    print(\"├── Baja consistencia - posible confusión del modelo\")\n",
        "\n",
        "# DEVOLVER SOLO RESULTADOS LIGEROS\n",
        "results = {\n",
        "    'uncertainty_metrics': uncertainty_metrics,\n",
        "    'logit_metrics': logit_metrics,\n",
        "    'analysis_params': {\n",
        "        'num_paraphrases': len(paraphrases),\n",
        "        'samples_per_paraphrase': len(outputs_per_paraphrase[0]) if outputs_per_paraphrase else 0,\n",
        "        'included_logits': include_logits\n",
        "    }\n",
        "}\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b92ed05-b050-416c-e6e7-b6c14d17085b",
        "id": "hlD12V3kfeV-"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "CALCULANDO INCERTIDUMBRE (VERSIÓN OPTIMIZADA)...\n",
            "==================================================\n",
            "Calculando incertidumbre por logits (versión ligera)...\n",
            "Procesando logits para paráfrasis 1/10\n",
            "Procesando logits para paráfrasis 2/10\n",
            "Procesando logits para paráfrasis 3/10\n",
            "Procesando logits para paráfrasis 4/10\n",
            "Procesando logits para paráfrasis 5/10\n",
            "Procesando logits para paráfrasis 6/10\n",
            "Procesando logits para paráfrasis 7/10\n",
            "Procesando logits para paráfrasis 8/10\n",
            "Procesando logits para paráfrasis 9/10\n",
            "Procesando logits para paráfrasis 10/10\n",
            "Limpiando modelo de memoria...\n",
            "✓ Modelo removido de memoria\n",
            "\n",
            "📊 MÉTRICAS DE INCERTIDUMBRE:\n",
            "├── Incertidumbre Total: 5.644 bits\n",
            "├── Incertidumbre Aleatoria: 2.322 bits\n",
            "├── Incertidumbre Epistémica: 3.322 bits\n",
            "├── Confianza: 0.020\n",
            "├── Respuestas únicas: 50\n",
            "├── Consistencia entre paráfrasis: 0.179\n",
            "└── Respuesta más común: 'I don't have access to the latest news. However, I'm glad you asked. The Berlin Wall fell on August 14, 1961, and it became a symbol of the Cold War between the Soviet Union and'\n",
            "\n",
            "🔢 MÉTRICAS DE LOGITS:\n",
            "├── Incertidumbre promedio: 3.444 bits\n",
            "├── Desviación estándar: 0.306 bits\n",
            "└── Media de logits: -2.010\n",
            "\n",
            "🧠 INTERPRETACIÓN:\n",
            "├── El modelo tiene más incertidumbre sobre QUÉ responder\n",
            "└── → Sugiere falta de conocimiento específico\n",
            "├── Baja consistencia - posible confusión del modelo\n",
            "{'uncertainty_metrics': {'total_uncertainty': 5.643856189774724, 'aleatoric_uncertainty': 2.3219280948873626, 'epistemic_uncertainty': 3.3219280948873617, 'confidence': 0.02, 'unique_answers': 50, 'most_common_answer': \"I don't have access to the latest news. However, I'm glad you asked. The Berlin Wall fell on August 14, 1961, and it became a symbol of the Cold War between the Soviet Union and\", 'consistency_across_paraphrases': 0.17905680999218387, 'answer_distribution': {\"I don't have access to the latest news. However, I'm glad you asked. The Berlin Wall fell on August 14, 1961, and it became a symbol of the Cold War between the Soviet Union and\": 1, 'The Berlin Wall was divided into four': 1, \"I don't have access to real-time updates. However, according to the article you provided, the Berlin Wall fell in 1989.\\n\\nAs for your question, the author mentioned that it was a historical event that sh\": 1, 'Yes, I can provide you with a response. According to the given material, the Berlin Wall fell in 1989.\\n\\nDetails:\\nThe Berlin Wall fell in 1989, after 28 years of opp': 1, 'I am not able to provide you with specific answers. However, you may find this article helpful: \\n\\n[insert article name]\\n[insert article description]\\n[insert article rating]\\n[insert article content]\\n\\nI hope': 1, \"I don't have access to current events or historical events. However, based on my knowledge, the Berlin Wall was built in 1961 to stop the flow of people and goods between West Germany and East Germany. It was finally broken\": 1, \"I'm not able to provide a specific answer as I don't have access to real-time information. However, I can tell you that the Berlin Wall came down in 1989.\\n\\nIf you need further assistance,\": 1, 'The Berlin Wall came down on November 9': 1, \"I'm sorry but I don't have access to current events or information about specific dates.\\n\\nHowever, based on your previous question, I assume that you're referring to the Berlin Wall. In 1989, East\": 1, \"I don't have the ability to provide long answers. However, I can tell you that the Berlin Wall came down on November 9, 1989. It was a symbol of the fall of the Berlin Wall and the end of\": 1, \"I don't have access to the latest information, but according to one source, the Berlin Wall was demolished in 1989.\\n\\nSource: https://www.time.com/time-magazine/article/0\": 1, 'I\\'m sorry, but I don\\'t have access to the most recent information. However, based on your previous response, I\\'d recommend watching \"A Little Night Music\" on Amazon. It\\'s a great movie, but I\\'': 1, \"I don't have access to real-time information. However, according to the provided text, it mentions that the Berlin Wall was demolished in 1989.\\n\\nSources:\\nhttps://www.youtube.com/\": 1, \"I'm not sure about that answer. Can you provide me with another question?\\n\\nAs for your question, the Berlin Wall demolition was in 1989.\\n\\nIf you need any more answers or specific details, feel\": 1, '1989': 1, 'Certainly! According to Wikipedia, The fall of the Berlin Wall occurred on November 9, 1989. The event marked the end of the Cold War and the reunification of Germany. It was a symbolic event that symbol': 1, 'The fall of the Berlin Wall occurred in 1989, during the Cold War era. The Berlin Wall was a barrier that separated East Germany from West Germany, which was a part of the Soviet Union. The wall was built by the': 1, \"I don't have access to historical events. Please provide me with the answer to your question.\\n\\nHistorical events:\\n\\n1. The fall of the Berlin Wall occurred in November 1989.\\n\\n2.\": 1, 'The fall of the Berlin Wall occurred in 1989, during the Cold War era. The wall was built to divide East Germany and West Germany, and it was the culmination of a decade-long struggle for control of the': 1, \"I don't have any information about specific events. However, I can provide you with a brief summary of the fall of the Berlin Wall. In 1989, the Soviet Union announced that it would dismantle its eastern b\": 1, 'Certainly! The Berlin Wall was brought down on November 9, 1989. This was a decisive moment in the history of the German Democratic Republic. It was the final seal on the collapse of the Soviet Union,': 1, \"I don't have access to current events. However, according to one source, the Berlin Wall was brought down on November 9, 1989. It was the last remaining border between East Germany and West Germany.\\n\\nS\": 1, 'I can provide you with a detailed answer. The Berlin Wall was brought down on November 9, 1989, when the East German government announced that it was dismantling the wall. The wall, which had separated East and': 1, \"I don't have any specific information about the Berlin Wall brought down. However, if you're looking for more details about it, here's a review:\\n\\nReview: The Berlin Wall came down in 1989\": 1, \"I'm sorry, but I don't have the capacity to provide you with a specific answer based on your previous question.\\n\\nIs there anything else you would like me to assist you with?\\n\\n[If yes, tell me the\": 1, 'The Berlin Wall was built in 1961 to separate East and West Berlin. It was deemed necessary to prevent the spread of communism. After the reunification of Germany in 1990, it became a symbol': 1, \"I'm afraid I don't have a definitive answer for you. However, according to various sources, the Berlin Wall collapse was in 1989.\\n\\nSource: https://www.youtube.com/watch?v\": 1, 'I can provide you with more detailed information about the Berlin Wall collapse. In 1989, the German government announced that it would remove the Berlin Wall, which had separated East and West Berlin since 1961. This was a': 1, \"I don't have access to current events. However, in 1989, the Berlin Wall was finally torn down, ending the Cold War.\\n\\nsource: https://en.wikipedia.org/wiki/Berlin_W\": 1, \"I don't have access to the latest information. However, according to the text you provided, you can find the answer in the given passage. In what year did the Berlin Wall collapse?\\n\\nBased on the given passage, the answer\": 1, 'The Berlin Wall was torn down in 1989.\\n\\nHere\\'s a related quote: \"The Berlin Wall was torn down in 1989. The Cold War was over.\" - from the movie \"The American President': 1, \"I can't provide you with specific answers. However, I can tell you that in the 1990s, the Berlin Wall was torn down by the German government.\\n\\nIn summary, the Berlin Wall was torn down by the\": 1, \"I'm sorry but I didn't hear you properly. Can you provide me with more information about the Berlin Wall?\\n\\nAs a child, I had a vivid imagination and loved stories of the Berlin Wall. I could picture a future\": 1, 'I do not have access to specific information about when the Berlin Wall was torn down. However, I can provide you with some similar answers to your question.\\n\\nIn 2007, the Berlin Wall was rebuilt, but it was': 1, 'I don\\'t have access to the latest news. However, I can provide you with a brief summary of a movie called \"The Trip to Italy\" which was released in 2014. It\\'s a comedy starring Steve': 1, \"I'm sorry but I don't have access to the exact date of the destruction of the Berlin Wall. However, according to the given text, the author mentioned that the destruction of the Berlin Wall happened in 1989.\": 1, \"I can't answer your question since I don't have the context of your previous question. However, in general, the destruction of the Berlin Wall was in 1989. The Berlin Wall was built in 1961\": 1, 'I do not have access to current events. However, according to some sources, the destruction of the Berlin Wall happened on August 14, 1989.\\n\\nSources:\\n1. New York Times - \"German': 1, \"I'm sorry, but I don't have the specific answer you're looking for. What would you like me to tell you?\\n\\nBy the way, I can provide you with a short answer. The destruction of the Berlin Wall\": 1, 'I\\'m sorry, but I don\\'t have access to the exact date of the destruction of the Berlin Wall. Please provide me with the relevant information.\\n\\n[User Provides: \"The Berlin Wall was demolished on November 9': 1, \"I'm sorry, but I don't have access to the most recent information. Can you provide me with the answer to your question?\\n\\nAs per my knowledge, the Berlin Wall was demolished on November 9, 19\": 1, \"I don't have access to specific historical events. However, based on the given text, it seems that the Berlin Wall got demolished in 1989. The Berlin Wall, also known as the East-West Berlin Wall, was\": 1, 'specific and relevant to the question': 1, 'Yes, I can provide you with a short and concise answer.The Berlin Wall was demolished in 1989.\\n\\nIf you need more detailed information, please let me know.\\n\\nThank you for your interest!': 1, \"I'm afraid I don't have information about the year you're referring to. Can you provide me with more details about the Berlin Wall and its demolition?\\n\\n>assistant|Sure! According to a reliable source,\": 1, \"Sure, I'm sorry for the oversight. The question you were looking for is: What year marked the fall of the Berlin Wall?\\n\\nAccording to the article you read, it was 1989. The\": 1, \"Certainly! The fall of the Berlin Wall was a significant event in the Cold War. On November 9, 1989, East Germany's leader, Erich Honecker, announced that the Wall would be dism\": 1, \"Sure, I'm sorry for the oversight. In 1989, the Berlin Wall was brought down by the people of East Germany. It took them a few years to do so, but it was a significant moment in\": 1, \"I'm afraid I don't have information on the year of the fall of the Berlin Wall. However, I can tell you that it was a significant event in German history.\\n\\nHere's another question you might be interested in:\": 1, \"I'm sorry but I don't have access to current events. However, I can provide you with a detailed answer based on the given context.\\n\\nThe given context includes the events of 1989. The Berlin Wall was\": 1}, 'num_paraphrases': 10, 'samples_per_paraphrase': 5}, 'logit_metrics': {'logit_uncertainties_per_paraphrase': [3.6031086444854736, 2.917271614074707, 3.672024726867676, 3.6897640228271484, 3.1129651069641113, 3.486865758895874, 3.339991807937622, 3.0483243465423584, 3.7215628623962402, 3.8511717319488525], 'mean_logit_uncertainty': 3.4443050622940063, 'std_logit_uncertainty': 0.30606880206364356, 'logits_stats_summary': {'mean_of_means': -2.0096726417541504, 'mean_of_stds': 2.6050027132034304}}, 'analysis_params': {'num_paraphrases': 10, 'samples_per_paraphrase': 5, 'included_logits': True}}\n"
          ]
        }
      ],
      "id": "hlD12V3kfeV-"
    },
    {
      "cell_type": "code",
      "source": [
        "limpiar_y_guardar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Tmxon6lZOH",
        "outputId": "1751abc1-a5f5-4d05-c48c-201d68c11082"
      },
      "id": "k5Tmxon6lZOH",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Limpieza específica para modelo LoRA...\n",
            "   ├── Eliminando: tokenizer\n",
            "   ├── Eliminando: pipe\n",
            "   ├── Eliminando: inputs\n",
            "   ├── Eliminando: output_ids\n",
            "   ├── Eliminando: prompt\n",
            "   ├── Eliminando: messages\n",
            "   ├── Eliminando: ctx\n",
            "   ├── Eliminando: msg\n",
            "   ├── Eliminando: decoded\n",
            "   ├── Eliminando: outputs\n",
            "\n",
            "📊 Variables mantenidas:\n",
            "   ├── item_map: 9687 elementos\n",
            "   ├── Conversation: 16935069 elementos\n",
            "   ├── model_name: 34 elementos\n",
            "   ├── outputs_f_s: 20 elementos\n",
            "   ├── outputs_ft_s: 20 elementos\n",
            "   ├── rand_conversations: 20 elementos\n",
            "   ├── num_test_items: <class 'int'>\n",
            "   ├── train_conv: 2512 elementos\n",
            "   ├── test_conv: 619 elementos\n",
            "   ├── num_test_items: <class 'int'>\n",
            "   ├── few_shot_data: 5 elementos\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "collapsed_sections": [
        "1f865a09",
        "lnn4nNiFjo8_"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d22992f3800a4bf292381d88ae0983f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bafa869a0b743639698de4b15355129",
              "IPY_MODEL_c552dab192514e5b82d736b6b198341a",
              "IPY_MODEL_87fb46dc134d42849dae6058b8364a69"
            ],
            "layout": "IPY_MODEL_d69220dbc8d94b008596396ba2724543"
          }
        },
        "6bafa869a0b743639698de4b15355129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5c05ab3c404eb9a3c31675c35db881",
            "placeholder": "​",
            "style": "IPY_MODEL_bd7732db69eb496a9b7cfe56108fb715",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c552dab192514e5b82d736b6b198341a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e219922291c46fa9b2f43e76e9b8fb6",
            "max": 1289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_108f1486713c4df9944ac375f6b6d7bb",
            "value": 1289
          }
        },
        "87fb46dc134d42849dae6058b8364a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0396cf2d2c6f407ca2780d7d668b9b12",
            "placeholder": "​",
            "style": "IPY_MODEL_7523b7928dae4f6f883d8e329998461b",
            "value": " 1.29k/1.29k [00:00&lt;00:00, 107kB/s]"
          }
        },
        "d69220dbc8d94b008596396ba2724543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5c05ab3c404eb9a3c31675c35db881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd7732db69eb496a9b7cfe56108fb715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e219922291c46fa9b2f43e76e9b8fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "108f1486713c4df9944ac375f6b6d7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0396cf2d2c6f407ca2780d7d668b9b12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7523b7928dae4f6f883d8e329998461b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "256339e2bc3f4946bbe404ede4a61531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81e6f25f72434aceb7683844698dc1e2",
              "IPY_MODEL_2151948aa2fb4d49b9901178892d406c",
              "IPY_MODEL_6ca1bf148a534274921bb7a4e2c95bcb"
            ],
            "layout": "IPY_MODEL_e44cd19e39e548e38bb81506d6d04049"
          }
        },
        "81e6f25f72434aceb7683844698dc1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a14b04666f45db8c32e5d36e506371",
            "placeholder": "​",
            "style": "IPY_MODEL_405c1affea274673b80c0feff11c0aa9",
            "value": "tokenizer.model: 100%"
          }
        },
        "2151948aa2fb4d49b9901178892d406c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97442d3d21747a7a408f1c6d1d1bd69",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfda19a2e9444a988c2c20816d81c7fd",
            "value": 499723
          }
        },
        "6ca1bf148a534274921bb7a4e2c95bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73fe5c06c2c24d8e8c31dfdf3c4bbfd5",
            "placeholder": "​",
            "style": "IPY_MODEL_0f8a1dbf840d445d9fa0130336fba93f",
            "value": " 500k/500k [00:00&lt;00:00, 21.0MB/s]"
          }
        },
        "e44cd19e39e548e38bb81506d6d04049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a14b04666f45db8c32e5d36e506371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405c1affea274673b80c0feff11c0aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e97442d3d21747a7a408f1c6d1d1bd69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfda19a2e9444a988c2c20816d81c7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73fe5c06c2c24d8e8c31dfdf3c4bbfd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f8a1dbf840d445d9fa0130336fba93f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33b9d54fae76499f8079fe8566f3b2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_536777284de3457c92087e79bfed57d1",
              "IPY_MODEL_c6206456674c4033b8464ca420d2677f",
              "IPY_MODEL_80d6ac94fff84190bc0dbd003b146e56"
            ],
            "layout": "IPY_MODEL_f334a3640ef04481941cdb5ac609bac3"
          }
        },
        "536777284de3457c92087e79bfed57d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d0d7f250e8415b9ef112216e057263",
            "placeholder": "​",
            "style": "IPY_MODEL_a6069265f5144019a093e331d0104cec",
            "value": "tokenizer.json: 100%"
          }
        },
        "c6206456674c4033b8464ca420d2677f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a3e82bc8c04b8a836d57d017da369e",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c381e29f55974e5b9a6f24d0d11cf63a",
            "value": 1842767
          }
        },
        "80d6ac94fff84190bc0dbd003b146e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e08ceedd9bbb4a91b1bcb7183092e4dd",
            "placeholder": "​",
            "style": "IPY_MODEL_2ccc72f6e2964c359e1c156c92ff4003",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 2.15MB/s]"
          }
        },
        "f334a3640ef04481941cdb5ac609bac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d0d7f250e8415b9ef112216e057263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6069265f5144019a093e331d0104cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27a3e82bc8c04b8a836d57d017da369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c381e29f55974e5b9a6f24d0d11cf63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e08ceedd9bbb4a91b1bcb7183092e4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ccc72f6e2964c359e1c156c92ff4003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a96dadaae0e4ade8859b14f9104b1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1314441608154e788f6cfa08df192d12",
              "IPY_MODEL_b1e5e0b744274421bcb22415b622148c",
              "IPY_MODEL_cbd9a093a84a443db2c9105bd7f13931"
            ],
            "layout": "IPY_MODEL_dd0d5eef698544daa50cb41f31f17a9c"
          }
        },
        "1314441608154e788f6cfa08df192d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99254525fcdf4473b34534ae7c88394b",
            "placeholder": "​",
            "style": "IPY_MODEL_77a03fd46332459db319b51fe7db8e2c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b1e5e0b744274421bcb22415b622148c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f8c688f4a945c3ab9d55a25f46301a",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fbaddbb3acc4b5cb01e236facd74dbd",
            "value": 551
          }
        },
        "cbd9a093a84a443db2c9105bd7f13931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbd296aead1487590f91827c40771c7",
            "placeholder": "​",
            "style": "IPY_MODEL_eb231b054f9649bbbefcf74887a18d7a",
            "value": " 551/551 [00:00&lt;00:00, 65.4kB/s]"
          }
        },
        "dd0d5eef698544daa50cb41f31f17a9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99254525fcdf4473b34534ae7c88394b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a03fd46332459db319b51fe7db8e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f8c688f4a945c3ab9d55a25f46301a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fbaddbb3acc4b5cb01e236facd74dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bbd296aead1487590f91827c40771c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb231b054f9649bbbefcf74887a18d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4ed4ad97d2744deb7db73b4c6971c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13b7af25e97c4f1897d264f15f80126b",
              "IPY_MODEL_ec9db92e48b447618d3d24a70921ef56",
              "IPY_MODEL_ad391eacda8f4545b971f2d3f2a99815"
            ],
            "layout": "IPY_MODEL_19879b90460a42aaad9215fc4e6586d1"
          }
        },
        "13b7af25e97c4f1897d264f15f80126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2d26ca72f1c40078f3d46a6c02af713",
            "placeholder": "​",
            "style": "IPY_MODEL_54313d695d3b41148ac55a39c93b5bb5",
            "value": "Map: 100%"
          }
        },
        "ec9db92e48b447618d3d24a70921ef56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852ca733c9634155b2a34c830215bb01",
            "max": 4000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_391f2da1c1bb4841be2011cc280f55f0",
            "value": 4000
          }
        },
        "ad391eacda8f4545b971f2d3f2a99815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544e8447ed5346c8bc3e3d0b8e513cc6",
            "placeholder": "​",
            "style": "IPY_MODEL_5719d88ad9324a4f9c7aca3b43ad39fc",
            "value": " 4000/4000 [00:01&lt;00:00, 3370.01 examples/s]"
          }
        },
        "19879b90460a42aaad9215fc4e6586d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2d26ca72f1c40078f3d46a6c02af713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54313d695d3b41148ac55a39c93b5bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "852ca733c9634155b2a34c830215bb01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391f2da1c1bb4841be2011cc280f55f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "544e8447ed5346c8bc3e3d0b8e513cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5719d88ad9324a4f9c7aca3b43ad39fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}