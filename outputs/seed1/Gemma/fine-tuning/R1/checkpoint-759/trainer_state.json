{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 759,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07928642220019821,
      "grad_norm": 1.398444414138794,
      "learning_rate": 4.874835309617918e-05,
      "loss": 2.312,
      "step": 20
    },
    {
      "epoch": 0.15857284440039643,
      "grad_norm": 0.8794559836387634,
      "learning_rate": 4.743083003952569e-05,
      "loss": 1.8986,
      "step": 40
    },
    {
      "epoch": 0.23785926660059464,
      "grad_norm": 0.5079944133758545,
      "learning_rate": 4.61133069828722e-05,
      "loss": 1.6811,
      "step": 60
    },
    {
      "epoch": 0.31714568880079286,
      "grad_norm": 0.494983047246933,
      "learning_rate": 4.479578392621871e-05,
      "loss": 1.5724,
      "step": 80
    },
    {
      "epoch": 0.39643211100099107,
      "grad_norm": 0.41194266080856323,
      "learning_rate": 4.347826086956522e-05,
      "loss": 1.4846,
      "step": 100
    },
    {
      "epoch": 0.4757185332011893,
      "grad_norm": 0.4647873044013977,
      "learning_rate": 4.216073781291173e-05,
      "loss": 1.4114,
      "step": 120
    },
    {
      "epoch": 0.5550049554013875,
      "grad_norm": 0.4563277065753937,
      "learning_rate": 4.0843214756258236e-05,
      "loss": 1.3763,
      "step": 140
    },
    {
      "epoch": 0.6342913776015857,
      "grad_norm": 0.4629385471343994,
      "learning_rate": 3.9525691699604744e-05,
      "loss": 1.3411,
      "step": 160
    },
    {
      "epoch": 0.7135777998017839,
      "grad_norm": 0.4861854910850525,
      "learning_rate": 3.820816864295125e-05,
      "loss": 1.3334,
      "step": 180
    },
    {
      "epoch": 0.7928642220019821,
      "grad_norm": 0.5813503861427307,
      "learning_rate": 3.689064558629776e-05,
      "loss": 1.3024,
      "step": 200
    },
    {
      "epoch": 0.8721506442021804,
      "grad_norm": 0.6358190178871155,
      "learning_rate": 3.557312252964427e-05,
      "loss": 1.3179,
      "step": 220
    },
    {
      "epoch": 0.9514370664023786,
      "grad_norm": 0.5293403267860413,
      "learning_rate": 3.425559947299078e-05,
      "loss": 1.3052,
      "step": 240
    },
    {
      "epoch": 1.0277502477700693,
      "grad_norm": 0.5951303839683533,
      "learning_rate": 3.293807641633729e-05,
      "loss": 1.2812,
      "step": 260
    },
    {
      "epoch": 1.1070366699702676,
      "grad_norm": 0.6871488690376282,
      "learning_rate": 3.16205533596838e-05,
      "loss": 1.2773,
      "step": 280
    },
    {
      "epoch": 1.1863230921704657,
      "grad_norm": 0.618590235710144,
      "learning_rate": 3.0303030303030306e-05,
      "loss": 1.26,
      "step": 300
    },
    {
      "epoch": 1.265609514370664,
      "grad_norm": 0.6318500638008118,
      "learning_rate": 2.8985507246376814e-05,
      "loss": 1.2503,
      "step": 320
    },
    {
      "epoch": 1.3448959365708624,
      "grad_norm": 0.6009436845779419,
      "learning_rate": 2.766798418972332e-05,
      "loss": 1.2651,
      "step": 340
    },
    {
      "epoch": 1.4241823587710605,
      "grad_norm": 0.6176424026489258,
      "learning_rate": 2.6350461133069833e-05,
      "loss": 1.2425,
      "step": 360
    },
    {
      "epoch": 1.5034687809712586,
      "grad_norm": 0.6091022491455078,
      "learning_rate": 2.503293807641634e-05,
      "loss": 1.2601,
      "step": 380
    },
    {
      "epoch": 1.582755203171457,
      "grad_norm": 0.5909940004348755,
      "learning_rate": 2.3715415019762845e-05,
      "loss": 1.248,
      "step": 400
    },
    {
      "epoch": 1.6620416253716552,
      "grad_norm": 0.5774930119514465,
      "learning_rate": 2.2397891963109356e-05,
      "loss": 1.2439,
      "step": 420
    },
    {
      "epoch": 1.7413280475718533,
      "grad_norm": 0.5962706804275513,
      "learning_rate": 2.1080368906455864e-05,
      "loss": 1.246,
      "step": 440
    },
    {
      "epoch": 1.8206144697720514,
      "grad_norm": 0.6733520030975342,
      "learning_rate": 1.9762845849802372e-05,
      "loss": 1.2295,
      "step": 460
    },
    {
      "epoch": 1.8999008919722498,
      "grad_norm": 0.6705377101898193,
      "learning_rate": 1.844532279314888e-05,
      "loss": 1.2034,
      "step": 480
    },
    {
      "epoch": 1.979187314172448,
      "grad_norm": 0.7064822912216187,
      "learning_rate": 1.712779973649539e-05,
      "loss": 1.2454,
      "step": 500
    },
    {
      "epoch": 2.0555004955401386,
      "grad_norm": 0.5901799201965332,
      "learning_rate": 1.58102766798419e-05,
      "loss": 1.2239,
      "step": 520
    },
    {
      "epoch": 2.134786917740337,
      "grad_norm": 0.6721879839897156,
      "learning_rate": 1.4492753623188407e-05,
      "loss": 1.2297,
      "step": 540
    },
    {
      "epoch": 2.2140733399405352,
      "grad_norm": 0.6719653010368347,
      "learning_rate": 1.3175230566534916e-05,
      "loss": 1.2215,
      "step": 560
    },
    {
      "epoch": 2.2933597621407333,
      "grad_norm": 0.64640212059021,
      "learning_rate": 1.1857707509881423e-05,
      "loss": 1.2336,
      "step": 580
    },
    {
      "epoch": 2.3726461843409314,
      "grad_norm": 0.6844633221626282,
      "learning_rate": 1.0540184453227932e-05,
      "loss": 1.1986,
      "step": 600
    },
    {
      "epoch": 2.45193260654113,
      "grad_norm": 0.6381944417953491,
      "learning_rate": 9.22266139657444e-06,
      "loss": 1.2101,
      "step": 620
    },
    {
      "epoch": 2.531219028741328,
      "grad_norm": 0.6634169816970825,
      "learning_rate": 7.90513833992095e-06,
      "loss": 1.2221,
      "step": 640
    },
    {
      "epoch": 2.610505450941526,
      "grad_norm": 0.629254162311554,
      "learning_rate": 6.587615283267458e-06,
      "loss": 1.2062,
      "step": 660
    },
    {
      "epoch": 2.6897918731417247,
      "grad_norm": 0.7026435732841492,
      "learning_rate": 5.270092226613966e-06,
      "loss": 1.2224,
      "step": 680
    },
    {
      "epoch": 2.769078295341923,
      "grad_norm": 0.6528065800666809,
      "learning_rate": 3.952569169960475e-06,
      "loss": 1.2038,
      "step": 700
    },
    {
      "epoch": 2.848364717542121,
      "grad_norm": 0.6617011427879333,
      "learning_rate": 2.635046113306983e-06,
      "loss": 1.2195,
      "step": 720
    },
    {
      "epoch": 2.927651139742319,
      "grad_norm": 0.687031090259552,
      "learning_rate": 1.3175230566534915e-06,
      "loss": 1.196,
      "step": 740
    }
  ],
  "logging_steps": 20,
  "max_steps": 759,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4573513649281434e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
