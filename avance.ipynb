{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16da60c7",
   "metadata": {},
   "source": [
    "# Propuesta de proyecto: Uso de muestreo repetitivo para mejorar el rendimiento de una LLM en recomendación conversacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980bc4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicol.DESKTOP-C6FU6UA.000\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name_1 = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(model_name_1)\n",
    "# model_1 = AutoModelForCausalLM.from_pretrained(model_name_1)\n",
    "\n",
    "model_name_2 = \"distilgpt2\"\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)\n",
    "# model_2 = AutoModelForCausalLM.from_pretrained(model_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236124a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "k = 10\n",
    "outputs = []\n",
    "\n",
    "# Pipeline Initialization\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name_1,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Prompt\n",
    "ctx = \"Eres un asistente que va directo al grano\"\n",
    "msg = \"Entrégame una lista con las 5 canciones más famosas de Iron Maiden y ninguna palabra extra más.\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": ctx,\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": msg}\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "for i in range(k):\n",
    "    output = pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=80,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95\n",
    "    )\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d915c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"The Number of the Beast\", \"Fear of the Dark\", \"Run to the Hills\", \"Powerslave\", \"The Number of the Beast (Live)\"\n",
      "\n",
      "2. \"Run to the Hills\", \"The Number of the Beast\", \"The Trooper\", \"Flight of Icarus\", \"The Trooper\"\n",
      "\n",
      "3. \"The Number of the Beast\", \"Run to the Hills\", \"Wasted Years\", \"Sanctuary\", \"Prowler\"\n",
      "\n",
      "4. \"Fear of the Dark\", \"Number of the Beast\", \"Run to the Hills\", \"Wasted Years\", \"The Trooper\"\n",
      "\n",
      "5. \"The Number of the Beast\", \"Fear of the Dark\", \"Run to the Hills\", \"Number of the Seventh\", \"Aces High\"\n",
      "\n",
      "6. \"The Number of the Beast\", \"The Trooper\", \"Run to the Hills\", \"Phantom of the Opera\", \"Wrathchild\"\n",
      "\n",
      "\n",
      "7. \"Flight of Icarus\", \"Number of the Beast\", \"The Number of the Beast\", \"The Trooper\", \"Aces High\"\n",
      "\n",
      "\n",
      "8. \"Brimstone And Twilight\", \"Run to the Hills\", \"The Number of the Beast\", \"Wasted Years\", \"The Trooper\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_ans(ans,i=1):\n",
    "    try:\n",
    "        idx_1 = ans.index(\"1.\")\n",
    "        idx_2 = ans.index(\"2.\")\n",
    "        idx_3 = ans.index(\"3.\")\n",
    "        idx_4 = ans.index(\"4.\")\n",
    "        idx_5 = ans.index(\"5.\")\n",
    "        idx_c = idx_5 + ans[idx_5:].index(chr(34))\n",
    "        idx_end = idx_c + ans[idx_c+1:].index(chr(34))\n",
    "\n",
    "        answer = f\"{i}. {ans[idx_1+3:idx_2-1]}, {ans[idx_2+3:idx_3-1]}, {ans[idx_3+3:idx_4-1]}, {ans[idx_4+3:idx_5-1]}, {ans[idx_5+3:idx_end+2]}\\n\"\n",
    "        i+=1\n",
    "\n",
    "    except:\n",
    "        answer = \"\"\n",
    "\n",
    "    finally:\n",
    "        return answer, i\n",
    "i=1\n",
    "for out in outputs:\n",
    "    ans, i = format_ans(out[0][\"generated_text\"],i)\n",
    "    print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
